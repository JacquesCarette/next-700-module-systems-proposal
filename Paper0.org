# (progn (org-babel-tangle) (org-latex-export-to-pdf) (async-shell-command "open Paper0.pdf"))

# TITLE: Loosen your belt whenever you like
#+TITLE: A Language Feature to Unbundle Data at Will
#+DESCRIPTION: Thesis proposal for Musa Al-hassy; McMaster University 2019.
#+AUTHOR: [[mailto:alhassm@mcmaster.ca][Musa Al-hassy]], [[mailto:carette@mcmaster.ca][Jacques Carette]], [[mailto:kahl@cas.mcmaster.ca][Wolfram Kahl]]
#+EMAIL: alhassy@gmail.com
#+OPTIONS: toc:nil d:nil title:t
#+PROPERTY: header-args :tangle no :comments link

# At the end of a section, explain why the section is there,
# and what the reader should take away from it.

# MA: LaTeX pads colons, :, with spacing.
# For inline typing annotations, use ghost colon ‚Äú\:‚Äù to avoid this issue.

# Drop the 'proposed'. Use positive, active language like

# YS.
# Maybe start with asking what is the message you want to deliver in this paper? What kind of
# bundling is bad and why is it so?

# (add-to-list 'org-latex-text-markup-alist '(code . verb))
# (add-to-list 'org-latex-text-markup-alist '(verbatim . verb))

:WK_Tips:


‚óà Re: abstract:
Paragraph 1: Background and identified problem
Paragraph 2: Contribution

‚óà After code blocks, and especially before one-line paragraphs between
code blocks, always put \noindent unless there is a strong reason not to.
Also consider doubling the code block indentation.

‚óà  PacakageFormer --> \textsf{\upshape PackageFormer}
    [Code is ALWAYS typeset as code,
     just like math is always typeset as math.]

:End:
:JC_Remarks:
‚óÜ Consider Finite State Machines, rather than graphs, so as to have a multi-sorted
  structure where the sorts do not ‚Äòdepend‚Äô on each other.

- The introduction needs to cover the *problem* that is being solved - and not the solution; that is not 100% clear below
- You need to save space for related work (can be a short paragraph, but without it, it'll get rejected)
- Where are the citations? There should be citations throughout!
:End:

#+begin_center
*Abstract*
#+end_center
#+begin_small

  # The eager commit to what data should be a type parameter or a record component
  # is a premature design decision. We demonstrate a language feature that circumvents
  # such over-specification.
  #
  # WK:  That's quite a mouthful and hard to parse. Perhaps establish some context first?

  # This is analogous to
  # which information is exposed dynamically at runtime and which is known statically,
  # respectively.

  Programming languages with sufficiently expressive type theories provide users with
  different means of data ‚Äòbundling‚Äô. Specifically one can choose to encode information
  in a record either as a parameter or a field, in depdently-typed languages such as
  Agda, Coq and Idris.
  For example, we can speak of graphs /over/ a particular vertex set, or speak
  of arbitrary graphs where the vertex set is a component.
  These create isomorphic types, but differ with respect to intended use.
  Traditionally, a library designer would make this choice (between parameters and fields);
  if a user wants a different variant, they are forced to build conversion utilities as well as
  duplicate functionality. For a graph data type,
  if a library only provides a Haskell-like typeclass view of graphs /over/ a vertex set,
  yet a user wishes to work with the category of graphs, they must now package a vertex
  set as a component in a record along with a graph over that set.

  We design and implement a language feature that allows both the library designer and
  the user to make the choice of information exposure only when necessary, and otherwise leave
  the distinguishing line between parameters and fields unspecified.
  Our language feature is currently implemented as a prototype meta-program
  incorporated into Agda's Emacs ecosystem, in a way that is unobtrusive to Agda users.
#+end_small

* LaTeX setup                                                        :ignore:
# latex_class_options: [acmsmall,review,anonymous]
#+latex_class_options: [acmsmall,review]
#+LATEX_CLASS: acmart

# LATEX_HEADER: \settopmatter{prinfolios=true,princcs=false,printacmref=false}
# LATEX_HEADER: \usepackage[backend=biber,style=alphabetic]{biblatex}
# LATEX_HEADER: \addbibresource{MyReferences.bib}

# LATEX_HEADER: \acmJournal{PACMPL}
# LATEX_HEADER: \acmVolume{1}
# LATEX_HEADER: \acmNumber{POPL}
# LATEX_HEADER: \acmArticle{1}
# LATEX_HEADER: \acmYear{2019}
# LATEX_HEADER: \acmMonth{1}
# LATEX_HEADER: \acmDOI{}
#+LATEX_HEADER: \setcopyright{none}

#+LATEX_HEADER: \usepackage{/Users/musa/MyUnicodeSymbols/MyUnicodeSymbols}
#+LATEX_HEADER: \newunicodechar{‚®æ}{\ensuremath{\mathop{\fatsemi}}}
#+LATEX_HEADER: \newunicodechar{‚â¢}{\ensuremath{\nequiv}}
#+LATEX_HEADER: \newunicodechar{œÑ}{\ensuremath{\tau}}
#+LATEX_HEADER: \newunicodechar{‚ÇÑ}{\ensuremath{_4}}
#+LATEX_HEADER: \newunicodechar{‚Ä≤}{'}
#+LATEX_HEADER: \newunicodechar{‚Ä≥}{''}

# LATEX_HEADER: \newunicodechar{Œ£}{\ensuremath{\mathop{\Sigma}}}
# LATEX_HEADER: \newunicodechar{‚àò}{\ensuremath{\mathop{\circ}}}
# LATEX_HEADER: \newunicodechar{Œì}{\ensuremath{\Gamma}}
# LATEX_HEADER: \newunicodechar{Œ†}{\ensuremath{\Pi}}
# LATEX_HEADER: \newunicodechar{‚ü¶}{\ensuremath{\llbracket}}
# LATEX_HEADER: \newunicodechar{‚üß}{\ensuremath{\rrbracket}}
# LATEX_HEADER: \newunicodechar{Œò}{\ensuremath{\theta}}
# LATEX_HEADER: \newunicodechar{‚àé}{\ensuremath{\qedsymbol}}
# LATEX_HEADER: \newunicodechar{‚Ä≤}{'}
# LATEX_HEADER: \newunicodechar{œÑ}{\ensuremath{\tau}}
# LATEX_HEADER: \newunicodechar{‚¶É}{\ensuremath{ \{\{ }}  % this is not correct
# LATEX_HEADER: \newunicodechar{‚¶Ñ}{\ensuremath{ \}\} }}   % this is not correct
# LATEX_HEADER: \newunicodechar{‚äé}{\ensuremath{\cupdot}}  % should be in myunicode; go #regenerate# it!
# LATEX_HEADER: \def\with{\kern0.7em \withrule \kern0.7em }
# LATEX_HEADER: \def\withrule{\vrule height1.57ex depth0.43ex width0.12em}
# LATEX_HEADER: \newunicodechar{‚ùô}{\ensuremath{\mathop{\with}}}

#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor} % named colours
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \definecolor{darkred}{rgb}{0.3, 0.0, 0.0}
#+LATEX_HEADER: \definecolor{darkgreen}{rgb}{0.0, 0.3, 0.1}
#+LATEX_HEADER: \definecolor{darkblue}{rgb}{0.0, 0.1, 0.3}
#+LATEX_HEADER: \definecolor{darkorange}{rgb}{1.0, 0.55, 0.0}
#+LATEX_HEADER: \definecolor{sienna}{rgb}{0.53, 0.18, 0.09}
#+LATEX_HEADER: \hypersetup{colorlinks,linkcolor=darkblue,citecolor=darkblue,urlcolor=darkgreen}

#+NAME: symbols for itemisation environment
#+BEGIN_EXPORT latex
\def\labelitemi{$\diamond$}
\def\labelitemii{$\circ$}
\def\labelitemiii{$\star$}
#+END_EXPORT

# Having small-font code blocks.
# LATEX_HEADER: \RequirePackage{fancyvrb}
# LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}
#+BEGIN_EXPORT latex
% \author{Musa Al-hassy}
% \affiliation{
%   \institution{McMaster University}
%   \streetaddress{1280 Main St. W.}
%   \city{Hamilton}
%   \state{ON}
%   \postcode{L8S 4K1}
%   \country{Canada}}
% \email{alhassm@mcmaster.ca}
% \author{Jacques Carette}
% \author{Wolfram Kahl}
#+END_EXPORT

* COMMENT old  ---outline, 4 pages

  0. Introduction: Which perspective of semigroups does one select? Semigroupùíæ from the thesis proposal;
     the perspective considered should have legitimate uses rather than artificial ones.
     How do we write, e.g., ‚Äòconcat‚Äô in the various forms. What is the minimal reduplication required using
     existing techniques.

  1. \textsf{\upshape PackageFormer}s: Unifying the different perspectives under the same banner. We speak in terms of elaborations,
     but may propose elementary typing rules or semantics. Discuss \textsf{\upshape PackageFormer} polymorphism, from ¬ß4 of thesis proposal.

  2. Next Steps: Ignoring the implementation, there are no sound semantics for these constructs.
     Discuss theory presentation combinators and possible extensions.

* Introduction ---Selecting the ‚Äòright‚Äô perspective

  :Ideas:
  Which perspective of semigroups does one select? Semigroupùíæ from the thesis proposal;
     the perspective considered should have legitimate uses rather than artificial ones.
     How do we write, e.g., ‚Äòconcat‚Äô in the various forms. What is the minimal reduplication required using
     existing techniques.
   :End:

  Library designers want to produce software components that are not only useful to their
  immediate needs but also useful to the needs of others, such as themselves for a
  later project. As such, designers aim for a high-level of generality for increased
  reusability. The dimension we tackle in this paper is how much of a structures
  constituents are exposed at the type level and how many are left inside,
  to be projected when needed.

  The subtlety of what is a ‚Äòparameter‚Äô ---exposed at the type level--- and what is a
  ‚Äòfield‚Äô ---hidden as a component value--- has led to awkward formulations and
  the duplication of existing types for the sole purpose of different uses.
  For example, the ever-ubiquitous monoid, a prime model of compositionality,
  in traditional Haskell, is only allowed one instance per datatype. The Booleans,
  however, have multiple monoids such as sequential and parallel monoids
  ---the former being conjunction with
  identity /true/ and the latter being disjunction with identity /false.
  # --- which are
  # tractable demonstrations mirroring sequential and concurrent programming.

  The solution, in Haskell, is to have two isomorphic copies ~All~ and ~Any~ for which
  the former is given the sequential monoid and the latter the parallel monoid.
  An alternative solution would be to parameterise the monoid interface not only by
  its carrier type ---the Booleans in our example--- but also by the underlying
  compositionality scheme ---the conjunction and disjunction operators in our scheme.

  It seems that there are two contenders for the monoid interface:
  #+begin_src agda
  record Monoid‚ÇÅ (Carrier : Set) : Set where
    field
      _‚®æ_    : Carrier ‚Üí Carrier ‚Üí Carrier
     Id      : Carrier
     assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
     leftId  : ‚àÄ {x} ‚Üí Id ‚®æ x ‚â° x
     rightId : ‚àÄ {x} ‚Üí x ‚®æ Id ‚â° x

  record Monoid‚ÇÇ (Carrier : Set) (_‚®æ_ : Carrier ‚Üí Carrier ‚Üí Carrier) : Set where
     Id      : Carrier
     assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
     leftId  : ‚àÄ {x} ‚Üí Id ‚®æ x ‚â° x
     rightId : ‚àÄ {x} ‚Üí x ‚®æ Id ‚â° x
  #+end_src

  \vspace{0.3em}
  Of-course there are also the alternative formulations of where we bundle up
  the ~Carrier~ rather than have it exposed ---e.g., when we wish to speak of /a/
  monoid rather than /a monoid on a given type/--- or where we are interested
  in the identity element rather than in the compositionality scheme
  ---e.g., discrepancy ‚Äò‚â¢‚Äô and indistinguishability ‚Äò‚â°‚Äô have the same identities as
  conjunction and disjunction, respectively. Moreover, there are other combinations
  of what is to be exposed and hidden, for applications that we might never think of.

  Rather than code with /interface formulations we think people will likely use/, it is far
  more general to /commit to no particular formulation/ and allow the user to select
  the form most convenient for their use-cases. This desire for reusability motivates
  a new language feature: The \textsf{\upshape PackageFormer}.

  Moreover, what if the user wanted the syntax to form monoid terms as in
  metaprogramming. That would necessitate yet another nearly identical data-structure
  ---having constructors rather than field projections. We show how all these different
  presentations can be derived from a /single/ \textsf{\upshape PackageFormer} declaration.
  It is this massive reduction in duplicated efforts and maintenance that we view
  as the main contribution of our work.

* \textsf{\upshape PackageFormer}s ---Being non-committal as much as possible
  :Remarks:
  Unifying the different perspectives under the same banner. We speak in terms of elaborations,
     but may propose elementary typing rules or semantics. Discuss \textsf{\upshape PackageFormer} polymorphism, from ¬ß4 of thesis proposal.
     :End:

    It is notoriously difficult to reconstruct the possible inputs to a function
    that yielded a certain output. That is, unless you are using Prolog of-course,
    where the distinctions between input and output are an illusion that is otherwise
    made real only by how Prolog users treat arguments to a relation.
    Dependently-typed programming at its core is the adamant hygienic blurring of
    concepts and so the previous presentations of monoids are unified in the following
    single declaration which does not distinguish between parameters and fields.

      #+begin_src agda
  PackageFormer MonoidP : Set where
     _‚®æ_    : MonoidP ‚Üí MonoidP ‚Üí MonoidP
    Id      : MonoidP
    assoc   : ‚àÄ {x y z} ‚Üí (x ‚®æ y) ‚®æ z ‚â° x ‚®æ (y ‚®æ z)
    leftId  : ‚àÄ {x} ‚Üí Id ‚®æ x ‚â° x
    rightId : ‚àÄ {x} ‚Üí x ‚®æ Id ‚â° x
  #+end_src

  Superficially, the parameters and fields have been flattened into a single location
  and the name ~Carrier~ has been dispensed with in-favour of ~MonoidP~, which also happens
  to be name of this newly declared entity.
  We commend the astute reader who has noticed a hint of predicitivity here, but it is
  an issue we shall not address in the current work.

  #+BEGIN_EXPORT latex
  \emph{One uses a \textsf{\upshape PacakageFormer} by instantiating the particular presentation that is desired.}
  #+END_EXPORT

  We conceive of an extensible type ~Variations~ which includes ~datatype~ and ~record~
  as two keywords. Moreover, this type is equipped with a number of combinators, one
  of which is the infix operator ~_unbundled_ : Variation ‚Üí ‚Ñï ‚Üí Variation~ which modifies a particular
  presentation by also lifting the first ~n~ constituents from the field level to the
  parameter level. In particular, ~typeclass = record unbundled 1~.
  We also allow the named version of this combinator, namely
  ~_exposing_ : Variation ‚Üí List Name ‚Üí Variation~.
  Let's demonstrate these concepts.

  0. [@0] We may obtain the previous formulations of ~Monoid‚ÇÅ~ in two different ways:
        \vspace{0.3em}
    #+begin_src agda
 Monoid‚ÇÅ‚Ä≤  = MonoidP typeclass
 Monoid‚ÇÅ‚Ä≥ = MonoidP record exposing Carrier
#+end_src

    \vspace{0.3em}

  1. Likewise, there are number of ways to regain the previous formulation of ~Monoid‚ÇÇ~.
        \vspace{0.3em}
    #+begin_src agda
 Monoid‚ÇÇ‚Ä≤  = MonoidP record unbundled 2
 Monoid‚ÇÇ‚Ä≥ = MonoidP record exposing (Carrier; _‚®æ_)
#+end_src

      \vspace{0.3em}

  2. To speak of /a monoid over an arbitrary carrier/, we declare:
        \vspace{0.3em}
   #+begin_src agda
 Monoid‚ÇÉ = MonoidP record
#+end_src
   \vspace{0.3em}
   \noindent
   It behaves as if it were declared thusly:
   \vspace{0.3em}
   #+begin_src agda
    record Monoid‚ÇÉ : Set‚ÇÅ where
      field
        Carrier : Set
        _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
        Id      : Carrier
        ‚ãØ
#+end_src

  The name ~Carrier~ is a default and could be renamed; likewise for ~Vars~ below.

  3. [@3] Finally, we mentioned metaprogramming's need to work with terms:
        \vspace{0.3em}
    #+begin_src agda
 Monoid‚ÇÑ = MonoidP datatype
#+end_src
    \vspace{0.3em}
    \noindent
    It behaves as if it were declared thusly:
       \vspace{0.3em}
     #+begin_src agda
    data Monoid‚ÇÑ : Set where
        _‚®æ_ : Monoid‚ÇÑ ‚Üí Monoid‚ÇÑ ‚Üí Monoid‚ÇÑ
        Id  : Monoid‚ÇÑ
#+end_src
   \vspace{0.3em}
   \noindent
   Of course we may want to have terms /over/ a particular variable set, and so declare:
      \vspace{0.3em}
     #+begin_src agda
 Monoid‚ÇÖ = MonoidP datatype exposing (Vars)
#+end_src
    \vspace{0.3em}
    \noindent
    It behaves as if it were declared thusly:
       \vspace{0.3em}
    #+begin_src agda
    data Monoid‚ÇÖ (Vars : Set) : Set where
        inj : Vars ‚Üí Monoid‚ÇÑ Vars
        _‚®æ_ : Monoid‚ÇÑ Vars ‚Üí Monoid‚ÇÑ Vars ‚Üí Monoid‚ÇÑ Vars
        Id  : Monoid‚ÇÑ Vars
  #+end_src

     \vspace{0.3em}
     \noindent
     Note that only ‚Äòfunctional‚Äô symbols have been exposed in these elaborations; no ‚Äòproof-matter‚Äô.

  There are of-course a number of variation on how a package is to be presented,
  we have only mentioned a two for brevity. The thesis proposal mentions more and
  provides examples as well.

  The \textsf{\upshape PackageFormer} language feature unifies disparate representations of the
  same concept under a single banner. How does one actually /do/ anything with
  these entities? Are we forced to code along particular instantiations?
  No; unless we desire to do so.

* A Novel Polymorphism

  Suppose we want to produce the function ~concat~, which composes the elements of a list
  according to a compositionality scheme ---examples of this include summing over
  a list, multiplication over a list, checking all items in a list are true, or
  at least one item in the list is true. Depending on the interface presentation
  selected, the typing of this function could be elegant or awkward, as follows.
#+BEGIN_SRC agda
  concat‚ÇÅ : {C : Set} {M : Monoid‚ÇÅ C} ‚Üí List C ‚Üí C

  concat‚ÇÇ : {C : Set} {_‚®æ_ : C ‚Üí C‚Üí C} {M : Monoid‚ÇÇ C _‚®æ_} ‚Üí List C ‚Üí C

  concat‚ÇÉ : {M : Monoid‚ÇÉ} ‚Üí let C = Monoid‚ÇÉ.Carrier M  in  List C ‚Üí C

  concat‚ÇÑ : List Monoid‚ÇÑ ‚Üí Monoid‚ÇÑ
#+END_SRC

  An immediate attempt to unify these declarations requires pinpointing exactly
  /which type is referred to semantically by the phrase MonoidP./
  For the ~datatype~ variation, it could only refer to the resulting algebraic data-type;
  whereas for the ~record~ variation, it could refer to the result record type /or/ to
  the ~Carrier~ projection of such record types. Consequently, we use monad-like notation
  ~do œÑ ‚Üê MonoidP; ‚ãØœÑ‚ãØ~ whenever we wish to refer to /values/ of the underlying carrier
  of a particular instantiaiton, rather than referring to the type /of/ such values.
  In particular:

  \vspace{0.3em}
#+BEGIN_SRC agda
  do œÑ ‚Üê MonoidP record; ‚Ñ¨ œÑ    ‚âà  Œª {œÑ : MonoidP record} ‚Üí ‚Ñ¨ (MonoidP.Carrier œÑ)
  do œÑ ‚Üê MonoidP datatype; ‚Ñ¨ œÑ  ‚âà  ‚Ñ¨ (MonoidP datatype)
#+END_SRC
  \vspace{0.3em}
  \noindent
  With this understanding in-hand, we may write /variation polymorphic/ programs:
#+BEGIN_SRC agda
  concatP : {v : Variation}  ‚Üí  do œÑ ‚Üê MonoidP v;  List œÑ ‚Üí œÑ
  concatP []       = MonoidP.Id
  concatP (x ‚à∑ xs) = x ‚®æ concatP xs where _‚®æ_ = MonoidP._‚®æ_
#+END_SRC

  \vspace{0.3em}
  \noindent
  It is important at this juncture to observe that the type of ~concatP~
  depends crucially on the variation ~v~ that is supplied, or inferred.
  This is a prime reason for using a dependently-typed language as the
  setting for the \textsf{\upshape PackageFormer} feature.

* Next Steps
  :Remarks:
  Ignoring the implementation, there are no sound semantics for these constructs.
     Discuss theory presentation combinators and possible extensions.
  :End:

  We have outlined a new unifying language feature that is intended to massively reduce
  duplicated efforts involving different perspectives of datatypes. Moreover, to make
  this tractable we have also provided a novel form of polymorphism and demonstrated
  it with minimal examples.

  We have implemented a meta-program that realises these elaborations in an unobtrusive
  fashion: An Agda programmer simply declares them in special comments.
  The resulting ‚Äòeditor tactic‚Äô demonstrates that this language feature is promising.

  Thus far we have relied on the reader's understanding of functional programming and
  algebraic data types to provide an informal and indirect semantics by means of
  elaborations into existing notions. An immediate next step would be to provide
  explicit semantics for \textsf{\upshape PackageFormer}'s within a minimal type theory.
  Moreover there are a number of auxiliary goals, including:

  1. How do users extend the built-in ~Variations~ type along with the intended
     elaboration scheme.

     One possible route is for a user to ‚Äòinstall‚Äô a new variation by specifying
     where the separation line between parameters and fields happens; e.g.,
     by providing a function such as ~List Constituent ‚Üí Pair (List Constituent)~,
     which may introduce new names, such as the aforementioned ~Carrier~ and ~Vars.~

  2. Explain how generative modules are supported by this scheme, and they indeed are.

  3. Demonstrate how tedious boilerplate code for renamings, hidings, extensions,
     and the flattening of hierarchical structures can be formed.

  4. How do multiple default, or optional, clauses for a constituent fit into this
     language feature. This may necessitate a form of limited subtyping.

  5. Discuss inheritance, coercion, and transport along canonical isomorphisms.

  6. Flexible polymorphic definitions: One should be able to construct a program
     according to the most convenient presentation, but be able to have it
     /automatically/ applicable to other instantiations.

     For example, the ~concat~ function was purely syntactic and the easiet formulation
     uses the algebraic data-type rendeition, whence one would write \newline
     ~concat : List MonoidP datatype ‚Üí MonoidP datatype~ \newline
     and the variation is found then systematically generalised to obtain \newline
     ~concatP : {v : Variation}  ‚Üí  do œÑ ‚Üê MonoidP v;  List œÑ ‚Üí œÑ~. \newline
     When there are multiple variations mentioned, the problem becomes less clear cut
     and the simplest solution may be to simply indicate which variation or occurrences
     thereof is intended to be generalised.

  Finally, the astute reader will have remembered that our abstract mentions graphs yet
  there was no further discussion on that example. Indeed, one of the next goals is to
  accommodate multi-sorted structures where sorts may /depend/ on one another, as edge-sets
  depend on the vertex-set chosen.

  There are many routes to progress on this fruitful endeavour.

  We look forward to this feature reducing the length of our code
  and alleviating us of tedious boilerplate constructions.

* COMMENT acmart Emacs setup
#+NAME: make-acmart-class
#+BEGIN_SRC emacs-lisp :results none
(with-eval-after-load "ox-latex"
   (add-to-list 'org-latex-classes
        '("acmart" "\\documentclass{acmart}"
          ("\\section{%s}" . "\\section*{%s}")
          ("\\subsection{%s}" . "\\subsection*{%s}")
          ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
          ("\\paragraph{%s}" . "\\paragraph*{%s}")
          ("\\subparagraph{%s}" . "\\subparagraph*{%s}"))))
#+END_SRC

* COMMENT other ideas

What about some context at the beginning of the first paragraph?

What does the term bundling refer to, bundling of what? and what kind of data exposure is a problem?
Suggestion (just an example of sth you can do), mention a record type (or something else) as a way of bundling, and explain that data exposure means what fields are exposed. I believe that is what you mean with type and value levels?

  ----other ideas----

  # We design and implement a language feature that allows both the library designer and user to make this choice as necessary.

  # True, but relevant?
  The more information known statically, the less arbitrary choices that need to be performed
  by inspecting data at runtime ---e.g., what to do when list elements, say in Java, differ
  or when list lengths, say in Haskell, differ when computing a dot product.
  However, it is not clear how much information exposure is ideal.

  For example, more exposure at the parameter or type-index level enforces too many constraints
  ---as in considering graphs /over/ a particular vertex set versus the type of graphs over an arbitrary
  vertex set. It thus appears that the context dictates which level of exposure is most appropriate.
  #
  # This definitely belongs in your abstract, but needs to be attached to something more concrete.
  #
  The traditional approach is to reduplicate utility functions or provide conversions between the few supported
  perspectives.
  Our proposed language feature will allow the library designer, and user, to make this choice only when necessary
  and otherwise leave the ‚Äòbelt line‚Äô between parameters and fields unspecified.

  To demonstrate the practicality of this feature, we have produced a prototype for the Agda language.
  After loading it, Agda users may employ special comments from which legitimate Agda code is automatically generated
  as users step-wise program.

* COMMENT old Abstract and toc                                               :ignore:
:PROPERTIES:
:CUSTOM_ID: abstract
:END:

# Use:  x vs.{{{null}}} ys
# This informs LaTeX not to put the normal space necessary after a period.
#
#+MACRO: null  @@latex:\null{}@@

#+begin_center
*Abstract*
#+end_center
#+begin_small
  Programming languages with sufficiently expressive type theories provide users with essentially two
  levels of data ‚Äòbundling‚Äô. One may expose important constituents at the type level or have them
  hidden at the value level. Alternatively put, which information is exposed dynamically at runtime and which is known
  statically. Rather than force a user to commit to a choice, we propose a language feature that allows such
  choices to be determined whenever is convenient for the task at hand.

  The more information known statically, the less arbitrary choices that need to be performed
  by inspecting data at runtime ---e.g., what to do when list elements, say in Java, differ
  or when list lengths, say in Haskell, differ when computing a dot product.
  However, it is not clear how much information exposure is ideal.
  For example, more exposure at the parameter or type-index level enforces too many constraints
  ---as in considering graphs /over/ a particular vertex set versus the type of graphs over an arbitrary
  vertex set. It thus appears that the context dictates which level of exposure is most appropriate.
  The traditional approach is to duplicate utility functions or provide conversions between the few supported
  perspectives.
  Our proposed language feature will allow the library designer, and user, to make this choice only when necessary
  and otherwise leave the ‚Äòbelt line‚Äô between parameters and fields unspecified.

  To demonstrate the practicality of this feature, we have produced a prototype for the Agda language.
  After loading it, Agda users may employ special comments from which legitimate Agda code is automatically generated
  as users step-wise program.
#+end_small
# \newpage
# \thispagestyle{empty}
# \tableofcontents
# \newpage

* COMMENT Introduction

  Programming languages with sufficiently expressive type theories provide users with essentially two
  levels of data ‚Äòbundling‚Äô. One may expose important constituents at the type level or have them
  hidden at the value level. Alternatively put, which information is exposed dynamically at runtime and which is known
  statically. Rather than force a user to commit to a choice, we propose a language feature that allows such
  choices to be determined whenever is convenient for the task at hand.

  For example, consider the dot-product $\Sigma_{i = 0}^n x_i \cdot y_i$ operation.
  It is unreasonable to have this as an operation of $2 \cdot n$ many numbers, instead of such a primitive type
  we may utilise the richer structure of vectors. Now what is the type of a vector ---is it ~Vec ‚Ñù n, Vec ‚Ñù,~ or just ~Vec~?
  That is, how much information is exposed at the type level and how much is hidden at the component value level.
  In the programming setting, nullary ~Vec~ may correspond to lists whose type is only known at runtime,
  whereas ~Vec ‚Ñù~ corresponds to lists of real numbers yet  the list length is known as run time, whereas
  ~Vec ‚Ñù n~ corresponds to lists of real numbers where the list length is statically known to be ~n~.

  Languages without sufficient support for polymorphism, such as old versions of Java, can only provide the nullary
  ~Vec~ form. The check that all the constituents are of the same type transpires at runtime, which necessities a decision
  of what is done when elements differ ---throwing an exception is common.
  In contrast, languages with elegant polymorphism support, such as Haskell, would have the element type pre-determined
  leaving the choice of what to do when vector lengths differ ---ignoring extra elements is common.
  Yet in dependently-typed languages, such as Agda, one can select either format or, better yet, have the length information
  at the type level. /The more information known statically, the less arbitrary choices that need to be performed./

  However, it is not clear how much information exposure is ideal.
  For example, when the type of elements is exposed we can easily form the dot-product
  and it would be awkward to phrase it otherwise. Perhaps a demonstration will clarify this further.
  {{{code(Typing the dot-product using different vector perspectives)}}}
  #+BEGIN_SRC agda
  data Vec (carrier : Set) (length : ‚Ñï) : Set where
    []  : Vec carrier 0
    _‚à∑_ : ‚àÄ {length : ‚Ñï}
      ‚Üí carrier ‚Üí Vec carrier length ‚Üí Vec carrier (length + 1)

  record Vec‚Ä≤ (carrier : Set)  : Set (‚Ñìsuc ‚Ñìzero) where
    field
      length   : ‚Ñï
      elements : Vec carrier length

  record Vec‚Ä≥ : Set (‚Ñìsuc ‚Ñìzero) where
    field
      carrier  : Set
      length   : ‚Ñï
      elements : Vec carrier length

   dot : ‚àÄ {n} (xs ys : Vec ‚Ñù n) ‚Üí ‚Ñù
   dot = ‚ãØ

   dot‚Ä≤ : (xs ys : Vec‚Ä≤ ‚Ñù) ‚Üí length xs ‚â° length ys ‚Üí ‚Ñù
   dot‚Ä≤ = ‚ãØ

   dot‚Ä≥ : (xs ys : Vec‚Ä≥)	‚Üí carrier xs ‚â° ‚Ñù  ‚Üí carrier ys ‚â° ‚Ñù
    ‚Üí length xs ‚â° length ys ‚Üí ‚Ñù
   dot‚Ä≥ = ‚ãØ
  #+END_SRC
  The more exposed data, the easier it is to type the dot-product.
  However, more exposure is not always ideal. For example, suppose we are interested
  is discussing the ubiquitous category ~ListSet~ whose objects are lists over some carrier set
  and whose morphisms are functions between the carrier sets. The type of objects cannot be
  ~Vec~ nor ~Vec‚Ä≤~ since they /enforce too many constraints/, instead it must be ~Vec‚Ä≥~.
  Hence, there is not best choice but it is contextual use that determines which presentation
  is most fitting. Are we then forced to re-duplicate the ~dot~ code for each level of exposure?
  Our proposed language feature suggests otherwise: /Write once, obtain many!/

  Interestingly, we can go so far as to form ~Vec ‚Ñù n xs~ to be the type consisting of a single formal value
  when ~xs~ is a list /and/ its constituents are of type ‚Ñù /and/ the list length is ~n~; and to have no value otherwise.
  This is, for nearly all uses, overkill; yet it begs the question /where is the line between parameters and component fields?/
  Traditionally, a library designer would make this choice and may provide views for the other perspectives.
  Our proposed language feature will allow the library designer, and user, to make this choice only when necessary
  and otherwise leave the ‚Äòbelt line‚Äô between parameters and fields unspecified.

  To demonstrate the practicality of this feature, we have produced a prototype for the Agda language.
  After loading it, Agda users may employ special comments from which legitimate Agda code is automatically generated
  as users step-wise program.

* COMMENT Preamble & title page :ignore:

# Top level editorial comments.
#+MACRO: remark  @@latex: \fbox{\textbf{Comment: $1 }}@@

#+LATEX_CLASS: acmart
# Defined below.

** ~acmart~ LaTeX Class                                            :noexport:

A custom version of the reports class which makes the outermost headings chapters, rather than parts.
#+NAME: make-acmart-class
#+BEGIN_SRC emacs-lisp :results none
(with-eval-after-load "ox-latex"
   (add-to-list 'org-latex-classes
        '("acmart" "\\documentclass{acmart}"
          ("\\section{%s}" . "\\section*{%s}")
          ("\\subsection{%s}" . "\\subsection*{%s}")
          ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
          ("\\paragraph{%s}" . "\\paragraph*{%s}")
          ("\\subparagraph{%s}" . "\\subparagraph*{%s}"))))
#+END_SRC

** Minted setup -- colouring code blocks                            :ignore:

#+LATEX_HEADER: \usepackage[]{minted}
#+LATEX_HEADER: \usepackage{tcolorbox}
#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \def\mytitle{??? Program Code ???}
#+LATEX_HEADER: \BeforeBeginEnvironment{minted}{\begin{tcolorbox}[title=\hfill \mytitle]}%
#+LATEX_HEADER: \AfterEndEnvironment{minted}{\end{tcolorbox}}%

# Before a code block, write {{{code(title-of-block)}}}
#
#+MACRO: code     #+LaTeX: \def\mytitle{$1}

#+LaTeX: \setminted[haskell]{fontsize=\footnotesize}
#+LaTeX: \setminted[agda]{fontsize=\footnotesize}

# Removing the red box that appears in "minted" when using unicode.
# Src: https://tex.stackexchange.com/questions/343494/minted-red-box-around-greek-characters
#
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \AtBeginEnvironment{minted}{\dontdofcolorbox}
#+LATEX_HEADER: \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
#+LATEX_HEADER: \makeatother
** LaTeX setup                                                      :ignore:

# Hijacking \date to add addtional text to the frontmatter of a ‚Äòreport‚Äô.
#
#
# DATE: \today\vfill \centerline{---Supervisors---} \newline [[mailto:carette@mcmaster.ca][Jacques Carette]] and [[mailto:kahl@cas.mcmaster.ca][Wolfram Kahl]]

#+LATEX_HEADER: \usepackage[hmargin=25mm,vmargin=25mm]{geometry}
#+LaTeX_HEADER: \setlength{\parskip}{1em}
#+latex_class_options: [12pt]
# LATEX_CLASS: report-noparts
# Defined below.
#
# Double spacing:
# LaTeX: \setlength{\parskip}{3em}\renewcommand{\baselinestretch}{2.0}
#
#+LATEX_HEADER: \setlength{\parskip}{1em}

#+LATEX_HEADER: \usepackage[backend=biber,style=alphabetic]{biblatex}
#+LATEX_HEADER: \addbibresource{MyReferences.bib}

#+LATEX_HEADER: \usepackage{../MyUnicodeSymbols/MyUnicodeSymbols}
#+LATEX_HEADER: \newunicodechar{‚Ñì}{\ensuremath{\ell}}
#+LATEX_HEADER: \newunicodechar{‚Ñù}{\ensuremath{\mathop{\mathbb{R}}}}
#+LATEX_HEADER: \newunicodechar{‚Ä≥}{''}
#+LATEX_HEADER: \newunicodechar{‚®æ}{\ensuremath{\mathop{\fatsemi}}}
#+LATEX_HEADER: \newunicodechar{Œ£}{\ensuremath{\mathop{\Sigma}}}
#+LATEX_HEADER: \newunicodechar{‚àò}{\ensuremath{\mathop{\circ}}}
#+LATEX_HEADER: \newunicodechar{Œì}{\ensuremath{\Gamma}}
#+LATEX_HEADER: \newunicodechar{Œ†}{\ensuremath{\Pi}}
#+LATEX_HEADER: \newunicodechar{Œò}{\ensuremath{\theta}}
#+LATEX_HEADER: \newunicodechar{‚àé}{\ensuremath{\qedsymbol}}
#+LATEX_HEADER: \newunicodechar{‚Ä≤}{'}
#+LATEX_HEADER: \newunicodechar{œÑ}{\ensuremath{\tau}}
#+LATEX_HEADER: \newunicodechar{‚¶É}{\ensuremath{ \{\{ }}  % this is not correct
#+LATEX_HEADER: \newunicodechar{‚¶Ñ}{\ensuremath{ \}\} }}   % this is not correct
#+LATEX_HEADER: \newunicodechar{‚äé}{\ensuremath{\cupdot}}  % should be in myunicode; go #regenerate# it!
#+LATEX_HEADER: \def\with{\kern0.7em \withrule \kern0.7em }
#+LATEX_HEADER: \def\withrule{\vrule height1.57ex depth0.43ex width0.12em}
#+LATEX_HEADER: \newunicodechar{‚ùô}{\ensuremath{\mathop{\with}}}

#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor} % named colours
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \definecolor{darkred}{rgb}{0.3, 0.0, 0.0}
#+LATEX_HEADER: \definecolor{darkgreen}{rgb}{0.0, 0.3, 0.1}
#+LATEX_HEADER: \definecolor{darkblue}{rgb}{0.0, 0.1, 0.3}
#+LATEX_HEADER: \definecolor{darkorange}{rgb}{1.0, 0.55, 0.0}
#+LATEX_HEADER: \definecolor{sienna}{rgb}{0.53, 0.18, 0.09}
#+LATEX_HEADER: \hypersetup{colorlinks,linkcolor=darkblue,citecolor=darkblue,urlcolor=darkgreen}

#+NAME: symbols for itemisation environment
#+BEGIN_EXPORT latex
\def\labelitemi{$\diamond$}
\def\labelitemii{$\circ$}
\def\labelitemiii{$\star$}

% Level 0                 Level 0
% + Level 1               ‚ãÑ Level 1
%   - Level 2       --->      ‚àò Level 2
%     * Level 3                   ‚ãÜ Level 3
%
#+END_EXPORT

# Having small-font code blocks.
# LATEX_HEADER: \RequirePackage{fancyvrb}
# LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}

** COMMENT ~reports-noparts~ LaTeX Class                                    :noexport:

A custom version of the reports class which makes the outermost headings chapters, rather than parts.
#+NAME: make-reports-class
#+BEGIN_SRC emacs-lisp :results none
(add-to-list
  'org-latex-classes
    '("report-noparts"
      "\\documentclass{report}"
      ("\\chapter{%s}" . "\\chapter*{%s}")
      ("\\section{%s}" . "\\section*{%s}")
      ("\\subsection{%s}" . "\\subsection*{%s}")
      ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
      ("\\paragraph{%s}" . "\\paragraph*{%s}")
      ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+END_SRC

Source: Mark Armstrong --github ~armkeh~
** COMMENT Personal title page                                              :ignore:

#+begin_center org

#+begin_export latex
\thispagestyle{empty}

{\color{white}{.}}

\vspace{5em}

{\Huge The Next 700 Module Systems}

\vspace{1em}

{\Large Extending Dependently-Typed Languages to Implement
\\ Module System Features In The Core Language}

\vspace{2em}

Department of Computing and Software

McMaster University

\vspace{2em}
\href{mailto:alhassy@gmail.com}{Musa Al-hassy}

\vspace{2em}
\today
#+end_export

\vfill

{{{code({\sc Thesis Proposal \hspace{12em} \color{grey}{.} })}}}
#+begin_src haskell
-- Supervisors                                       -- Emails
Jacques Carette                                      carette@mcmaster.ca
Wolfram Kahl                                         kahl@cas.mcmaster.ca
#+end_src
#+end_center

# LaTeX: \centerline{\sc Draft}

* COMMENT Preliminary Research

The homogeneous treatment of structuring mechanisms is herein presented using a prototype
developed using the user-friendly Emacs application framework by means of textual expansion,
the details of which are largely uninteresting ---suffice it to say, the code is tremendously terse.
In this section we demonstrates that packaging concepts differ only in their use, leading to a uniform
syntax of which first-class records are an instance and so the resulting system is homoiconic in nature.
We introduce fictitious syntax, mostly in red, with its intended Agda elaboration in blue
---the users write the red and expect it to behave like the blue; no ‚Äúcode generation‚Äù transpires.

The reader is advised to remember that the value of a prototype is in the guidance it provides,
not the implementation itself nor any of its design decisions ---such as using strings in meta-programming
scenarios. In other words, for the reader, portions of this section may serve as an exercise in foresight and patience.
( A brief demonstration of the prototype may be viewed at https://www.youtube.com/watch?v=NYOOF9xKBz8 .)

:Minimality:
A prime guiding design decision is
/try to avoid making any decisions, including unconscious restrictions, unless deemed necessary!/
:End:

The initiated reader will quickly notice that our package formers are just theory presentations
---a list of name-type pairs. The chosen phrasing is due to the target audience, DTL programmers.
We are not committed to the name, but unlike the overloaded ‚Äòmodule‚Äô, ‚Äòpackage former‚Äô is a good
new name without too many meanings. We have not provided full semantics for package formers, but
we have provided concrete well-defined elaborations to communicate the intent: A package former
is akin to a type former, it is ‚Äòincomplete‚Äô and does not define a concrete package until a certain
tag is provided.
It is part of the thesis effort to investigate which features of our proposed package formers
break, or become limited, when considered with other language constructs.

The uniformity in syntax reduces the variety of sub-languages in a dependently-typed language
by eliminating needless distinctions for notions of containers. The first subsection below
addresses syntactic similarity, whereas the second tackles computing similarity,
and we conclude with a brief discussion on foundational concerns.

*** First Observation: Syntactic Similarity for Containers

Since the prototypical notion of packaging is that of records,
which are value terms, all, necessarily succeeding, notions of packaging
ought to be treated uniformly as value types.
Consequently, variations on packaging should only be signalled by necessary
keywords, and otherwise should be syntactically indistinguishable.
That is to say, a ‚Äòvariation‚Äô is a tag identifying what particular
form of module is desired, such as ~datatype~ for an algebraic data type
with the declared fields as constructors, or as ~record~ to yield a record structure
with constituents being the declared fields.

For example, just as ~List~ is a type-former, we may declare a ‚Äòpackage former‚Äô:
{{{code(Our first package former)}}}
#+begin_src haskell
 PackageFormer TermP (v : Variation) : Set where
    Var : Int ‚Üí TermP v
    Add : TermP v ‚Üí TermP v ‚Üí TermP v
 #+end_src

Note that a package former is just a sequence of names with types and,
as will be demonstrated later, optional default types.
It requires a particular ‚Äúinterpretation‚Äù ---possibly user-defined---,
to produce some notion of package. This is signalled by the ~Variation~
type, which for brevity contains ~data, record, typeclass~, and a few more
that we will meet below.

For example, the ~data~ variation of packaging gives us a
free data type.
{{{code(Free data type: Terms are integer variables and addition of terms)}}}
#+begin_src haskell
TermData = TermP data
{-
‚âÖ  data TermData : Set where
     Var : Int ‚Üí TermData
     Add : TermData ‚Üí TermData ‚Üí TermData
-}
#+end_src
In the comment above, we indicate how our fictitious syntax is intended to be elaborated
into current Agda syntax. Besides syntax, induction principles are also derived:
Our envisioned system would be able to derive simple, tedious, uninteresting concepts;
leaving difficult, interesting, ones  for humans to solve.
For this type, below is the dependently typed eliminator, which in a DTL, corresponds to an induction
principle.
{{{code(Free data types also come with an induction principle)}}}
#+begin_src haskell
{-
   term-data-elim : ‚àÄ {‚Ñì} {R : TermData ‚Üí Set ‚Ñì}
          ‚Üí (base : (n : Int) ‚Üí R (Var n))
          ‚Üí (ind  : ‚àÄ {s t} ‚Üí R s ‚Üí R t ‚Üí R (Add s t))
          ‚Üí (t : TermData) ‚Üí R t

   term-data-elim base ind (Var n)   = base n
   term-data-elim base ind (Add s t) = ind rs rt
      where rs = term-data-elim base ind s
        rt = term-data-elim base ind t
-}
#+end_src

The type of the package former, for now, could simply be ~Set~
---c.f., the commented-out elaboration which declares ~TermData ‚à∂ Set~.
However, if we permit a sufficiently small subtyping system, we
may find it desirable to have the type of a package former be itself
a package former! Moreover, if package former ~t~ has type package former ~t‚Ä≤~,
then the user should be able to use ~t~ at the levels ~t ‚à∂ s~
without too much overhead, where ~s~ is any subtype of ~t~ with ~Set~ being a minimal
such subtype. These thoughts are hurried and it is the purpose of the thesis
to investigate what is the appropriate route.

It is often the case that one begins working with a ~record~ of useful semantic
data, but then, say, for proof automation, may want to use the associated ~datatype~
for syntax. The latter should be mechanically derivable, and this is what we aim
provide with our package formers.
We will not delve into the relationship between free data types and how, for example,
their associated catamorphism is necessarily also an interpreter
---in the programming languages sense.
The reader is invited to consult a reference \parencite{cats_logic_shulman}.

We shall not discuss polymorphism along variations, the ~v~ components above,
as it is orthogonal to our immediate goals. For example, ~TermP~ could have a field typed
\newline \texttt{TermP (f v) ‚Üí TermP (g v) ‚Üí TermP v},
where ~f~ and ~g~ are operations on variations.
Nonetheless, this is a feature that one should be aware of.

The remaining items instantiate package formers for the usual
common uses. Including notions of records in item 1;
an algorithmic sketch underlying the examples of item 1 is presented in item2;
union types and external, second-class, modules in item 3;
package former polymorphism in item 4;
operating on package formers and inheritance in items 5 and 6; then discuss
how package formers handle the diamond problem in item 7.
Finally, we close in item 8 by discussing a problem not generally found
in pedestrian languages and how it is solved using package formers.

**** The Generality of Package Formers ---Products

To demonstrate the generality of the notion of package formers we shall demonstrate
how other common forms could be ‚Äòderived‚Äô from the single declaration above.
It is to be noted that for such a small example, such derived code may be taken for
granted, however for much larger theories ---for example, a ‚Äúfield‚Äù comes with more than
20 fields--- the ability to derive different perspectives in a consistent fashion
is indispensable; especially when the package is refactored.
More realistically, a symmetric rig groupoid uses about 212 coherence laws \parencite{rig_computation},
for which case-splitting, to perform proofs, yields [[https://github.com/JacquesCarette/pi-dual][over 200 goals]] thereby making
metaprogramming a tempting approach.

:counting_field_componenets:
field ‚âÖ ablean group ‚ü∂ Carrier, op, inv, unit, assoc, 2 unit-laws, 2 inverse-laws, comm-law ‚ü∂ 10 laws
      multiplicative monoid ‚ü∂ Carrier, op, unit, assoc, 2 unit-laws ‚ü∂ 6 laws
      the above two carries are identical  ‚ü∂ 1 law
      distributively laws   ‚ü∂ 2 laws
      integrity & div-op & non-zero division ‚ü∂ 3 laws

Total ‚ü∂ 22 laws
:end:

# {{{code(Records; a magma with the integers)}}}
{{{code(Records)}}}
#+begin_src haskell
-- An instance of  TermRecord should have a carrier type
-- containing the integers, ‚ÄòVar‚Äô, and supports some binary operation, ‚ÄòAdd‚Äô.
TermRecord = TermP record
{-
‚âÖ   record TermRecord  : Set where
      field
    Carrier : Set
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier
-}
#+end_src
In the previous  and following invocations, the name ~Carrier~ is a system internal, for now,
and can easily be ~renamed~ ---as will be demonstrated later on.
For now, we adhere to a single-sorted stance: Unless indicated otherwise, a ~Carrier~ will always
be included. An example of a two-sorted algebraic structure, graphs, is demonstrated at the end of this subsection.

Built-in names, such as ~Carrier~, are generally not ideal. For example, a machine may provide the
names ~FourLeggedFeline~ and ~CommutativeIdempotentMonoid~ where a human may prefer ~Cat~ and ~JoinSemilattice~ instead.
As such, the resulting system, would accept ‚Äòrenaming‚Äô functions to generate names. For now, we mostly limit
such an approach for brevity.

{{{code(Haskell-style typeclasses ---or Scala-like traits)}}}
#+begin_src haskell
TermOn = TermP typeclass
{-
‚âÖ   record TermOn (Carrier : Set) : Set where
      field
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier
-}
#+end_src
{{{code(A pair of functions \emph{on} a declared carrier type)}}}
#+begin_src haskell
TermFunctionsOn = TermP tuples
{-
TermFunctionsOn : Set ‚Üí Set
TermFunctionsOn C = (Int ‚Üí C) √ó (C ‚Üí C ‚Üí C)
-}
#+end_src
{{{code(Or the carrier is existential)}}}
#+begin_src haskell
TermFunctions = TermP Œ£
-- ‚âÖ  TermFunctions  =  Œ£ C ‚à∂ Set  ‚Ä¢  Œ£ Var : Int ‚Üí C  ‚Ä¢  (C ‚Üí C ‚Üí C)
#+end_src

Let's show a more intricate yet desirable use.
{{{code(The interface of non-empty lists, with a dedicated list)}}}
#+begin_src haskell
PointedSemigroup = TermP record hiding (Var) renaming (Add to _‚®æ_)
             field
               Id     : Carrier
               ‚®æ-assoc : ‚àÄ x y z ‚Üí x ‚®æ (y ‚®æ z) ‚â° (x ‚®æ y) ‚®æ z
{-
‚âÖ   record PointedSemigroup  : Set‚ÇÅ where
      field
    Carrier : Set
    _‚®æ_     : Carrier ‚Üí Carrier ‚Üí Carrier
    Id      : Carrier
    ‚®æ-assoc : ‚àÄ x y z ‚Üí x ‚®æ (y ‚®æ z) ‚â° (x ‚®æ y) ‚®æ z
-}
#+end_src

**** Algorithmically Obtaining Elaborated Types
We have discussed how the generic package formers elaborate
---each blue comment indicates a standalone isomorphic Agda rendition---,
as such it should be unsurprising that the constituents of a package former
are dependently typed functions /consuming/ each concrete variation in
its traditional fashion. Let's clarify this idea further.

{{{code(Our example package former)}}}
#+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
   Var : Int ‚Üí TermP v
   Add : TermP v ‚Üí TermP v ‚Üí TermP v
#+end_src

The ‚Äòtype‚Äô of the first item, for example, is as follows
---where ~TermP v~ is rewritten using the above introduced names
for the sake of clarity.
{{{code(The types of a constituents of a package former)}}}
#+begin_src haskell
Var : (v : Variation) ‚Üí Set

{- Datatype constructor -}
Var datatype   =  Int ‚Üí TermData
{- Dependent projection -}
Var record     =  (œÑ : TermRecord) ‚Üí Int ‚Üí TermRecord.Carrier œÑ
Var Œ£          =  (œÑ : TermFunctions) ‚Üí Int ‚Üí proj‚ÇÅ œÑ
{- Parameter of a constraint -}
Var typeclass  =  ‚àÄ{C} {{_ : TermOn C}} ‚Üí Int ‚Üí C
Var tuples     =  ‚àÄ{C} ‚Üí TermFunctionsOn C ‚Üí Int ‚Üí C
‚ãØ
#+end_src

An initial glance suggests that this is all ad-hoc; let us demonstrate that
this is not the case. Suppose there were a method ~ùíØ~ to obtain the user-provided types of
constituents; e.g., the given ~Var ‚à∂ Int ‚Üí TermP v~ is indistinguishable from \newline  ~Var ‚à∂ ùíØ ‚ÄúVar‚Äù (TermP v)~.
{{{code( Obtaining User-Provided Types ---Under the hood )}}}
#+begin_src haskell
Constituent = String -- Draft idea, not ideal.

-- ‚ÄúA ‚ü®n‚ü©‚Üí B  ‚âà  A ‚Üí ‚ãØ ‚Üí A ‚Üí B‚Äù with n-many A's.
_‚ü®_‚ü©‚Üí_ : Set ‚Üí ‚Ñï ‚Üí Set ‚Üí Set
A ‚ü® zero   ‚ü©‚Üí B  =  B
A ‚ü® succ n ‚ü©‚Üí B  =  A ‚Üí (A ‚ü® n ‚ü©‚Üí B)

-- Constituents of package formers give rise to ‚ÄúSet ‚ü®n‚ü©‚Üí Set‚Äù functions.
ùíØ : {P : PackageFormer} ‚Üí Constituent P ‚Üí Set ‚ü® arity P ‚ü©‚Üí Set
ùíØ ‚ÄúVar‚Äù X  =  Int ‚Üí X
ùíØ ‚ÄúAdd‚Äù X  =  X ‚Üí X ‚Üí X
#+end_src
It is now trivial to reify the above prescription for ~Var~ in a uniformly fashion
---namely, ~Var = ùìâùìéùìÖùíÜ ‚ÄúVar‚Äù~.
{{{code( Providing User-Facing Types ---Under the hood )}}}
#+begin_src haskell
ùìâùìéùìÖùíÜ : Constituent ‚Üí Variation ‚Üí Set
ùìâùìéùìÖùíÜ c v@datatype  = ùíØ c (TermP v)
ùìâùìéùìÖùíÜ c v@record    = (œÑ : TermP v) ‚Üí ùíØ c ((TermP v).Carrier œÑ)
ùìâùìéùìÖùíÜ c v@Œ£         = (œÑ : TermP v) ‚Üí ùíØ c (proj‚ÇÅ œÑ)
ùìâùìéùìÖùíÜ c v@typeclass = ‚àÄ{C} {{_ : TermP v C}} ‚Üí ùíØ c C
ùìâùìéùìÖùíÜ c v@tuples    = ‚àÄ{C} ‚Üí TermP v C ‚Üí ùíØ c C
‚ãØ
#+end_src
For example, invoking this approach we find that ~Add~, on ~TermRecord~'s, is typed \newline
~ùìâùìéùìÖùíÜ ‚ÄúAdd‚Äù record~, which may be rewritten as \newline
~(œÑ ‚à∂ TermRecord) ‚Üí TermRecord.Carrier œÑ ‚Üí TermRecord.Carrier œÑ ‚Üí TermRecord.Carrier œÑ~.
That is, as expected, ~Add~ on records consumes a record value then acts as a binary
operation on the carrier of said record value. Likewise, we invite the reader
to check that ~Add~ on algebraic datatype ~TermData~ is typed as a binary constructor.

Users have access to the elaborated types.
{{{code(Providing User-Facing Types)}}}
#+begin_src haskell
 TermP.Var : ‚àÄ{v} ‚Üí ùìâùìéùìÖùíÜ ‚ÄúVar‚Äù v
 TermP.Add : ‚àÄ{v} ‚Üí ùìâùìéùìÖùíÜ ‚ÄúAdd‚Äù v
#+end_src
This is particularly useful when one wants to extract such types for re-use elsewhere.
{{{code(Extracting a single ---possibly complicated--- signature)}}}
#+begin_src haskell
ListBop = TermP.Add datatype ‚àò List
{-
‚âÖ  ListBop : Set ‚Üí Set
   ListBop C = (List C ‚Üí List C ‚Üí List C)
-}

ConstrainedBop : (Set ‚Üí Set) ‚Üí Set
ConstrainedBop constraint  = TermP.Add typeclass using constraint
{-
‚âÖ ConstrainedBop constraint  =  ‚àÄ{C} ‚Üí constraint C ‚Üí C ‚Üí C ‚Üí C

-- N.B., this would not elaborate without the ‚Äúusing‚Äù.
-- Semantically, ‚ÄúP.x y using z = (P.x y)[P v ‚âî z]‚Äù
-- ‚îÄthe ‚Äúv‚Äù appears from ‚Äú‚àÄ{v}‚Äù above.
-}

SetoidBop = TermP.Add record using Setoid
{-
‚âÖ SetoidBop : Setoid ‚Ñì‚ÇÄ ‚Ñì‚ÇÄ ‚Üí Set
  SetoidBop S = Setoid.Carrier C ‚Üí Setoid.Carrier C ‚Üí Setoid.Carrier C

-- N.B., this would not elaborate if ‚ÄúSectoid.Carrier‚Äù were undefiend.
-}
#+end_src
These examples open a flurry of problems.

At this stage, it is sufficient to have observed what could possibly
be performed and that it is not without burden.
We will not attempt to clarify any problem nor propose any solution;
the thesis effort will contend with these matters further.

**** The Generality of Package Formers ---Sums & Modules

Thus far we have only discussed products; however
the proposed general notion of containers should also produce sum types
and be used in modules ---which are just packages.
{{{code(At ‚Äúleast one‚Äù of the operations is desired on a declared carrier type)}}}
#+begin_src haskell
TermFunctionsSumOn = TermP sum
-- ‚âÖ  TermFunctionsSumOn C  =  (Int ‚Üí C) ‚äé (C ‚Üí C ‚Üí C)
#+end_src

In general, this yields a disjoint collection of declarations
where each declaration is itself a Œ£ consisting of the context necessary
to ensure that the operations are well-defined.

For modules,
{{{code(Using our package former \emph{within} another package)}}}
#+begin_src haskell
  PackageFormer MyDriver (t : TermP record renaming (Carrier to C)) : Set where ‚ãØ
-- ‚âÖ module MyDriver (t : TermRecord[Carrier ‚âî C]) where ‚ãØ
-- ‚âÖ module MyDriver (C : Set) (Var : Int ‚Üí C) (Add : C ‚Üí C ‚Üí C) where ‚ãØ
#+end_src
At least two ‚Äòfree‚Äô invocation notations ought to be supplied:
1. ~MyDriver t~
2. ~MyDriver type varOp addOp~

Multifaceted invocations provide a common use case: No overhead to pack or unpack
the constituents of a type former so the sole purpose of an invocation.
However, the pragmatic feasibility of such an approach is unclear at this stage.

**** Novel Genericity: ‚ÄòPackage Polymorphism‚Äô

We have a sufficient number of elaborations thus far to demonstrate
that the notion of package formers is not without merit.
It is now an appropriate moment to address an elephant in the room:
/The phrase ~TermP v~ semantically refers to which type?/

If ~v = datatype~ then ~TermP v~
refers to the associated algebraic datatype.
If ~v = record~, then there are at least two ways to interpret ~TermP v~:
As either the record type or as the carrier of a record value.
Likewise for other variations. For now, we settle with a monadic-like interpretation:
We write ~do œÑ ‚Üê TermP v; ‚ãØ~ whenever we wish to refer to the underlying carrier of a concrete
package former. Loosely put,
{{{code(Syntax ---Under the hood )}}}
#+begin_src haskell
do œÑ ‚Üê TermP v; b  ‚âà  v ‚ï± (Œª œÑ ‚Üí b)

v@datatype  ‚ï± f  =  f (TermP v)
v@record    ‚ï± f  =  ‚àÄ(œÑ : TermP v) ‚Üí f ((TermP v).Carrier œÑ)
v@Œ£         ‚ï± f  =  ‚àÄ(œÑ : TermP v) ‚Üí f (proj‚ÇÅ œÑ)
v@typeclass ‚ï± f  =  ‚àÄ{œÑ} {{_ : TermP v œÑ}} ‚Üí f œÑ
v@tuples    ‚ï± f  =  ‚àÄ{œÑ} ‚Üí TermP v œÑ ‚Üí f œÑ
#+end_src
The ‚Äòover‚Äô notation, ~_‚ï±_~, assumes ~f~ is a function acting on types;
however, this is not necessary, if the ~‚àÄ~ were replaced with ~Œª~, then
the result would be a term expression. This is yet another opportunity for investigation
during the thesis effort. Moreover, there is the possibility of providing
‚Äúimplicit counterparts‚Äù to these variations,; e.g., for ~tuples~ one may want
~‚àÄ{œÑ} {_ ‚à∂ TermP v œÑ} ‚Üí f œÑ~ instead, which could be variation, say, ~tuples-imp~.
Likewise, we may want notation ~do-Œ£~ to replace \newline ~‚àÄ ‚ãØ ‚Üí ‚ãØ~ with ~Œ£ ‚ãØ ‚Ä¢ ‚ãØ~.

Unsurprisingly, this approach subsumes our earlier typing elaboration: \newline
~ùìâùìéùìÖùíÜ c v  = do œÑ ‚Üê TermP v; ùíØ c œÑ~.
More concretely, for example, a notion of ‚Äòdepth‚Äô for terms may have type
~‚àÄ {v} ‚Üí  do œÑ ‚Üê TermP v; (œÑ ‚Üí ‚Ñï)~ ---a function
that takes a package and yields a number.
In the case of ~v = record~, such a function actually takes /two/
items: The first being a record value, the second being an element of
the carrier of that record value. In the case of ~v = typeclass~,
the function takes an argument found by instance search. Likewise,
for the remaining variations.

Let us now turn to an example of a function operating on the above many, and all, variations of such packages.
This example may appear contrived, yet the power of this form of polymorphism
appears at the end of this subsection where one programs towards a /particular/
interface and has the result /generalised/ to other variations
---a prime use case is to code against a typeclass representation and use the
same methods on bundled records.
{{{code(‚ÄúTimes Loop‚Äù: Iterate an action $n$ times. )}}}
#+begin_src haskell
-- Suppose I have the following syntactic construction.
repeat : TermData ‚Üí ‚Ñï ‚Üí TermData
repeat t Zero      =  Var 0
repeat t (Succ n)  =  Add t (repeat t n)

-- Here is its semantic counterpart.
run : (œÑ : TermRecord) ‚Üí TermRecord.Carrier œÑ ‚Üí ‚Ñï ‚Üí TermRecord.Carrier œÑ
run œÑ t Zero      =  TermRecord.Var œÑ 0
run œÑ t (Succ n)  =  TermRecord.Add œÑ t (run œÑ t n)

-- Which is merely multiplication for the naturals.
_√ó_ : ‚Ñï ‚Üí ‚Ñï ‚Üí ‚Ñï
t √ó Zero     = Zero
t √ó (Succ n) = t + (t √ó n)
#+end_src

The first two are instances of a package former, and it is not diffcult to construe the naturals as the carrier of a package former.
After which, we should be able to write one generic function, by writing according to the pacakge former as the interface.
{{{code(‚ÄúTimes Loop‚Äù: Iterate an action $n$ times. )}}}
#+begin_src haskell
instance
  ‚ÑïTerms : TermOn ‚Ñï
  ‚ÑïTerms = record {Var = Œª n ‚Üí 0; Add = _+_}

{- IsConsumer is defined below; ignore for now. -}
exp : ‚àÄ{v} {{_ : IsConsumer v}}  ‚Üí  do œÑ ‚Üê TermP v; œÑ ‚Üí ‚Ñï ‚Üí œÑ
exp t Zero     = Var 0
exp t (Succ n) = Add t (exp t n)
#+end_src
For example, we immediately obtain an instance for strings.
{{{code(‚ÄúTimes Loop‚Äù: Iterate an action $n$ times. )}}}
#+begin_src haskell
instance
  STerms : TermOn (List Char)
  STerms = record {Var = Œª n ‚Üí []; Add = _++_}

repeat-s = exp {v = typeclass}
{- Yields a whole family, which includes:

   repeat-s0 : {{TermOn (List Char)}} ‚Üí List Char ‚Üí ‚Ñï ‚Üí List Char
   repeat-s0 c Zero = []
   repeat-s0 c (Succ n) = c ++ repeat c n
-}
#+end_src

Now that's re-use! One function for many semantically distinct types.
Notice that invoking ~exp~ on ~ListBop~ or ~TermFunctionsSumOn~ values is ill-typed
since the mechanically verifiable constraint ~IsConsumer~ fails for those variations.
Indeed, we may utilise a number of constraints on our package variations, such as
the following.
{{{code(Under the hood constraints)}}}
#+begin_src haskell
data IsConsumer : Variation ‚Üí Set where
  Prod    : IsConsumer tuples
  DepProd : IsConsumer Œ£
  Data    : IsConsumer datatype
  Rec     : IsConsumer record
#+end_src
When a user defines a variation, they can signal whether it is a consumer or not.
Likewise, one can indicate whether a variation should have ~Set~-valued operations
on not. Note that a default mechanism could be implemented, but the user should
continue to have the ability to enforce a particular discipline
---c.f., how ~C#~ allows the user to enforce the subtyping variance of a type former.
{{{code(Under the hood constraints)}}}
#+begin_src haskell
data HasConstructiveRelations : Variation ‚Üí Set where
  Prod    : HasConstructiveRelations tuples
  DepProd : HasConstructiveRelations Œ£
  Rec     : HasConstructiveRelations record
#+end_src
For example, ~data~ declarations cannot contain proofs of an arbitrary, but fixed, constructive relation
without declaring it as a parameter to the type. Nonetheless, a user may want to be
able to express syntactic statements about such proof terms
---say for proof automation--- and they should have the ability to toggle such
a feature.

A more important concern is the type of ~exp~: The phrase ~do œÑ ‚Üê TermP v; œÑ ‚Üí ‚Ñï ‚Üí œÑ~
elaborates to different types according to the value of ~v~, whence to define ~exp~
it seems necessary to actually pattern match on it to obtain a concrete type, which,
for example, may contain more arguments. Case analysis on the possible packaging variations
is far from ideal ---one might as well re-implement the definition only on the cases they
want rather than all cases. The aim ---to be pursued further in the full thesis effort---
is to invert the process: /Avoid case analysis in favour of a particularly convenient view./

This is clarified best by referring to the current prototype language: Lisp.
Since all data and methods in a lisp are essentially lists, when one prescribes
how to project a value from a possibly nested datatype, then the same prescription
essentially directs how to get to the location of that value and so we obtain
/generic setters/. The following tiny example demonstrates this idea.
{{{code(Generic Setters in Lisp)}}}
#+begin_src emacs-lisp
(setq xs '("a" nil (x y z) 12))  ;; Heterogenous list of 4 items.
(cadar (cdaddr xs))              ;; ‚áí y
(setf (cadar (cdaddr xs)) 'woah) ;; xs ‚áí '("a" nil (x woah z) 12))
#+end_src
It is this flexibility that we aim to provide to users.
They code not against a generic variation, but rather along one that
is the most appropriate task at hand. We would hope that it would not
be unrealistic to then mechanically derive the other forms from it.
For example, suppose we wish to define retracts on magmas; rather than
define the concept for each possible view, we define it once and obtain it
for other views.
{{{code(Example Algebra)}}}
#+begin_src haskell
PackageFormer MagmaP (v : Variation) : Set where
  _‚®æ_ : MagmaP v ‚Üí MagmaP v ‚Üí MagmaP v

MagmaOn = MagmaP typeclass
AMagma  = MagmaP record
#+end_src

The ubiquity of magmas ---literally everywhere--- lends itself to recall that
working with structure, possibly needless structure, may usurp the goals of
proof \parencite{purposes_of_proof}: No mathematician would naturally say
/let M be an algebra on set C/ when it suffices to say /let M be an algebra/;
yet it may be /convenient/ to phrase problems more elegantly when the carrier
set is mentioned explicitly \parencite{packaging_mathematical_structures}.
On the other hand,
having the carrier explicit for the sake of typeclass resolution
relies on decidable type (non)equality; which may be resonable for a simplly
typed language but for a DTL type normalisation generally requires non-trivial,
non-constant, computation.
Anyhow, as mentioned earlier, bundling data
is akin to currying or nesting quantifiers, yet is vastly more expensive
since library designers generally commit early to one form or another;
in this case \newline ~AMagma ‚âÖ Œ£ C : Set ‚Ä¢ MagmaOn C~
and \newline
~MagmaOn C ‚âÖ Œ£ M : AMagma ‚Ä¢ M.Carrier ‚â° C~.
{{{code(Example Operation)}}}
#+begin_src haskell
retract : ‚àÄ{S T} ‚Üí (f : S ‚Üí T) ‚Üí MagmaOn T ‚Üí MagmaOn S
retract f Tgt = record {_‚®æ_ = Œª x y ‚Üí f x ‚®æ f y} where open MagmaOn Tgt
#+end_src
Since ~MagmaOn = MagmaP v~ where ~v = typeclass~, we would ideally be able
to derive the generic form ---possibly via case analysis.
{{{code(Variation Generalisation)}}}
#+begin_src haskell
retract-v : ‚àÄ{v}
      ‚Üí ‚àÄ {S T} (f : S ‚Üí T)
      ‚Üí  do   tgt ‚Üê MagmaP v; tgt ‚â° T  -- Intentionally no parens.
      ‚Üí (do-Œ£ src ‚Üê MagmaP v; src ‚â° S)
retract-v = ‚ãØ -- Unclear at this stage.
#+end_src
#  {{_ : HasCarrier v}}
The record case could, semi-algorithmically, yield:
{{{code(Verbose Record Case)}}}
#+begin_src haskell
retract-v {record}  :  ‚àÄ {S T} (f : S ‚Üí T)
            ‚Üí  ‚àÄ (Tgt : AMagma) ‚Üí AMagma.Carrier Tgt ‚â° T
            ‚Üí  Œ£ (Src : AMagma) ‚Ä¢ AMagma.Carrier Src ‚â° S
retract-v {record} {S} {T} f Tgt refl =  record { Carrier = S
                        ;  _‚®æ_ = Œª x y ‚Üí f x ‚®æ f y }
                       , refl
                       where open AMagma Tgt
#+end_src
From a usability perspective the trivial proofs should not be present
and so we need to algorithmically rewrite the above type to omit them, as follows.
We would like to preserve the argument syntax, ~retract f Tgt~, that was originally declared.
Unfortunately, for the record case, the type of ~f~ must refer to the types of the other magamas
if we eliminate the trivial equalities. One possible workaround, as follows, is thus to simply provide
a omit the tedious equality proofs since they can be found by instance search.
{{{code(Usable Record Case)}}}
#+begin_src haskell
retract-v {record}  :  ‚àÄ {S T} (f : S ‚Üí T)
            ‚Üí  ‚àÄ (Tgt : AMagma) ‚¶É_ : AMagma.Carrier Tgt ‚â° T ‚¶Ñ
            ‚Üí  proj‚ÇÅ (‚¶ÉŒ£‚¶Ñ Src : AMagma ‚Ä¢ AMagma.Carrier Src ‚â° S)
retract-v {record} f Tgt  = ‚ãØ

-- ‚Äú‚¶ÉŒ£‚¶Ñ (x : A) ‚Ä¢ B x‚Äù consists of a pair
-- where the second is found by instance search.
#+end_src
Notice that we also project at the end since we do not care about the tedious proof;
nor should its existence be forced upon the user.

Before we move on, there is particular reason we have deviated from our ~TermP~ example
to the ~MagmaP~ concept. The ~datatype~ variation for ~MagmaP~ does not provide a way
to speak of variables of the data type ---indeed ~MagmaP datatype~ has no closed terms,
whence no terms at all. It is thus appropriate to now introduce a variation for
syntactic terms /over/ some variable set which is then utilised by a mechanically
derivable semantic function that is freely homomorphic.

{{{code(From Syntax to Semantics)}}}
#+begin_src haskell
MagmaTermsOn = MagmaP term-typeclass
{-
‚âÖ data MagmaTermsOn (Vars : Set) : Set where
    Var : Vars ‚Üí MagmaTermsOn Vars
    _‚®æ_  : MagmaTermsOn Vars ‚Üí MagmaTermsOn Vars ‚Üí MagmaTermsOn Vars

MagmaTermsOn-sem : ‚àÄ {v} {A}  ‚Üí  do œÑ ‚Üê MagmaP v;
                 (f : A ‚Üí œÑ) ‚Üí MagmaTermsOn A ‚Üí œÑ
MagmaTermsOn-sem {record} S f (Var x) = f x
MagmaTermsOn-sem {record} S f (l ‚®æ r)  = ll s‚®æ rr
  where _‚®æs_ = AMagma._‚®æ_ S
    ll = MagmaTermsOn-sem {record} S f l
    rr = MagmaTermsOn-sem {record} S f r
‚ãØ
-}
#+end_src

We will return to homomorphisms later on, for now it is important to notice
that some variations may be useless ---as in the empty datatypes.
There is also the opportunity to explore co-inductive datatypes.
**** Common Operations on Package Formers
It is rather common in the record variation to have multiple instances being
mentioned and it is desirable to refer to them with syntactically distinct yet appealing
names ---such as using subscripts, primes, or other decoration. Moreover, a notion of
homomorphism, structure-preservation, can usually be automatically inferred.

Here we show what such declarations looks like, later we show that such things
could be /user defined/.

{{{code(An example package former)}}}
#+begin_src haskell
PackageFormer TermRelP (v : Variation) : Set where
   Var : Int ‚Üí TermRelP v
   Add : TermRelP v ‚Üí TermRelP v ‚Üí TermRelP v
   Rel : TermRelP v ‚Üí TermRelP v ‚Üí Set  -- This time we have a relation as well.
#+end_src
{{{code(A prime-decorated package former)}}}
#+begin_src haskell
Declare PackageFormer TermRelP (v : Variation) decorated (Œª x ‚Üí x ++ "‚Ä≤")
{-
‚âÖ PackageFormer TermRelP‚Ä≤ (v : Variation) : Set where
   Var‚Ä≤ : Int ‚Üí TermRelP‚Ä≤ v
   Add‚Ä≤ : TermRelP‚Ä≤ v ‚Üí TermRelP‚Ä≤ v ‚Üí TermRelP‚Ä≤ v
   Rel‚Ä≤ : TermRelP‚Ä≤ v ‚Üí TermRelP‚Ä≤ v ‚Üí Set

-- Coherence Meta-property: ‚àÄ v, d  ‚Ä¢  TermRelP v decorated d  ‚âÖ  TermRelP v
-}
#+end_src
{{{code(Structure preserving operations)}}}
#+begin_src haskell
Declare Homomorphism TermRelP (v : Variation)
{-
‚âÖ PackageFormer TermRelP-Homomorphism (v : Variation) : Set where

    Src : TermRelP v   decorated  (Œª x ‚Üí x ++ "‚ÇÅ")
    Tgt : TermRelP v   decorated  (Œª x ‚Üí x ++ "‚ÇÇ")

    map : Src ‚Üí Tgt
    -- Elaborates to ‚ÄúCarrier Src ‚Üí Carrier Tgt‚Äù in ‚Äúrecord‚Äù variation.

    var_preservation : ‚àÄ n   ‚Üí map (Var‚ÇÅ n) ‚â° Var‚ÇÇ n
    add_preservation : ‚àÄ x y ‚Üí map (Add‚ÇÅ x y) ‚â° Add‚ÇÇ (map x) (map y)
    rel_preservation : ‚àÄ x y ‚Üí Rel‚ÇÅ x y ‚Üí Rel‚ÇÇ (map x) (map y)

NB: The ‚Äúdecorated‚Äù annotations are local to the package.
-}
#+end_src

**** Inheritance & Defaults for Package Formers

Things get a bit more interesting with multiple packaging,
fields making use of dependent types, and of (multiple) default implementations.
Besides defaults, a desirable feature of our envisioned system is the ability to lift definitional extensions
into fields of the package, say for more efficient implementations.

{{{code(Recall our example package former)}}}
#+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
   Var : Int ‚Üí TermP v
   Add : TermP v ‚Üí TermP v ‚Üí TermP v
#+end_src

{{{code(All the pieces of \texttt{TermP} but now with additionall new pieces)}}}
#+begin_src haskell
PackageFormer PreOrderedTermP (v : Variation) : Set  inherits-from (TermP v) where
   Ord   : OrderedTermP v ‚Üí OrderedTermP v ‚Üí Set
   Refl  : ‚àÄ x ‚Üí Ord x x
   Trans : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z

   -- Two default ‚Äòimplementations‚Äô

   default‚ÇÅ Ord x y                =  x ‚â° y
   default‚ÇÅ Refl  x                =  refl
   default‚ÇÅ Trans _ _ _ refl refl  =  refl

   default‚ÇÇ Ord x y                =  ‚ä§
   default‚ÇÇ Refl  x                =  tt
   default‚ÇÇ Trans _ _ _ _ _        =  tt
#+end_src

Notice how ‚Äúfree type‚Äù formation incorporates this new open-ended
construct, ~Ord~, as a two-value holder. An alternative interpretation would
be to eliminate it altogether from the elaborated data declaration.
Anyhow, since we elaborate a relation as a pair former, proofs for
such a relation cannot be included ---otherwise it's not a ‚Äúfree‚Äù type!
{{{code(Derivied ADT from a package former with constructive relations)}}}
#+begin_src haskell
PreOrderedTermData = PreOrderedTermP data
{-
‚âÖ  data PreOrderedTermData : Set where
     Var : Int ‚Üí OrderedTermData
     Add : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí PreOrderedTermData
     Ord : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí PreOrderedTermData

     -- No reflexitivity axiom on ‚ÄòOrd‚Äô, nor transitivity!
-}
#+end_src
{{{code(Using a ~default~ implementation)}}}
#+begin_src haskell
PreOrderedTermData = PreOrderedTermP data with-default‚ÇÅ
{-
‚âÖ  data PreOrderedTermData : Set where
     Var : Int ‚Üí OrderedTermData
     Add : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí PreOrderedTermData

     -- No ‚ÄòOrd‚Äô construction, but instead a constructive relation and properties:

     Ord : PreOrderedTermData ‚Üí PreOrderedTermData ‚Üí Set
     Ord x y  =  x ‚â° y

     Refl  : ‚àÄ x ‚Üí Ord x x
     Refl  x  =  refl

     Trans : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z
     Trans _ _ _ refl refl  =  refl
-}
#+end_src
The naming ~Ord, Refl, Trans~ could have been altered to refer to the newly declared data
type, for simplicity we have avoided such a transformation.
Moreover, we could reserve ~with-default‚ÇÄ~ to simply omit constructive relations from
being reified as data constructors.

{{{code(Keeping the axioms by using a record)}}}
#+begin_src haskell
PreOrderedTermRecord = PreOrderedTermP record
{-
‚âÖ   record PreOrderedTermRecord : Set where
      field
    Carrier : Set
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier
    Ord     : Carrier ‚Üí Carrier ‚Üí Set
    Refl    : ‚àÄ x ‚Üí Ord x x
    Trans   : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z

     -- Notice that the reflexitivity & transitivity axioms are kept!
-}
#+end_src
Moreover, the default implementations means we also have the following
declaration, where distinctions are made by the occurenace, or absence, of fields.
{{{code(Defaults yield additional elaborations)}}}
#+begin_src haskell
{-
    record PreOrderedTermRecord : Set where
      field
    Carrier : Set
    Var     : Int ‚Üí Carrier
    Add     : Carrier ‚Üí Carrier ‚Üí Carrier

      Ord     : Carrier ‚Üí Carrier ‚Üí Set
      Ord x y =  x ‚â° y

      Refl    : ‚àÄ x ‚Üí Ord x x
      Refl _ = refl

      Trans   : ‚àÄ x y z ‚Üí Ord x y ‚Üí Ord y z ‚Üí Ord x z
      Trans _ _ _ refl refl = refl
-}
#+end_src
Here is our first observation of a uniform presentation of packaging,
where the ‚Äúintended use‚Äù differs: Whether we want axioms or not?

Not only is the use amicable, but utilities written for the first elaboration
effortlessly apply to instances of the second elaboration. Unfortunately,
the relationship is not symmetric
---e.g., using the additional information provided by the default implementations,
 ~‚àÄ x y ‚Üí Ord x y ‚Üí Add x y ‚â° Add y x~ is provable for the latter but
not the former. As such, there is need to be able to mark results applying
to a subtype of a package former, or to eliminate such a desirable feature
that reduces needless distinctions when applying utilties of the former to the
latter. The thesis will provide a solution with a discussion of the alternatives
and why they were not adopted.

**** Package Formers Dispense with The Diamond Problem

Let's consider combining multiple containers.
{{{code(A package former for unital magmas)}}}
#+begin_src haskell
Package UnitalTermP (v : Variation) : Set inherits-from (TermP v) where
   unit : UnitalTermP v
   lid  : ‚àÄ x ‚Üí Add unit x ‚â° x
   rid  : ‚àÄ x ‚Üí Add x unit ‚â° x
#+end_src
# -- NB: Using ‚ÄúMaybe‚Äù, every ‚ÄúTermP record‚Äù can be converted into a ‚ÄúUnitalTermP record‚Äù.
{{{code(Inheriting from multiple pacakage formers)}}}
#+begin_src haskell
Package PreOrderedMonoid (v : Variation) : Set
      inherits-from (UnitalTermP v; PreOrderedTermP v)
  where
   associative : ‚àÄ x y z ‚Üí (Add x y) z ‚â° Add x (Add y z)
   monotone    : ‚àÄ x x' y y' ‚Üí Ord x x' ‚Üí Ord y y' ‚Üí Ord (Add x y) (Add x' y')
#+end_src
This package ought to be indistinguishable from the following, whence allowing tremendously flexible
declarations and uses. In particular, there is no longer a need to distinguish between a hierarchical
and a flattened perspective, since they are considered identical.
{{{code(Equivalent backend representation)}}}
#+begin_src haskell
Package PreOrderedMonoid (v : Variation) : Set where

   unitaltermp : UnitalTermP v
   preorderedtermp : PreOrderedTermP v

   associative : ‚àÄ x y z ‚Üí (Add x y) z ‚â° Add x (Add y z)
   monotone    : ‚àÄ x x' y y' ‚Üí Ord x x' ‚Üí Ord y y' ‚Üí Ord (Add x y) (Add x' y')

   -- From which sub-structure does the above ‚ÄúAdd‚Äù arise?
   --
   -- The ‚Äúrecord‚Äù and ‚Äútypeclass‚Äù variations elaborate with axioms declaring
   -- that identical names are indeed identical operations:
   carrier_coherence : unitaltermp.Carrier ‚â° preorderedtermp.Carrier
   var_coherence     : unitaltermp.Var     ‚â° preorderedtermp.Var
   add_coherence     : unitaltermp.Add     ‚â° preorderedtermp.Add
   --
   -- They also elaborate with default tedious implementations:
   carrier_coherence = refl; var_coherence = refl; add_coherence = refl

   -- Moreover, we can continue the ‚Äòdefault‚Äô implementation.
   default‚ÇÅ monotone _ _ _ _ refl refl = refl
   default‚ÇÇ monotone _ _ _ _ _ _       = tt
#+end_src

**** Package Formers & Representational Shifts

Let us close this section by demonstrating how this genericity can aid in
ubiquitous representational shifts that appear rather often in dependently typed programming.
In pedestrian languages, there are usually less ways to accomplish a task in
dependently typed languages and so programming style is not of great concern.
In contrast, in a DTL, a user could, for example, work over an abstract data type
where a particular argument is fixed or where it is allowed to vary.
The two approaches are a matter of style, but can lead to awkward situations.
# The downside of the former is that we cannot vary, whereas in the latter

# context shifting; Œª-introduction; ‚áí-theorem.
#
More concretely, we consider the bread and buffer of coding: Graphs.
Without dependent types we can only speak about graphs /over/ a given vertex type,
with dependent types we can speak about /a/ graph, irrespective of vertex type.
The former is tantamount to the context ~Vertex ‚à∂ Type ‚ä¢ Edges ‚à∂ Vertex ‚Üí Vertex  ‚Üí Type~,
and an empty assumption context ~‚ä¢ Vertex ‚à∂ Set, Edges ‚à∂ Vertex ‚Üí Vertex ‚Üí Type~
for the latter.
However, the latter form sometimes leads us into contexts where we have two
graphs ~G~ and ~H~ for which we make the tedious constraint \newline ~Vertex G ‚â° Vertex H~.
It would be less clumsy to explicitly declare the two graphs to be /over/ the
same vertex type.

The previous paragraph mentioned a terse dependently-typed presentation of graphs,
let us use the classic presentation as it may be more familiar to readers.
{{{code(Graph package former)}}}
#+begin_src haskell
PackageFormer GraphP (v : Variation) : Set where
  Vertex, Edges : Set
  src, tgt      : Edges ‚Üí Vertex

  -- The dependently typed notion of edges.
  derivied
    _‚ü∂_ : Vertex ‚Üí Vertex ‚Üí Set
    x ‚ü∂ y  =  Œ£ e : Edges  ‚Ä¢  src e ‚â° x  ‚àß  tgt e ‚â° y
#+end_src

{{{code(Graphs as records)}}}
#+begin_src haskell
AGraph = GraphP record renaming (Carrier to ‚ÄúVertex‚Äù)
{-
‚âÖ   record AGraph : Set where
      field
    Vertex Edges : Set
    src    tgt   : Edges ‚Üí Vertex
-}

-- NB. The implicitly generated name ‚ÄúCarrier‚Äù has been identified with
-- the *declared* name ‚ÄúVertex‚Äù. This is acceptable since they have the same type.
-- Without the identification, the record elaboration would have provided a
-- third type field named ‚ÄúCarrier‚Äù.
#+end_src
{{{code(Parameterised graphs as typeclasses)}}}
#+begin_src haskell
GraphOver = TermP typeclass renaming (Carrier to ‚ÄúVertex‚Äù)
{-
‚âÖ   record GraphOver (Vertex : Set) : Set where
       field
      Edges   : Set
      src tgt : Edges ‚Üí Vertex
-}
#+end_src
With these in hand, our goal is to replace the following first line with the second.
However, since both types ~GraphOver~ and ~AGraph~ are declared as one liners,
such a transition is a cheap as possible.
#+begin_src haskell
(G H : AGraph) ‚Üí Vertex G ‚â° Vertex H ‚Üí ‚ãØ

(V : Set) ‚Üí (G H : GraphOver V) ‚Üí ‚ãØ
#+end_src
In order to /replace a semantic constraint with a syntactic constraint/
the user simply need to use a /variant/ on packaging. Furthermore, we
are ensured \newline ~AGraph ‚âÖ Œ£ V ‚à∂ Set ‚Ä¢ GraphOver V~.

Dependently-typed graphs are an curious structure. With a bit of renaming, and adding a few laws,
we obtain a ‚Äòsetoid‚Äô --i.e., an undirected graph where every node has a self-loop, and paths
correspond are essentially edges.
{{{code(Setoid package former)}}}
#+begin_src haskell
PackageFormer SetoidP (v : Variation) : Set where
  -- Graph structure
  Carrier : Set
  _‚âà_     : Carrier ‚Üí Carrier ‚Üí Set
  -- Properties
  refl  : ‚àÄ{e}     ‚Üí e ‚âà e
  sym   : ‚àÄ{d e}   ‚Üí e ‚âà d ‚Üí d ‚âà e
  trans : ‚àÄ{c d e} ‚Üí c ‚âà d ‚Üí d ‚âà e ‚Üí c ‚âà d
#+end_src
A non-dependently-typed ‚Äòsignature‚Äô of a structure is generally obtained by discarding the relational operators
and all properties. For ~SetoidP~ one would immediately think the signature consists of just ~Carrier~.
However, if we view it instead as undirected graphs with self-loops at each node and edge-transitivity, then
one would say the signature is the vertices ~Carrier~ and the edges ~_‚âà_~. It is thus not clear when an item,
~_‚âà_~ or ~_‚ü∂_~, forms constructive proofs or provides a type family. As such, signature extraction thus requires
a parameter identifying which elements constitute ‚Äòproof matter‚Äô ---then one simply filters a pacakge-former
against this criterion to obtain the associated signature. More generally, this allows us to take an ~X~ structure
and obtain may of its the associated views about where knowledge is consolidated \parencite{realms}, including:
#+BEGIN_SRC haskell
X         = ‚ü® Carrier; Operations; Properties ‚ü©     -- C.f., SetoidP
XOver C   = ‚ü® Operations; Properties ‚ü©
IsX C Ops = ‚ü® Properties ‚ü©
XSig      = ‚ü® Carrier; Operations‚ü©                  -- C.f., GraphP
#+END_SRC
Having the signature in hand, one can easily and mechanically generate many derivied concepts.
For example, a ‚Äòhomomorphism‚Äô is a family of functions of the underlying sorts such that
the given operations are preserved. Likewise, equality of homomorphisms is extensional equality of
the underlying maps. One can then generate closed and open terms and their interpretation functions.
With this approach to signature extraction, we can use the same algorithms
for the production of, say homomorphisms or other constructs, on completely
different algebraic structures, whether they be monoids or graphs.
Moreover, this implies that concepts generally not considered for a class
of algebras can easily be derived and experimented with; likewise for exploring
new algebraic theories.
These matters are an application, rather than a goal, of our envisioned system.

:Neat_but_irrelevant:
Sometimes constraints on an item can be derived, leaked by a signature.

E.g., the signature of sets, on a carrier, leaks that the carrier necessary
has decidable equality.
:End:

The curiosity of graphs is that they are one of the simplest /two-sorted/ structures
and one of the most common in computing. Counter to intuition, existing packaging
systems, namely canonical structures and typeclasses, are oriented toward having
a distinct parameter: They cannot work well with multi-parameters; like classical
single-sorted algebra. However, the both /aim to solve a usability problem:/
/Having to spell out everything is too tedious./ Typeclasses are essentially dictionary look-up,
having unicity as an issue. Whereas canonical structures require familiarity with how unifer works
--we provide enough information to the unifer to find the desired structure-- but, in general,
canonical structures do not scale. It is one of the thesis efforts to ensure the the unionised
approach scales by a complex example with clear avenues of extension.

It should be clear from these examples that package formers provide
expectant generality, including the common uses one is mostly interested in.
What about unexpected uses? What if a user wishes to utilise a representation
we did not conceive of? They should be able to use the existing language to
form it.
*** Second Observation: Computing Similarity for Containers

By necessity of the first corollary, we are forced to utilise a uniform language
between the varying notions of packaging thereby relegating their treatment
to be a normal aspect of a language's core vernacular, rather than an extra-linguistic feature.
The previous examples hint at possible issues regarding well-definedness of certain constructs.
Moreover, we only elaborated on a few compositional operations,
~inherits-from, renaming, decorated~, yet users
may well wish to utilise their own compositional schemes and so it is imperative that we allow
them such a flexibility.
Consequently, users ought to be able to define their own compositional mechanisms, thereby
necessitating that they be able to manipulate package declarations themselves
which in-turn forces the language to be somewhat homoiconic. Moreover, to avoid a hierarchy
of languages, the facility for manipulating package declarations must itself be a part of
the core language, rather than an extra-linguistic feature ---c.f., Coq's Ltac.

In our envisioned setup, every ~PackageFormer~ declaration adds a clause to a special
function,
{{{code(Under the hood)}}}
#+begin_src haskell
packageInfo : PackageFormer ‚Üí PackageInfo
packageInfo = ‚ü™compiler defined‚ü´
#+end_src
Where a ~PackageInfo~ consists of ~Name~, which is a list of parameter names and types, along with the name of the package former;
and ~Declarations~, a list of name-type pairs whose last element is the target type.
{{{code(PackageInfo: Just another package ---for ‚Äúsignatures‚Äù)}}}
#+begin_src haskell
{- Draft: Lots of string manipulation, not ideal. -}
record PackageInfo : Set where
  field
    Name         : List (String √ó String) √ó String
    Declarations : List (String √ó List String)
--
-- This is just another package,
-- it incidentally happens to be the representation of packages!
#+end_src

It is to be noted that there is no commitment to a string-based representation.
It is only a prototype and the thesis will likely move to a better typed
representation ---otherwise, we may run into too many problems of ill-formed
package formers.

{{{code(Recall our example package former)}}}
#+begin_src haskell
PackageFormer TermP (v : Variation) : Set where
  Var : Int ‚Üí TermP v
  Add : TermP v ‚Üí TermP v ‚Üí TermP v
#+end_src
The above declaration provides, under the hood, the following clause to ~packageInfo~.
{{{code(Under the hood)}}}
#+begin_src haskell
packageInfo TermP = record { Name         = ["v", Variation] , "TermP"
               ; Declarations = [ ("Var", ["Int", "TermP v"])
                        , ("Add", ["TermP v", "TermP v", "TermP v"])
                        ]
               }
#+end_src
# Note the ‚Äòv‚Äô, whence String not Set in the defn of PackageInfo.

We are now in a position to provide the semantics for the keyword ~Declare~,
from the previous section. It takes a ~PackageInfo~ and declares a ~PackageFormer~.
There should be a compile-time warning if such declarations are meaningless, ill-formed.

For example, the previous \newline ~Declare PackageFormer TermRelP (v ‚à∂ Variation) decorated (Œª x ‚Üí x ++ "‚Ä≤")~
can thus be obtained by a user by defining ~decorated~ as an operation on packages!
{{{code(User-defined composition scheme)}}}
#+begin_src haskell
_decorated_ : PackageInfo ‚Üí (String ‚Üí String) ‚Üí PackageInfo
pk decorated f = record { Name         = bimap id f pk.Name
            ; Declarations = fmap (bimap f id) pk.Declarations
            }
#+end_src

To rectify the seemingly wild mixfix notions, we request from the compiler
the following suitably general syntactic sugar.
An operation, call it, ~altered-by~ of the type ~PackageInfo ‚Üí List PackageInfo ‚Üí List X ‚Üí PackageInfo~
automatically obtains the syntactic sugar ~p altered-by (q0; ‚Ä¶; qk) with (f0; ...; fN)~ ---c.f., the ~inherits-from~ syntax above.

# Woah! Look at how easy that was, no need to build it in!

With such terse functional programs for forming composition schemes,
there is no need to build much into the compiler.

Users can define other similar operations, such as ~decorated-rounded~
which replaces the first two binary relations' names with ~‚äÜ~ and ~‚äÇ~;
or ~decorated-square~ to make the renamings ~‚äë~ and ~‚äè~.
Additionally, such renames would propagate into any axioms or derived laws.
Moreover, the flexibility to invoke such operations in complex ways allows for
intricate renamings to be generated at tremendous scale without worry that
future renames would need to be made if the orginal packages included new items.
Numerous examples of such renaming transpire manually in the impressive
RATH \parencite{RATH} development, as well as in Agda's standard library.

When working with multiple values of the same record type, for example,
one encounters a usability problem: Refereeing to the constituents without being verbose.
The simplest solution is to qualify each invocation, as in ~instance.field~, however this
is rather cumbersome, inelegant, and is awkward for mixfix names. An alternative is to
locally rename the fields according to a scheme reflecting their use. For example, in
a produce construction of 5 items, the field names would be renamed to have a subscript number.
In a setting of two instances, a user may instead prefer a primed and an undecorated version
of field names. Thus far, by hand we have created these tedious subscript and primed renamings,
with our envisioned systems, we need no longer worry about such boilerplate.

In nearly the same fashion, a user could have defined the ~inherits-from~ compositional scheme.
Such a scheme may assume that all identically named items have the same types, and crash otherwise.
A user could define a better scheme that takes a renaming function, or another function to handle
the crash, or simply omitt conflicting names altogether.
The examples suggest that many commonly occurring compositional mechanisms \parencite{tpc}
can be directly provided by a library, rather than by a particular compiler
---this includes the ability to hide fragments, expose the largest well-defined fragment,
and to combine packages along a given substructure.

Rather than select what we think is best, we can simply provide the general mechanism to the
library designer and allow them the freedom to provide their own schemes.

*** Next Steps

Our brief examples demonstrate that the less design decisions about packaging
made by language designers, the more general, applicable, and, most importantly, increased homogeneity
in the resulting datatype language without becoming unityped but rather thanks to being dependently-typed.
As mentioned in the previous section on existing approaches, one formalism for
packages is that of theories and theory combinators; below we thus draw on some problems from theory combinators
rendered toward packaging systems.

We have mentioned that the ~record~ and ~typeclass~ perspectives solve the common requirement of
structures sharing an identical field. Other than that, we have essentially only
outlined a general mechanism for declaring packages and compositional schemes, but have not
discussed which are the most common and most useful packaging combinators.
It is also desirable to discuss the formal properties of such combinators
---if anything, to ensure they are sensible and behave as expected.
Moreover, which combinators act as a basis for all packaging combinators?
Whence their use ensures the resulting composition is well-formed
and they could be targeted for optimisations.
#  Soundness & Completeness proofs?

To make our approach accessible, the generic package operations are brought to the user
rather than baked into the compiler ---too great a distance for most users.
The ~Declare~ syntax reifies ~PackageInfo~'s into package declarations, but we have not mentioned
under what constraints it can actually provide compiler-time, or typechecking-time,
errors of ill-formedness. Moreover, how (in)efficient is this process?
Could it be extended to work on variable, runtime provided, declarations
for refying packages? Perhaps there is a constraint that suffices for the most common cases?
Moreover, having observable ~PackageInfo~'s being automatically generated for every package declaration
renders representation hiding nearly moot.

The proposed approach boarders on meta-programming.
Can type erasure and other compiler-specific optimisations be brought into
the homoiconic-like setting being pursued here?
We have mentioned a few ‚Äòbuilt in‚Äô variations for packaging; can such a feature
be liberated from the compiler and be bent to the users' will?
We would need the ability to explain how a package elaborates.

Tremendous flexibility is demanded from the back-end so as to ignore needless distinctions
at the users' level. Whereas the practicality is promising, the feasibility of an
implementation for such ambiguous parsing \parencite{ambiguous_parsing} is unclear.
It is also unclear what effects identifying syntactically distinct items
has on, say, normalisation and propositional equality.

The numerous claims and associaited bookkeeping of details pushes us into using a proof assistant, Agda.

Our examples have been ‚Äòvariation‚Äô polymorphic;
we have been even more generic by defining ~decorated~.
What are the limits of programming genericity provided by our scheme?
It would unsurprising if this approach yields
the next 700 module systems.

* COMMENT Conclusion
:PROPERTIES:
:CUSTOM_ID: conclusion
:END:

As already discussed,
more often than not a module system is an afterthought secondary citizen
whose primary purpose is to act as a namespace delimiter
---e.g., C#'s ~namespace~ construct---
while relatively more effort is given to their abstraction encapsulation
counterpart, e.g., C#'s ~class~'es.
Some languages' module systems blend both namespace management and
implementation hiding, e.g., as in the Haskell programming language.
Other languages such as OCaml take modules even further: Not only are modules
used for namespace organisation and datatype abstraction, but they can also be
passed around as values for manipulation as if they were nothing special, thereby
collapsing the distinction between record constructs and organisational constructs.

The proposed research is to build upon the existing state of module
systems and develop an extension to a compiler to substantiate our claims,
and to ultimately discover new semantical relationships between programming
language constructs in a dependently typed setting with modules as first-class
citizens. This involves redesigning and enhancing existing module systems
to take into account dependent types as well as producing rewrite theorems
to ensure acceptable performance times.

Intended outcomes include:
  1. A clean module system for DTLs
     + Dependent types blur many distinctions therefore rendering certain
       traditional programming constructs as inter-derivable and so only
       a minimal amount need be supported directly, while the rest can be
       defined within the extended type theory we will be creating.
       Since modules are records, which are
       one-field algebraic data types, and we can form sums of modules, it
       would not be surprising if first-class modules suffice for arbitrary data type
       definitions.

       # syntactic sugar ‚âà pre-processing

  2. /Utility Objectives/: A variety of use-cases contrasting the resulting system with previous
     approaches. In particular, the system should:

     + Reduce amount of ‚Äònoise‚Äô necessary for working with grouping mechanisms in a number of ways.
     + It should be easy and elegant to use and, possibly, to extend.
  3. A module system that enables rather than inhibits (or worse) efficiency.
     + Currently Agda modules, for example, are sugar for extra functional parameters
       and so all implicit sharing in modules is lost at compilation time.
     + Deeply nested, deeply tagged, operations could be costly and so being apply
       to /soundly/ flatten modules and /soundly/ extract operations and results
       is a necessity when speed is concerned ---moreover, this needs to be mechanical and succinct if it is to be useful.
  4. Demonstrate that module features usually requiring meta-programming can be brought
     to the data-value level.
     + Names and types, for example, in a module should be accessible
       and alterable. For example, we can obtain a rig by combining two instances
       of a monoid module where we would rename the fields of one, or both, of them.
     + Thereby relegating abstract syntax tree and programs-as-strings manipulations
       to the edges of the computing environment.

Most importantly, we intend to implement our theory to obtain
validation that it ‚Äúworks‚Äù!

# It goes without saying, these are preliminary goals, as the outcomes are likely to
# change and evolve multiple times as the research is carried out.

* COMMENT Bib                                                                :ignore:
# LaTeX: \addcontentsline{toc}{section}{References}
#+LaTeX: \addcontentsline{toc}{part}{References}
#+LaTeX: \printbibliography
* COMMENT My References                                                    :noexport:

# Please don't judge me too harshely for having my referneces in-place like this.
# In the future, I'll likely refactor into their own file and possibly use org-ref.

# Using biblio-lookup tool in emacs to make my bibtexs.
#
# In doubt, use http://www.citationmachine.net/bibtex
# Give it a site and it tries to generate a bibtex.

** Theory Presentation Combinators :tpc:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{tpc,
  author       = {Carette, Jacques and O‚ÄôConnor, Russell},
  title        = {Theory Presentation Combinators},
  year         = 2012,
  pages        = {202‚Äì215},
  issn         = {1611-3349},
  doi          = {10.1007/978-3-642-31374-5_14},
  url          = {http://dx.doi.org/10.1007/978-3-642-31374-5_14},
  isbn         = 9783642313745,
  journal      = {Intelligent Computer Mathematics},
  publisher    = {Springer Berlin Heidelberg}
}
#+END_SRC
** Computing with Semirings and Weak Rig Groupoids :rig_computations:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{rig_computations,
  author       = {Jacques Carette and Amr Sabry},
  title        = {Computing with Semirings and Weak Rig Groupoids},
  year         = 2016,
  booktitle    = {Programming Languages and Systems - 25th European
          Symposium on Programming, {ESOP} 2016, Held as Part
          of the European Joint Conferences on Theory and
          Practice of Software, {ETAPS} 2016, Eindhoven, The
          Netherlands, April 2-8, 2016, Proceedings},
  pages        = {123-148},
  doi          = {10.1007/978-3-662-49498-1\_6},
  url          = {https://doi.org/10.1007/978-3-662-49498-1\_6},
  crossref     = {DBLP:conf/esop/2016},
  timestamp    = {Fri, 02 Nov 2018 09:46:30 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/esop/CaretteS16},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Hasochism: the pleasure and pain of dependently typed haskell programming :hasochism:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{hasochism,
  author       = {Sam Lindley and Conor McBride},
  title        = {Hasochism: the pleasure and pain of dependently
          typed haskell programming},
  year         = 2013,
  booktitle    = {Proceedings of the 2013 {ACM} {SIGPLAN} Symposium on
          Haskell, Boston, MA, USA, September 23-24, 2013},
  pages        = {81-92},
  doi          = {10.1145/2503778.2503786},
  url          = {https://doi.org/10.1145/2503778.2503786},
  timestamp    = {Tue, 06 Nov 2018 16:58:22 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/haskell/LindleyM13},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Deriving Via                                                :deriving_via:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{deriving_via,
  author       = {Baldur Bl{\"{o}}ndal and Andres L{\"{o}}h and Ryan
          Scott},
  title        = {Deriving via: or, how to turn hand-written instances
          into an anti-pattern},
  year         = 2018,
  booktitle    = {Proceedings of the 11th {ACM} {SIGPLAN}
          International Symposium on Haskell, Haskell@ICFP
          2018, St. Louis, MO, USA, September 27-17, 2018},
  pages        = {55-67},
  doi          = {10.1145/3242744.3242746},
  url          = {https://doi.org/10.1145/3242744.3242746},
  timestamp    = {Tue, 11 Dec 2018 19:30:58 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/haskell/BlondalLS18},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Realms: A Structure for Consolidating Knowledge about Mathematical Theories :realms:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Online{realms,
  author       = {Jacques Carette AND William M. Farmer AND Michael
          Kohlhase},
  title        = {{Realms: A Structure for Consolidating Knowledge
          about Mathematical Theories}},
  year         = 2014,
  archiveprefix= {arXiv},
  eprint       = {1405.5956v1},
  primaryclass = {cs.MS}
}
#+END_SRC
** programatica, haskell_modules_formally, haskell_in_haskell, classic_haskell_genericity
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{classic_haskell_genericity,
  author = {Tim Sheard},
  title = {Generic Unification via Two-Level Types and Parameterized Modules},
  booktitle = {ICFP 2001},
  publisher = {acm press},
  note = {to appear},
}

@Unpublished{haskell_in_haskell,
  author = {Tim Sheard and William Harrison and James Hook},
  title = {Modeling the Fine Control of Demand in Haskell.},
  note = {(submitted to Haskell workshop 2001)},
  OPTkey = {},
  OPTmonth = {},
  year = 2001,
}

@InProceedings{haskell_modules_formally,
  author = {Iavor S. Diatchki and Mark P. Jones and Thomas Hallgren },
  title = {A formal specification of the {Haskell 98} module system },
  crossref = {Haskell2002},
  pages = {17--28},
  URL = {http://doi.acm.org/10.1145/581690.581692},
  abstract = {Many programming languages provide means to split large
      programs into smaller modules. The module system of a language
      specifies what constitutes a module and how modules interact.This
      paper presents a formal specification of the module system for the
      functional programming language Haskell. Although many aspects of
      Haskell have been subjected to formal analysis, the module system
      has, to date, been described only informally as part of the Haskell
      language report. As a result, some aspects of it are not well
      understood or are under-specified; this causes difficulties in
      reasoning about Haskell programs, and leads to practical problems
      such as inconsistencies between different implementations. One
      significant aspect of our work is that the specification is written
      in Haskell, which means that it can also be used as an executable
      test-bed, and as a starting point for Haskell implementers.}
}

@InProceedings{programatica,
  author = {Thomas Hallgren and James Hook and Mark P. Jones and Richard B. Kieburtz},
  title =        {An Overview of the Programatica Toolset},
  booktitle =  {HCSS '04},
  URL =          {http://www.cse.ogi.edu/PacSoft/projects/programatica/},
  bibliographies = {HHOL},
}
#+END_SRC
** packaging_mathematical_structures
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{packaging_mathematical_structures,
  author       = {Garillot, Fran{\c c}ois and Gonthier, Georges and
          Mahboubi, Assia and Rideau, Laurence},
  title        = {{Packaging Mathematical Structures}},
  year         = 2009,
  booktitle    = {{Theorem Proving in Higher Order Logics}},
  editor       = {Tobias Nipkow and Christian Urban},
  volume       = 5674,
  series       = {Lecture Notes in Computer Science},
  publisher    = {{Springer}},
  url          = {https://hal.inria.fr/inria-00368403},
  address      = {Munich, Germany},
  keywords     = {Formalization of Algebra ; Coercive subtyping ; Type
          inference ; Coq ; SSReflect},
  pdf          = {https://hal.inria.fr/inria-00368403/file/main.pdf},
  hal_id       = {inria-00368403},
  hal_version  = {v2}
}
#+END_SRC
** A modular module system
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{modular_modules,
  author       = {Xavier Leroy},
  title        = {A modular module system},
  year         = 2000,
  volume       = 10,
  number       = 3,
  pages        = {269-303},
  url          =
          {http://journals.cambridge.org/action/displayAbstract?aid=54525},
  journal      = {J. Funct. Program.},
  timestamp    = {Fri, 10 Jun 2011 14:42:13 +0200},
  biburl       = {https://dblp.org/rec/bib/journals/jfp/Leroy00},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** A type system for higher-order modules :types_for_modules:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{types_for_modules,
  author       = {Derek Dreyer and Karl Crary and Robert Harper},
  title        = {A type system for higher-order modules},
  year         = 2003,
  booktitle    = {Conference Record of {POPL} 2003: The 30th
          {SIGPLAN-SIGACT} Symposium on Principles of
          Programming Languages, New Orleans, Louisisana, USA,
          January 15-17, 2003},
  pages        = {236-249},
  doi          = {10.1145/640128.604151},
  url          = {https://doi.org/10.1145/640128.604151},
  timestamp    = {Tue, 06 Nov 2018 11:07:43 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/popl/DreyerCH03},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Understanding TypeScript                       :understanding_typescript:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{understanding_typescript,
  author       = {Gavin M. Bierman and Mart{\'{\i}}n Abadi and Mads
          Torgersen},
  title        = {Understanding TypeScript},
  year         = 2014,
  booktitle    = {{ECOOP} 2014 - Object-Oriented Programming - 28th
          European Conference, Uppsala, Sweden, July 28 -
          August 1, 2014. Proceedings},
  pages        = {257-281},
  doi          = {10.1007/978-3-662-44202-9\_11},
  url          = {https://doi.org/10.1007/978-3-662-44202-9\_11},
  timestamp    = {Tue, 18 Jul 2017 16:43:00 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/ecoop/BiermanAT14},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Type inference in mathematics :type_inference_in_math:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Online{type_inference_in_math,
  author       = {Jeremy Avigad},
  title        = {{Type inference in mathematics}},
  year         = 2011,
  archiveprefix= {arXiv},
  eprint       = {1111.5885v2},
  primaryclass = {cs.LO}
}
#+END_SRC

** First-class modules for component-based programming: Case for support :first_class_modules_support:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@misc{first_class_modules_support,
title={First-class modules for component-based programming: Case for support}, url={https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.5793}, journal={CiteSeerX}}
#+END_SRC

** Using Dependent Types to Express Modular Structure :dtls_give_modules:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{dtls_give_modules,
  author       = {David B. MacQueen},
  title        = {Using Dependent Types to Express Modular Structure},
  year         = 1986,
  booktitle    = {Conference Record of the Thirteenth Annual {ACM}
          Symposium on Principles of Programming Languages,
          St. Petersburg Beach, Florida, USA, January 1986},
  pages        = {277-286},
  doi          = {10.1145/512644.512670},
  url          = {https://doi.org/10.1145/512644.512670},
  timestamp    = {Tue, 06 Nov 2018 11:07:43 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/popl/MacQueen86},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** (Re-)Creating sharing in Agda's GHC backend :perna:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@misc{perna, title={(Re-)Creating sharing in Agda's GHC backend}, url={https://macsphere.mcmaster.ca/handle/11375/22177}, journal={MacSphere}, author={Natalie Perna}, year={2017}, month={Jan}}
#+END_SRC
** A New Style of Proof for Mathematics Organized as a Network of Axiomatic Theories :purposes_of_proof:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Online{purposes_of_proof,
  author       = {William M. Farmer},
  title        = {{A New Style of Proof for Mathematics Organized as a
          Network of Axiomatic Theories}},
  year         = 2018,
  archiveprefix= {arXiv},
  eprint       = {1806.00810v2},
  primaryclass = {cs.LO}
}
#+END_SRC

** Backpack: retrofitting Haskell with interfaces} :haskell_backpack:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{haskell_backpack,
  author       = {Scott Kilpatrick and Derek Dreyer and Simon
          L. {Peyton Jones} and Simon Marlow},
  title        = {Backpack: retrofitting Haskell with interfaces},
  year         = 2014,
  booktitle    = {The 41st Annual {ACM} {SIGPLAN-SIGACT} Symposium on
          Principles of Programming Languages, {POPL} '14, San
          Diego, CA, USA, January 20-21, 2014},
  pages        = {19-32},
  doi          = {10.1145/2535838.2535884},
  url          = {https://doi.org/10.1145/2535838.2535884},
  timestamp    = {Tue, 06 Nov 2018 11:07:43 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/popl/KilpatrickDJM14},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** The next 700 syntactical models of type theory :seven_hundred_tt_models:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{seven_hundred_tt_models,
  author       = {Simon Boulier and Pierre{-}Marie P{\'{e}}drot and
          Nicolas Tabareau},
  title        = {The next 700 syntactical models of type theory},
  year         = 2017,
  booktitle    = {Proceedings of the 6th {ACM} {SIGPLAN} Conference on
          Certified Programs and Proofs, {CPP} 2017, Paris,
          France, January 16-17, 2017},
  pages        = {182-194},
  doi          = {10.1145/3018610.3018620},
  url          = {https://doi.org/10.1145/3018610.3018620},
  timestamp    = {Tue, 06 Nov 2018 16:59:23 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/cpp/BoulierPT17},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Isabelle: The Next 700 Theorem Provers            :seven_hundred_provers:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{seven_hundred_provers,
  author       = {Lawrence C. Paulson},
  title        = {Isabelle: The Next 700 Theorem Provers},
  year         = 1993,
  volume       = {cs.LO/9301106},
  url          = {http://arxiv.org/abs/cs.LO/9301106},
  journal      = {CoRR},
  timestamp    = {Mon, 13 Aug 2018 16:48:11 +0200},
  biburl       =
          {https://dblp.org/rec/bib/journals/corr/cs-LO-9301106},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** The Next 700 Challenge Problems for Reasoning with HOAS
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{seven_hundred_hoas,
  author       = {Amy P. Felty and Alberto Momigliano and Brigitte
          Pientka},
  title        = {The Next 700 Challenge Problems for Reasoning with
          Higher-Order Abstract Syntax Representations - Part
          2 - {A} Survey},
  year         = 2015,
  volume       = 55,
  number       = 4,
  pages        = {307-372},
  doi          = {10.1007/s10817-015-9327-3},
  url          = {https://doi.org/10.1007/s10817-015-9327-3},
  journal      = {J. Autom. Reasoning},
  timestamp    = {Fri, 15 Sep 2017 17:21:46 +0200},
  biburl       = {https://dblp.org/rec/bib/journals/jar/FeltyMP15},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** The next 700 programming libraries
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{seven_hundred_libraries,
  author       = {Ant{\'{o}}nio Menezes Leit{\~{a}}o},
  title        = {The next 700 programming libraries},
  year         = 2007,
  booktitle    = {International Lisp Conference, {ILC} 2007,
          Cambridge, UK, April 1-4, 2007},
  pages        = 21,
  doi          = {10.1145/1622123.1622147},
  url          = {https://doi.org/10.1145/1622123.1622147},
  crossref     = {DBLP:conf/lfp/2007},
  timestamp    = {Tue, 06 Nov 2018 16:58:56 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/lfp/Leitao07},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** The next 700 programming languages
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{seven_hundred_langs,
  author       = {Peter J. Landin},
  title        = {The next 700 programming languages},
  year         = 1966,
  volume       = 9,
  number       = 3,
  pages        = {157-166},
  doi          = {10.1145/365230.365257},
  url          = {https://doi.org/10.1145/365230.365257},
  journal      = {Commun. {ACM}},
  timestamp    = {Wed, 14 Nov 2018 10:22:35 +0100},
  biburl       = {https://dblp.org/rec/bib/journals/cacm/Landin66},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** The next 700 data description languages
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{seven_hundred_data,
  author       = {Kathleen Fisher and Yitzhak Mandelbaum and David
          Walker},
  title        = {The next 700 data description languages},
  year         = 2010,
  volume       = 57,
  number       = 2,
  pages        = {10:1--10:51},
  doi          = {10.1145/1667053.1667059},
  url          = {https://doi.org/10.1145/1667053.1667059},
  journal      = {J. {ACM}},
  timestamp    = {Tue, 06 Nov 2018 12:51:46 +0100},
  biburl       = {https://dblp.org/rec/bib/journals/jacm/FisherMW10},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Locales and Locale Expressions in Isabelle/Isar :locales:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{locales,
  author       = {Clemens Ballarin},
  title        = {Locales and Locale Expressions in Isabelle/Isar},
  year         = 2003,
  booktitle    = {Types for Proofs and Programs, International
          Workshop, {TYPES} 2003, Torino, Italy, April 30 -
          May 4, 2003, Revised Selected Papers},
  pages        = {34-50},
  doi          = {10.1007/978-3-540-24849-1\_3},
  url          = {https://doi.org/10.1007/978-3-540-24849-1\_3},
  timestamp    = {Thu, 15 Jun 2017 21:39:32 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/types/Ballarin03},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** All about maude :maude:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Book{maude,
  title        = {All About Maude - {A} High-Performance Logical
          Framework, How to Specify, Program and Verify
          Systems in Rewriting Logic},
  year         = 2007,
  editor       = {Manuel Clavel and Francisco Dur{\'{a}}n and Steven
          Eker and Patrick Lincoln and Narciso
          Mart{\'{\i}}{-}Oliet and Jos{\'{e}} Meseguer and
          Carolyn L. Talcott},
  volume       = 4350,
  series       = {Lecture Notes in Computer Science},
  publisher    = {Springer},
  isbn         = {978-3-540-71940-3},
  doi          = {10.1007/978-3-540-71999-1},
  url          = {https://doi.org/10.1007/978-3-540-71999-1},
  timestamp    = {Wed, 14 Mar 2018 11:45:08 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/maude/2007},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Beluga: Programming with Dependent Types, Contextual                  Data, and Contexts :beluga:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{beluga,
  author       = {Brigitte Pientka},
  title        = {Beluga: Programming with Dependent Types, Contextual
          Data, and Contexts},
  year         = 2010,
  booktitle    = {Functional and Logic Programming, 10th International
          Symposium, {FLOPS} 2010, Sendai, Japan, April 19-21,
          2010. Proceedings},
  pages        = {1-12},
  doi          = {10.1007/978-3-642-12251-4\_1},
  url          = {https://doi.org/10.1007/978-3-642-12251-4\_1},
  timestamp    = {Sun, 21 May 2017 00:19:14 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/flops/Pientka10},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Canonical Structures for the working Coq user :coq_canonical_tutorial:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{coq_canonical_tutorial,
  author       = {Mahboubi, Assia and Tassi, Enrico},
  title        = {{Canonical Structures for the working Coq user}},
  year         = 2013,
  booktitle    = {{ITP 2013, 4th Conference on Interactive Theorem
          Proving}},
  editor       = {Sandrine Blazy and Christine Paulin and David
          Pichardie},
  volume       = 7998,
  series       = {LNCS},
  publisher    = {{Springer}},
  month        = Jul,
  pages        = {19-34},
  doi          = {10.1007/978-3-642-39634-2\_5},
  url          = {https://hal.inria.fr/hal-00816703},
  address      = {Rennes, France},
  pdf          = {https://hal.inria.fr/hal-00816703/file/main.pdf},
  hal_id       = {hal-00816703},
  hal_version  = {v2}
}
#+END_SRC

** How to make ad hoc proof automation less ad hoc           :coq_canonical:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{coq_canonical,
  author       = {Georges Gonthier and Beta Ziliani and Aleksandar
          Nanevski and Derek Dreyer},
  title        = {How to make ad hoc proof automation less ad hoc},
  year         = 2013,
  volume       = 23,
  number       = 4,
  pages        = {357-401},
  doi          = {10.1017/S0956796813000051},
  url          = {https://doi.org/10.1017/S0956796813000051},
  journal      = {J. Funct. Program.},
  timestamp    = {Sat, 27 May 2017 14:24:34 +0200},
  biburl       = {https://dblp.org/rec/bib/journals/jfp/GonthierZND13},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Mizar Course in Logic and Set Theory :mizar_logic_course:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InCollection{mizar_logic_course,
   author = {Borak, Ewa and Zalewska, Anna},
   affiliation = {University of Bialystok, Institute of Computer Science, Bia≈Çystok Poland},
   title = {Mizar Course in Logic and Set Theory},
   booktitle = {Towards Mechanized Mathematical Assistants},
   series = {Lecture Notes in Computer Science},
   editor = {Kauers, Manuel and Kerber, Manfred and Miner, Robert and Windsteiger, Wolfgang},
   publisher = Springer,
   pages = {191--204},
   volume = {4573},
   DOIURL = {http://dx.doi.org/10.1007/978-3-540-73086-6_17},
   DOI = {10.1007/978-3-540-73086-6_17},
   abstract = {From the very beginning of the development of the Mizar system experiments with using Mizar as a tool for teaching mathematics have been conducted. Numerous organized courses were based on different versions of the system: starting from the first implementation of its processor, through Mizar-MSE, Mizar‚Äì4 and PC‚ÄìMizar up till its present version. Now Mizar with its mathematical library gives us quite new didactic possibilities.  The purpose of this paper is to present a certain course on logic and set theory offered by our Institute for freshman students. The course employs Mizar as the main tool of instruction. In the paper we discuss the organization of this course and describe some examples of students‚Äô tasks. Finally, some conclusions and remarks are given.},
   year = {2007}
}
#+END_SRC
** Mizar in a Nutshell :mizar_nutshell:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{mizar_nutshell,
  author =       {Grabowski, Adam and Korni{\l}owicz, Artur and Naumowicz, Adam},
  title =        {Mizar in a Nutshell},
  journal =      {J.~Formalized Reasoning},
  year =         2010,
  volume =    3,
  number =    2,
  pages =     {153--245}
}
#+END_SRC

** Theory Interpretation in Simple Type Theory :theory_interpretations_farmer:

#+BEGIN_SRC latex :tangle MyReferences.bib :exports none
@proceedings{theory_interpretations_farmer,
    author={William M. Farmer},
    title={Theory Interpretation in Simple Type Theory},
    year={1993},
    month={September},
    Journal={International Workshop on Higher-Order Algebra, Logic, and Term Rewriting},
    publisher={Springer-Verlag},
    ISBN={3-540-58233-9},
    url={http://imps.mcmaster.ca/doc/interpretations.pdf},
    keywords = {theory interpretations; axiomatic method; interactive theorem proving},
    abstract = {Theory interpretation is a logical technique for relating one
        axiomatic theory to another with important applications in mathematics
        and computer science as well as in logic itself. This paper presents a
        method for theory interpretation in a version of simple type theory, called
        lutins, which admits partial functions and subtypes. The method is
        patterned on the standard approach to theory interpretation in firstorder
        logic. Although the method is based on a nonclassical version of
        simple type theory, it is intended as a guide for theory interpretation in
        classical simple type theories as well as in predicate logics with partial
        functions.},
    note={Theory interpretations formalise folklore of subtheories inheriting properties
      from parent theories such as satisfiability and consistency.

      The idea of interpreting a theory into itself is commonly done in the RATH-Agda project,
      for example, to obtain dual results such as those for lattices and other categorical structures.
    },
}
#+END_SRC
#
** Dependent Types Ensure Partial Correctness of Theorem Provers :twelf_proves_tp_correctness:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{twelf_proves_tp_correctness,
  author       = {Andrew W. Appel and Amy P. Felty},
  title        = {Dependent types ensure partial correctness of
          theorem provers},
  year         = 2004,
  volume       = 14,
  number       = 1,
  pages        = {3-19},
  doi          = {10.1017/S0956796803004921},
  url          = {https://doi.org/10.1017/S0956796803004921},
  journal      = {J. Funct. Program.},
  timestamp    = {Sat, 27 May 2017 14:24:34 +0200},
  biburl       = {https://dblp.org/rec/bib/journals/jfp/AppelF04},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** {IDRIS} --- Systems Programming Meets Full Dependent Types :idris_main:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{idris_main,
 author = {Brady, Edwin C.},
 title = {{IDRIS} --- Systems Programming Meets Full Dependent Types},
 booktitle = {Proceedings of the 5th ACM workshop on Programming languages meets program verification},
 series = {PLPV '11},
 year = {2011},
 isbn = {978-1-4503-0487-0},
 location = {Austin, Texas, USA},
 pages = {43--54},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1929529.1929536},
 doi = {http://doi.acm.org/10.1145/1929529.1929536},
 acmid = {1929536},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data description, dependent types},
 abstract = {Dependent types have emerged in recent years as a promising approach to ensuring program
correctness. However, existing dependently typed languages such as Agda and Coq work at a very high
level of abstraction, making it difficult to map verified programs to suitably efficient executable code.
This is particularly problematic for programs which work with bit level data, e.g. network packet
processing, binary file formats or operating system services. Such programs, being fundamental to the
operation of computers in general, may stand to benefit significantly from program verification techniques.
This paper describes the use of a dependently typed programming language, Idris, for specifying and verifying
properties of low-level systems programs, taking network packet processing as an extended example.
We give an overview of the distinctive features of Idris which allow it to interact with external systems code,
with precise types. Furthermore, we show how to integrate tactic scripts and plugin decision procedures to
reduce the burden of proof on application developers. The ideas we present are readily adaptable to languages
with related type systems.}
}
#+END_SRC

** The {Coq} Reference Manual, version 8.4/8.8                  :coq_manual:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Misc{coq_manual,
  author       = {The {Coq Development Team}},
  title        = {{The Coq Proof Assistant, version 8.8.0}},
  year         = 2018,
  month        = Apr,
  doi          = {10.5281/zenodo.1219885},
  url          = {https://hal.inria.fr/hal-01954564},
  hal_id       = {hal-01954564},
  hal_version  = {v1},
}
#+END_SRC

#+BEGIN_SRC latex :tangle no
@Manual{coq_manual,
  author      = {The {Coq Development Team}},
  title       = {The {Coq} Reference Manual, version 8.4},
  month       = Aug,
  year        = {2012},
  note        = {Available electronically at \url{http://coq.inria.fr/doc}}
}
#+END_SRC
** COMMENT Mechanizing the Metatheory of {LF} :twelf_mechanise_lf:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@TechReport{twelf_mechanise_lf,
  author =	 Christian Urban and James Cheney and Stefan Berghofer,
  title =	 {Mechanizing the Metatheory of {LF}},
  institution =  {arXiv.org},
  year =	 2008,
  number =	 {arXiv:0804.1667v1 [cs.LO]},
  month =	 APR,
  note = {Expanded technical report for LICS 2008 conference paper},
  URL =		 {http://arxiv.org/abs/0804.1667v1},
  WKloc = {doc/pap/BIB},
  bibliographies = {HHOL},
  abstract =	 {LF is a dependent type theory in which many other
          formal systems can be conveniently
          embedded. However, correct use of LF relies on
          nontrivial metatheoretic developments such as proofs
          of correctness of decision procedures for LF's
          judgments. Although detailed informal proofs of
          these properties have been published, they have not
          been formally verified in a theorem prover. We have
          formalized these properties within Isabelle/HOL
          using the Nominal Datatype Package, closely
          following a recent article by Harper and
          Pfenning. In the process, we identified and resolved
          a gap in one of the proofs and a small number of
          minor lacunae in others. Besides its intrinsic
          interest, our formalization provides a foundation
          for studying the adequacy of LF encodings, the
          correctness of Twelf-style metatheoretic reasoning,
          and the metatheory of extensions to LF.}
}
#+END_SRC
** COMMENT Pattern Matching with Dependent Types :dtl_pattern_matching:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{dtl_pattern_matching,
  author =	 {Thierry Coquand},
  title =	 {Pattern Matching with Dependent Types},
  booktitle =	 {Electronic Proceedings of the
    Third Annual {BRA} Workshop on Logical Frameworks
    ({B{\oring{a}}stad, Sweden})},
  year =	 1992,
}
#+END_SRC
** COMMENT An Algorithm for Type-Checking Dependent Types :dtl_type_checking:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Misc{dtl_type_checking,
  author = Thierry Coquand,
  title = {An Algorithm for Type-Checking Dependent Types},
  year = 1996,
}
#+END_SRC
** TODO COMMENT ‚ÄúTo Read‚Äù A Logical Framework with Dependently Typed Records
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{Coquand-Pollack-Takeyama-2005,
  author =	 {Thierry Coquand and Randy Pollack and Makoto Takeyama},
  title =	 {A Logical Framework with Dependently Typed Records},
  journal =	 FUNDI,
  year =	 2005,
  volume =	 65,
  number =	 {1--2},
  pages =	 {113--134},
  bibliographies = {HHOL},
  annote = {see \url{http://unit.aist.go.jp/cvs/Agda/} for Agda}
}
#+END_SRC

** TODO COMMENT ‚ÄúTo Read‚Äù Interfaces as functors, programs as coalgebras --- A final coalgebra theorem in intensional type theory
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{Michelbrink-2006,
  author =	 {Markus Michelbrink},
  title =	 {Interfaces as functors, programs as coalgebras ---
          A final coalgebra theorem in intensional type theory},
  journal =	 TCS,
  year =	 {2006},
  OPTkey =	 {},
  OPTvolume =	 {360},
  OPTnumber =	 {1--3},
  OPTpages =	 {415--439},
  OPTmonth =	 AUG,
  DOI =		 {http://dx.doi.org/10.1016/j.tcs.2006.05.033},
  WKloc = {doc/pap/BIB},
  abstract =	 {In [P. Hancock, A. Setzer, Interactive programs in dependent type theory, in: P. Clote, H. Schwichtenberg (Eds.), Proc. 14th Annu. Conf. of EACSL, CSL'00, Fischbau, Germany, 21--26 August 2000, Vol. 1862, Springer, Berlin, 2000, pp. 317--331, \url{citeseer.ist.psu.edu/article/hancock00interactive.html}; P. Hancock, A. Setzer, Interactive programs and weakly final coalgebras in dependent type theory, in: L. Crosilla, P. Schuster (Eds.), From Sets and Types to Topology and Analysis. Towards Practicable Foundations for Constructive Mathematics, Oxford Logic Guides, Clarendon Press, 2005, \url{www.cs.swan.ac.uk/~csetzer/}] Hancock and Setzer introduced rules to extend Martin-L√∂f's type theory in order to represent interactive programming. The rules essentially reflect the existence of weakly final coalgebras for a general form of polynomial functor. The standard rules of dependent type theory allow the definition of inductive types, which correspond to initial algebras. Coalgebraic types are not represented in a direct way. In this article we show the existence of final coalgebras in intensional type theory for these kind of functors, where we require uniqueness of identity proofs $...$ for the set of states $...$ and the set of commands $...$ which determine the functor. We obtain the result by identifying programs which have essentially the same behaviour, viz. are bisimular. This proves the rules of Setzer and Hancock admissible in ordinary type theory, if we replace definitional equality by bisimulation. All proofs [M. Michelbrink, Verifications of final coalgebra theorem in: Interfaces as Functors, Programs as Coalgebras --- A Final Coalgebra Theorem in Intensional Type Theory, 2005, \url{www.cs.swan.ac.uk/~csmichel/}] are verified in the theorem prover agda [C. Coquand, Agda, Internet, \url{www.cs.chalmers.se/~catarina/agda/}; K. Peterson, A programming system for type theory, Technical Report, S-412 96, Chalmers University of Technology, G√∂teborg, 1982], which is based on intensional Martin-L√∂f type theory.}
}
#+END_SRC

** Experience Implementing a Performant Category-Theory Library in {C}oq :coq_cat_experiences:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Online{coq_cat_experiences,
  author       = {Jason Gross AND Adam Chlipala AND David I. Spivak},
  title        = {{Experience Implementing a Performant
          Category-Theory Library in Coq}},
  year         = 2014,
  archiveprefix= {arXiv},
  eprint       = {1401.7694v2},
  primaryclass = {math.CT}
}
#+END_SRC
** Certified Functional Programming --- Program Extraction within {Coq} Proof Assistant :coq_program_extraction:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@PhdThesis{coq_program_extraction,
  author =	 {Pierre Letouzey},
  title =	 {Certified Functional Programming --- Program Extraction within {Coq} Proof Assistant},
  school =	 {Universit\'e Paris 7 Denis Diderot},
  year =	 2004,
  address =	 {Jussieu},
  month =	 JUL,
  URL =		 {http://www.pps.jussieu.fr/~letouzey/download/these_letouzey_English.ps.gz},
}
#+END_SRC
** The Calculus of Inductive Definitions and its Implementation: the Coq Proof Assistant :coq_implementation:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{coq_implementation,
  author = {Christine Paulin-Mohring},
  title = {The Calculus of Inductive Definitions and its
          Implementation: the Coq Proof Assistant},
  crossref = {LPAR94},
  note = {invited tutorial},
  authorsAddress = {LIP/ENS Lyon  cpaulin\@lip.ens-lyon.fr},
  abstract = {Type Theory serves as a basis for several environments
          dedicated to the formalization of reasoning. We
          shall present the theory and practice of one of
          them: the Coq Proof Assistant.

          This environment is based on a typed lambda-calculus
          called the Calculus of Inductive Definitions. It is
          a powerful language which extends the Calculus of
          Constructions, introduced by Coquand and Huet, with
          a mechanism for general inductive definitions in the
          spirit of Martin-Lof's Intuitionistic Type Theory.

          The Coq proof assistant can be decomposed into three parts.
          \begin{itemize}
          \item A specification language which combines
          higher-order logic, functional programming and
          inductive definitions of relations.
          \item A tactic language which provides several tools
          for the interactive development of proofs of formulas.
          \item An environment for manipulating  proof-terms
          built by the system, especially for extracting ML
          programs out of constructive proofs of specifications.
          \end{itemize}},
}
#+END_SRC
** Program Calculation in Coq :coq_program_calculation:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{coq_program_calculation,
   author = {Tesson, Julien and Hashimoto, Hideki and Hu, Zhenjiang and Loulergue, Fr√©d√©ric and Takeichi, Masato},
   affiliation = {LIFO, Universit√© d‚ÄôOrl√©ans, France},
   title = {Program Calculation in Coq},
   crossref = {AMAST2010},
   pages = {163-179},
   DOIURL = {http://dx.doi.org/10.1007/978-3-642-17796-5_10},
   DOI = {10.1007/978-3-642-17796-5_10},
   abstract = {Program calculation, being a programming technique that derives programs from specification by means of formula manipulation, is a challenging activity. It requires human insights and creativity, and needs systems to help human to focus on clever parts of the derivation by automating tedious ones and verifying correctness of transformations. Different from many existing systems, we show in this paper that Coq, a popular theorem prover, provides a cheap way to implement a powerful system to support program calculation, which has not been recognized so far. We design and implement a set of tactics for the Coq proof assistant to help the user to derive programs by program calculation and to write proofs in calculational form. The use of these tactics is demonstrated through program calculations in Coq based on the theory of lists.},
}
#+END_SRC
** A Brief Overview of Agda --- A Functional Language with Dependent Types :agda_overview:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InCollection{agda_overview,
  author = {Ana Bove and Peter Dybjer and Ulf Norell},
  title = {A Brief Overview of {Agda} --- A Functional Language with Dependent Types},
  crossref =  {TPHOL2009},
  pages =     {73--78},
  DOIURL = {https://doi.org/10.1007/978-3-642-03359-9_6},
  DOI = {10.1007/978-3-642-03359-9_6},
  abstract = {We give an overview of Agda, the latest in a series
    of dependently typed programming languages developed in Gothenburg.
    Agda is based on Martin-L√∂f‚Äôs intuitionistic type theory
    but extends it with numerous programming language features.
    It supports a wide range of inductive data types,
    including inductive families and inductive-recursive types,
    with associated flexible pattern-matching.
    Unlike other proof assistants, Agda is not tactic-based.
    Instead it has an Emacs-based interface which allows
    programming by gradual refinement of incomplete type-correct terms.},
}
#+END_SRC
** Towards a Practical Programming Language Based on Dependent Type Theory :agda_thesis:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@PhdThesis{agda_thesis,
  author =	 {Ulf Norell},
  title =	 {Towards a Practical Programming Language Based on Dependent Type Theory},
  OPTschool  = {Department of Computer Science and Engineering, Chalmers University of Technology},
  school  = {Dept.\null{} Comp.\null{} Sci.\null{} and Eng., Chalmers Univ.\null{} of Technology},
  year =	 2007,
  month = SEP,
  DirectURL =	 {http://www.cs.chalmers.se/~ulfn/papers/thesis.html},
  WKloc =	 {doc/pap/BIB},
  note = {See also \href{http://wiki.portal.chalmers.se/agda/pmwiki.php}{\textsf{http://wiki.portal.chalmers.se/agda/pmwiki.php}}},
  abstract =	 {Dependent type theories have a long history
    of being used for theorem proving.
    One aspect of type theory
    which makes it very powerful as a proof language
    is that it mixes deduction with computation.
    This also makes type theory a good candidate for programming ---
    the strength of the type system allows properties of programs
    to be stated and established,
    and the computational properties provide semantics for the programs.

    This thesis is concerned with bridging the gap
    between the theoretical presentations of type theory
    and the requirements on a practical programming language.
    Although there are many challenging research problems
    left to solve before we have
    an industrial scale programming language based on type theory,
    this thesis takes us a good step along the way.

    In functional programming languages
    pattern matching provides a concise notation for defining functions.
    In dependent type theory, pattern matching becomes even more powerful,
    in that inspecting the value of a particular term
    can reveal information about the types and values of other terms.
    In this thesis we give a type checking algorithm
    for definitions by pattern matching in type theory,
    supporting overlapping patterns,
    and pattern matching on intermediate results using the with rule.

    Traditional presentations of type theory
    suffers from rather verbose notation,
    cluttering programs and proofs with,
    for instance, explicit type information.
    One solution to this problem is to allow
    terms that can be inferred automatically to be omitted.
    This is usually implemented
    by inserting metavariables in place of the omitted terms
    and using unification to solve these metavariables during type checking.
    We present a type checking algorithm for a theory with metavariables
    and prove its soundness
    independent of whether the metavariables are solved or not.

    In any programming language it is important
    to be able to structure large programs into separate units or modules
    and limit the interaction between these modules.
    In this thesis we present a simple, but powerful module system
    for a dependently typed language.
    The main focus of the module system
    is to manage the name space of a program,
    and an important characteristic
    is a clear separation between the module system and the type checker,
    making it largely independent of the underlying language.

    As a side track,
    not directly related to the use of type theory for programming,
    we present a connection between type theory
    and a first-order logic theorem prover.
    This connection saves the user the burden of proving simple,
    but tedious first-order theorems by leaving them for the prover.
    We use a transparent translation to first-order logic
    which makes the proofs constructed by the theorem prover human readable.
    The soundness of the connection is established by a general metatheorem.

    Finally we put our work into practise
    in the implementation of a programming language, Agda,
    based on type theory.
    As an illustrating example we show how to program
    a simple certfied prover for equations in a commutative monoid,
    which can be used internally in Agda.
    Much more impressive examples have been done by others,
    showing that the ideas developed in this thesis are viable in practise. },
}
#+END_SRC
** Working with Mathematical Structures in Type Theory :math_structs_in_types:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{math_structs_in_types,
  author       = {Claudio Sacerdoti Coen and Enrico Tassi},
  title        = {Working with Mathematical Structures in Type Theory},
  year         = 2007,
  booktitle    = {Types for Proofs and Programs, International
          Conference, {TYPES} 2007, Cividale del Friuli,
          Italy, May 2-5, 2007, Revised Selected Papers},
  pages        = {157-172},
  doi          = {10.1007/978-3-540-68103-8\_11},
  url          = {https://doi.org/10.1007/978-3-540-68103-8\_11},
  timestamp    = {Thu, 15 Jun 2017 21:39:32 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/types/CoenT07},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** The Zipper                                                       :zipper:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{zipper,
 author = {Huet, G{\'e}rard},
 title = {The Zipper},
 journal = {J. Funct. Program.},
 issue_date = {September 1997},
 volume = {7},
 number = {5},
 month = sep,
 year = {1997},
 issn = {0956-7968},
 pages = {549--554},
 numpages = {6},
 url = {http://dx.doi.org/10.1017/S0956796897002864},
 doi = {10.1017/S0956796897002864},
 acmid = {969872},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
 abstract={Almost every programmer has faced the problem of representing a tree together
       with a subtree that is the focus of attention, where that focus may move left,
       right, up or down the tree. The Zipper is Huet's nifty name for a nifty data
       structure which fulfills this need. I wish I had known of it when I faced this
       task, because the solution I came up with was not quite so efficient or elegant
       as the Zipper.},
 keywords = {functional programming, zipper},
 note={
     A succinct introduction to focusing onto particular neighbourhoods within
     a data structure is provided. Along with the definitions of primitives to
     move up and down the structure. Then the results are generalised to first
     order terms, thereby providing a notion of neighbourhood-focusing for terms
     formed from a given signature. Neat stuff.
    },
}
#+END_SRC

** Reason Isomorphically!                                    :iso_reasoning:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{iso_reasoning,
 author = {Hinze, Ralf and James, Daniel W.H.},
 title = {Reason Isomorphically!},
 booktitle = {Proceedings of the 6th ACM SIGPLAN Workshop on Generic Programming},
 series = {WGP '10},
 year = {2010},
 isbn = {978-1-4503-0251-7},
 location = {Baltimore, Maryland, USA},
 pages = {85--96},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1863495.1863507},
 doi = {10.1145/1863495.1863507},
 acmid = {1863507},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adjunctions, category theory, isomorphism, yoneda lemma},
 abstract = {When are two types the same? In this paper we argue that isomorphism is a
        more useful notion than equality. We explain a succinct and elegant
        approach to establishing isomorphisms, with our focus on showing their
        existence over deriving the witnesses. We use category theory as a
        framework, but rather than chasing diagrams or arguing with arrows,
        we present our proofs in a calculational style. In particular, we hope to
        showcase to the reader why the Yoneda lemma and adjunctions should be in
        their reasoning toolbox.},
 note={
     An excellent paper summarising elementary category theory with the practical
     aim of showing that rose trees and binary trees, and others, are isomorphic.

     It uses a calculational approach to show that isomorphisms can be proven by
     working with types, i.e., functors, rather than necessarily explicitly providing
     two arrows that are inverse.

     They also provide a theory of fixpoints and a flurry of functional programming
     examples and remarks.
    },
}
#+END_SRC

** Little Theories                                         :little_theories:

#+BEGIN_SRC latex :tangle MyReferences.bib :exports none

@InProceedings{little_theories,
author="Farmer, William M.
and Guttman, Joshua D.
and Javier Thayer, F.",
editor="Kapur, Deepak",
title="Little theories",
booktitle="Automated Deduction---CADE-11",
year="1992",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="567--581",
abstract="In the ``little theories'' version of the axiomatic method, different portions of mathematics are developed in various different formal axiomatic theories. Axiomatic theories may be related by inclusion or by theory interpretation. We argue that the little theories approach is a desirable way to formalize mathematics, and we describe how IMPS, an Interactive Mathematical Proof System, supports it.",
isbn="978-3-540-47252-0"
}
#+END_SRC

** Agda Wiki :agda_wiki:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{agda_wiki,
  author = {The {Agda Team}},
  title = {Agda Wiki},
  year = 2018,
  url = {http://wiki.portal.chalmers.se/agda/pmwiki.php},
  urldate = {2018-10-12}
}
#+END_SRC
** Constructive Mathematics and Computer Programming :lof_constructive_math:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{lof_constructive_math,
 author = {Martin-L\"{o}f, P.},
 title = {Constructive Mathematics and Computer Programming},
 booktitle = {Proc. Of a Discussion Meeting of the Royal Society of London on Mathematical Logic and Programming Languages},
 year = {1985},
 isbn = {0-13-561465-1},
 location = {London, United Kingdom},
 pages = {167--184},
 numpages = {18},
 url = {http://dl.acm.org/citation.cfm?id=3721.3731},
 acmid = {3731},
 publisher = {Prentice-Hall, Inc.},
 address = {Upper Saddle River, NJ, USA},
}
#+END_SRC

** Intuitionistic type theory                                      :lof_itt:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{lof_itt,
  title={Intuitionistic type theory},
  author={Martin-L{\"o}f, P. and Sambin, G.},
  series={Studies in proof theory},
  url={https://books.google.ca/books?id=\_D0ZAQAAIAAJ},
  year={1984},
  publisher={Bibliopolis}
}
#+END_SRC

** Programming in Martin-Lo\&Uml;F's Type Theory: An Introduction

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{lof_programming,
 author = {Nordstr\"{o}m, Bengt and Petersson, Kent and Smith, Jan M.},
 title = {Programming in Martin-Lo\&Uml;F's Type Theory: An Introduction},
 year = {1990},
 isbn = {0-19-853814-6},
 publisher = {Clarendon Press},
 address = {New York, NY, USA},
}
#+END_SRC
** Coq Website :coq_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{coq_website,
  author = {The {Coq Team}},
  title = {The Coq Proof Assistant},
  year = 2018,
  url = {https://coq.inria.fr/},
  urldate = {2018-10-12}
}
#+END_SRC
** Inductively Defined Types in the Calculus of Constructions :coq_inductive_coc:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{coq_inductive_coc,
  author    = {Frank Pfenning and
           Christine Paulin{-}Mohring},
  title     = {Inductively Defined Types in the Calculus of Constructions},
  booktitle = {Mathematical Foundations of Programming Semantics, 5th International
           Conference, Tulane University, New Orleans, Louisiana, USA, March
           29 - April 1, 1989, Proceedings},
  pages     = {209--228},
  year      = {1989},
  crossref  = {DBLP:conf/mfps/1989},
  url       = {https://doi.org/10.1007/BFb0040259},
  doi       = {10.1007/BFb0040259},
  timestamp = {Fri, 19 May 2017 13:10:47 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/mfps/PfenningP89},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** The Calculus of Constructions :coq_coc:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{coq_coc,
  author    = {Thierry Coquand and
           G{\'{e}}rard P. Huet},
  title     = {The Calculus of Constructions},
  journal   = {Inf. Comput.},
  volume    = {76},
  number    = {2/3},
  pages     = {95--120},
  year      = {1988},
  url       = {https://doi.org/10.1016/0890-5401(88)90005-3},
  doi       = {10.1016/0890-5401(88)90005-3},
  timestamp = {Thu, 18 May 2017 09:54:18 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/iandc/CoquandH88},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Lean Website :lean_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{lean_website,
  author = {The {Lean Team}},
  title = {Lean Theorem Prover},
  year = 2018,
  url = {http://leanprover.github.io/},
  urldate = {2018-10-12}
}
#+END_SRC
** The Lean Theorem Prover (System Description)           :lean_system_desc:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{lean_system_desc,
  author    = {Leonardo Mendon{\c{c}}a de Moura and
           Soonho Kong and
           Jeremy Avigad and
           Floris van Doorn and
           Jakob von Raumer},
  title     = {The Lean Theorem Prover (System Description)},
  booktitle = {Automated Deduction - {CADE-25} - 25th International Conference on
           Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings},
  pages     = {378--388},
  year      = {2015},
  crossref  = {DBLP:conf/cade/2015},
  url       = {https://doi.org/10.1007/978-3-319-21401-6\_26},
  doi       = {10.1007/978-3-319-21401-6\_26},
  timestamp = {Sun, 21 May 2017 00:17:17 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cade/MouraKADR15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Formalizing Mathematics using the Lean Theorem Prover :lean_formalizing_math:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{lean_formalizing_math,
  author    = {Leonardo de Moura},
  title     = {Formalizing Mathematics using the Lean Theorem Prover},
  booktitle = {International Symposium on Artificial Intelligence and Mathematics,
           {ISAIM} 2016, Fort Lauderdale, Florida, USA, January 4-6, 2016.},
  year      = {2016},
  crossref  = {DBLP:conf/isaim/2016},
  url       = {http://isaim2016.cs.virginia.edu/papers/ISAIM2016\_Proofs\_DeMoura.pdf},
  timestamp = {Thu, 18 Jan 2018 13:13:58 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/isaim/Moura16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Type classes for mathematics in type theory :typeclasses_for_maths:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{typeclasses_for_maths,
  author    = {Bas Spitters and
           Eelis van der Weegen},
  title     = {Type classes for mathematics in type theory},
  journal   = {Mathematical Structures in Computer Science},
  volume    = {21},
  number    = {4},
  pages     = {795--825},
  year      = {2011},
  url       = {https://doi.org/10.1017/S0960129511000119},
  doi       = {10.1017/S0960129511000119},
  timestamp = {Wed, 14 Jun 2017 20:39:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/mscs/SpittersW11},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Theories as Types :theories_as_types:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{theories_as_types,
  author    = {Dennis M{\"{u}}ller and
           Florian Rabe and
           Michael Kohlhase},
  title     = {Theories as Types},
  booktitle = {Automated Reasoning - 9th International Joint Conference, {IJCAR}
           2018, Held as Part of the Federated Logic Conference, FloC 2018, Oxford,
           UK, July 14-17, 2018, Proceedings},
  pages     = {575--590},
  year      = {2018},
  crossref  = {DBLP:conf/cade/2018},
  url       = {https://doi.org/10.1007/978-3-319-94205-6\_38},
  doi       = {10.1007/978-3-319-94205-6\_38},
  timestamp = {Mon, 09 Jul 2018 13:01:56 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cade/MullerRK18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** A calculus of open modules: call-by-need strategy and confluence :open_modules:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{open_modules,
  author    = {Sonia Fagorzi and
           Elena Zucca},
  title     = {A calculus of open modules: call-by-need strategy and confluence},
  journal   = {Mathematical Structures in Computer Science},
  volume    = {17},
  number    = {4},
  pages     = {675--751},
  year      = {2007},
  url       = {https://doi.org/10.1017/S0960129507006238},
  doi       = {10.1017/S0960129507006238},
  timestamp = {Sun, 28 May 2017 13:25:37 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/mscs/FagorziZ07},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** A Theory of Mixin Modules: Algebraic Laws and Reduction Semantics :mixin_modules:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{mixin_modules,
  author    = {Davide Ancona and
           Elena Zucca},
  title     = {A Theory of Mixin Modules: Algebraic Laws and Reduction Semantics},
  journal   = {Mathematical Structures in Computer Science},
  volume    = {12},
  number    = {6},
  pages     = {701--737},
  year      = {2002},
  url       = {https://doi.org/10.1017/S0960129502003687},
  doi       = {10.1017/S0960129502003687},
  timestamp = {Sun, 28 May 2017 13:25:37 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/mscs/AnconaZ02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** A Cateogry-Theoretic Account of Program Modules :modules_categorically:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{modules_categorically,
  author    = {Eugenio Moggi},
  title     = {A Cateogry-Theoretic Account of Program Modules},
  journal   = {Mathematical Structures in Computer Science},
  volume    = {1},
  number    = {1},
  pages     = {103--139},
  year      = {1991},
  url       = {https://doi.org/10.1017/S0960129500000074},
  doi       = {10.1017/S0960129500000074},
  timestamp = {Sun, 28 May 2017 13:25:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/mscs/Moggi91},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** An Agda Formalization Asynchronous Fixed-Point Theory :agda_fixpoints:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{agda_fixpoints,
  author    = {Ran Zmigrod and
           Matthew L. Daggitt and
           Timothy G. Griffin},
  title     = {An Agda Formalization of {\"{U}}resin and Dubois' Asynchronous
           Fixed-Point Theory},
  booktitle = {Interactive Theorem Proving - 9th International Conference, {ITP}
           2018, Held as Part of the Federated Logic Conference, FloC 2018, Oxford,
           UK, July 9-12, 2018, Proceedings},
  pages     = {623--639},
  year      = {2018},
  crossref  = {DBLP:conf/itp/2018},
  url       = {https://doi.org/10.1007/978-3-319-94821-8\_37},
  doi       = {10.1007/978-3-319-94821-8\_37},
  timestamp = {Wed, 03 Oct 2018 12:55:05 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/itp/ZmigrodDG18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Formalizing Constructive Quantifier Elimination in Agda :agda_quantifier_elim:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{agda_quantifier_elim,
  author    = {Jeremy Pope},
  title     = {Formalizing Constructive Quantifier Elimination in Agda},
  booktitle = {Proceedings of the 7th Workshop on Mathematically Structured Functional
           Programming, MSFP@FSCD 2018, Oxford, UK, 8th July 2018.},
  pages     = {2--17},
  year      = {2018},
  crossref  = {DBLP:journals/corr/abs-1807-03732},
  url       = {https://doi.org/10.4204/EPTCS.275.2},
  doi       = {10.4204/EPTCS.275.2},
  timestamp = {Mon, 10 Sep 2018 16:20:34 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-04083},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Modelling Bitcoin in Agda :agda_bitcoin:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{agda_bitcoin,
  author    = {Anton Setzer},
  title     = {Modelling Bitcoin in Agda},
  journal   = {CoRR},
  volume    = {abs/1804.06398},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.06398},
  archivePrefix = {arXiv},
  eprint    = {1804.06398},
  timestamp = {Mon, 13 Aug 2018 16:46:25 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-06398},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Proving Non-Deterministic Computations in Agda :agda_nondeterministic:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{agda_nondeterministic,
  author    = {Sergio Antoy and
           Michael Hanus and
           Steven Libby},
  title     = {Proving Non-Deterministic Computations in Agda},
  booktitle = {Proceedings 29th and 30th Workshops on (Constraint) Logic Programming
           and 24th International Workshop on Functional and (Constraint) Logic
           Programming, and 24th International Workshop on Functional and (Constraint)
           Logic Programming, {WLP} 2015 / {WLP} 2016 / {WFLP} 2016, Dresden
           and Leipzig, Germany, 22nd September 2015 and 12-14th September 2016.},
  pages     = {180--195},
  year      = {2017},
  crossref  = {DBLP:journals/corr/SchwarzV17},
  url       = {https://doi.org/10.4204/EPTCS.234.13},
  doi       = {10.4204/EPTCS.234.13},
  timestamp = {Wed, 12 Sep 2018 01:05:16 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/AntoyHL17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Pi-Ware: Hardware Description and Verification in Agda :agda_hardware:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{agda_hardware,
  author    = {Jo{\~{a}}o Paulo Pizani Flor and
           Wouter Swierstra and
           Yorick Sijsling},
  title     = {Pi-Ware: Hardware Description and Verification in Agda},
  booktitle = {21st International Conference on Types for Proofs and Programs, {TYPES}
           2015, May 18-21, 2015, Tallinn, Estonia},
  pages     = {9:1--9:27},
  year      = {2015},
  crossref  = {DBLP:conf/types/2015},
  url       = {https://doi.org/10.4230/LIPIcs.TYPES.2015.9},
  doi       = {10.4230/LIPIcs.TYPES.2015.9},
  timestamp = {Thu, 23 Aug 2018 15:56:39 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/types/FlorSS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Painless DTP: Fully Certified Merge Sort in Agda :agda_mergesort:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{agda_mergesort,
  author    = {Ernesto Copello and
           Alvaro Tasistro and
           Bruno Bianchi},
  title     = {Case of (Quite) Painless Dependently Typed Programming: Fully Certified
           Merge Sort in Agda},
  booktitle = {Programming Languages - 18th Brazilian Symposium, {SBLP} 2014, Maceio,
           Brazil, October 2-3, 2014. Proceedings},
  pages     = {62--76},
  year      = {2014},
  crossref  = {DBLP:conf/sblp/2014},
  url       = {https://doi.org/10.1007/978-3-319-11863-5\_5},
  doi       = {10.1007/978-3-319-11863-5\_5},
  timestamp = {Fri, 26 May 2017 00:49:32 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/sblp/CopelloTB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Dependently Typed Web Client Applications - {FRP} in Agda in {HTML5}} :agda_web:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{agda_web,
  author    = {Alan Jeffrey},
  title     = {Dependently Typed Web Client Applications - {FRP} in Agda in {HTML5}},
  booktitle = {Practical Aspects of Declarative Languages - 15th International Symposium,
           {PADL} 2013, Rome, Italy, January 21-22, 2013. Proceedings},
  pages     = {228--243},
  year      = {2013},
  crossref  = {DBLP:conf/padl/2013},
  url       = {https://doi.org/10.1007/978-3-642-45284-0\_16},
  doi       = {10.1007/978-3-642-45284-0\_16},
  timestamp = {Tue, 18 Jul 2017 14:13:01 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/padl/Jeffrey13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Modular type-safety proofs in Agda :agda_type_Safety:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{agda_type_Safety,
  author    = {Christopher Schwaab and
           Jeremy G. Siek},
  title     = {Modular type-safety proofs in Agda},
  booktitle = {Proceedings of the 7th Workshop on Programming languages meets program
           verification, {PLPV} 2013, Rome, Italy, January 22, 2013},
  pages     = {3--12},
  year      = {2013},
  crossref  = {DBLP:conf/plpv/2013},
  url       = {http://doi.acm.org/10.1145/2428116.2428120},
  doi       = {10.1145/2428116.2428120},
  timestamp = {Thu, 15 Jun 2017 21:35:58 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/plpv/SchwaabS13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Agda as a platform for the development of verified railway interlocking systems :agda_trains:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@phdthesis{agda_trains,
  author    = {Karim Kanso},
  title     = {Agda as a platform for the development of verified railway interlocking
           systems},
  school    = {Swansea University, {UK}},
  year      = {2012},
  url       = {http://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.678306},
  timestamp = {Fri, 19 Aug 2016 19:15:39 +0200},
  biburl    = {https://dblp.org/rec/bib/phd/ethos/Kanso12},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Algebra of programming in Agda: Dependent types for relational program derivation :agda_aop:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{agda_aop,
  author    = {Shin{-}Cheng Mu and
           Hsiang{-}Shang Ko and
           Patrik Jansson},
  title     = {Algebra of programming in Agda: Dependent types for relational program
           derivation},
  journal   = {J. Funct. Program.},
  volume    = {19},
  number    = {5},
  pages     = {545--579},
  year      = {2009},
  url       = {https://doi.org/10.1017/S0956796809007345},
  doi       = {10.1017/S0956796809007345},
  timestamp = {Tue, 06 Jun 2017 22:25:48 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/jfp/MuKJ09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** A Proof-Theoretic Approach to Tactics :tactics:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{tactics,
  author    = {Kamal Aboul{-}Hosn},
  title     = {A Proof-Theoretic Approach to Tactics},
  booktitle = {Mathematical Knowledge Management, 5th International Conference, {MKM}
           2006, Wokingham, UK, August 11-12, 2006, Proceedings},
  pages     = {54--66},
  year      = {2006},
  crossref  = {DBLP:conf/mkm/2006},
  url       = {https://doi.org/10.1007/11812289\_6},
  doi       = {10.1007/11812289\_6},
  timestamp = {Fri, 02 Jun 2017 13:01:08 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/mkm/Aboul-Hosn06},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Programming Language Foundations in Agda :agda_plf:


#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{agda_plf,
  title = {Programming Language Foundations in Agda},
  author    = {Philip Wadler and
           Wen Kokke},
  year = 2018,
  url = {https://plfa.github.io/},
  urldate = {2018-10-12}
}
#+END_SRC
** Teaching Agda :agda_teaching:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{agda_teaching,
  title = {Teaching Agda},
  author    = {Anton Setzer},
  year = 2018,
  url = {http://www.cse.chalmers.se/research/group/logic/AIM/AIM6/SetzerTeachingAgda.pdf},
  urldate = {2018-10-12}
}
#+END_SRC
** Verified Functional Programming in Agda                  :agda_iowa_book:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{agda_iowa_book,
 author = {Stump, Aaron},
 title = {Verified Functional Programming in Agda},
 year = {2016},
 isbn = {978-1-97000-127-3},
 publisher = {Association for Computing Machinery and Morgan \&\#38; Claypool},
 address = {New York, NY, USA},
}
#+END_SRC
** Agda's Documentation :agda_docs:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{agda_docs,
  author = {The {Agda Team}},
  title = {Agda's Documentation},
  year = 2018,
  url = {https://agda.readthedocs.io/en/v2.5.4.1/index.html},
  urldate = {2018-10-12}
}
#+END_SRC
** Relation-Algebraic Theories in Agda :RATH:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{RATH,
  title = {Relation-Algebraic Theories in Agda},
  author  = {Wolfram Kahl},
  year = 2018,
  url = {http://relmics.mcmaster.ca/RATH-Agda/},
  urldate = {2018-10-12}
}
#+END_SRC
** CASL Reference Manual :casl_ref:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{casl_ref,
  author    = {Peter D. Mosses},
  title     = {{CASL} Reference Manual, The Complete Documentation of the Common
           Algebraic Specification Language},
  series    = {Lecture Notes in Computer Science},
  volume    = {2960},
  publisher = {Springer},
  year      = {2004},
  url       = {https://doi.org/10.1007/b96103},
  doi       = {10.1007/b96103},
  isbn      = {3-540-21301-5},
  timestamp = {Mon, 29 May 2017 13:41:08 +0200},
  biburl    = {https://dblp.org/rec/bib/books/sp/Mosses04},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** CASL User Manual :casl_user:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{casl_user,
  author    = {Michel Bidoit and
           Peter D. Mosses},
  title     = {Casl User Manual - Introduction to Using the Common Algebraic Specification
           Language},
  series    = {Lecture Notes in Computer Science},
  volume    = {2900},
  publisher = {Springer},
  year      = {2004},
  url       = {https://doi.org/10.1007/b11968},
  doi       = {10.1007/b11968},
  isbn      = {3-540-20766-X},
  timestamp = {Mon, 29 May 2017 13:41:08 +0200},
  biburl    = {https://dblp.org/rec/bib/books/sp/BidoitM04},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Maude's module algebra :maude_module_algebra:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{maude_module_algebra,
  author    = {Francisco Dur{\'{a}}n and
           Jos{\'{e}} Meseguer},
  title     = {Maude's module algebra},
  journal   = {Sci. Comput. Program.},
  volume    = {66},
  number    = {2},
  pages     = {125--153},
  year      = {2007},
  url       = {https://doi.org/10.1016/j.scico.2006.07.002},
  doi       = {10.1016/j.scico.2006.07.002},
  timestamp = {Thu, 08 Jun 2017 08:59:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/scp/DuranM07},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Reuse of Specification Patterns with the {B} Method :B_reuse:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{B_reuse,
  author    = {Sandrine Blazy and
           Fr{\'{e}}d{\'{e}}ric Gervais and
           R{\'{e}}gine Laleau},
  title     = {Reuse of Specification Patterns with the {B} Method},
  journal   = {CoRR},
  volume    = {abs/cs/0610097},
  year      = {2006},
  url       = {http://arxiv.org/abs/cs/0610097},
  archivePrefix = {arXiv},
  eprint    = {cs/0610097},
  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-cs-0610097},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Categorical foundations for structured specifications in {Z} :Z_categorical:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{Z_categorical,
  author    = {Pablo F. Castro and
           Nazareno Aguirre and
           Carlos L{\'{o}}pez Pombo and
           T. S. E. Maibaum},
  title     = {Categorical foundations for structured specifications in {Z}},
  journal   = {Formal Asp. Comput.},
  volume    = {27},
  number    = {5-6},
  pages     = {831--865},
  year      = {2015},
  url       = {https://doi.org/10.1007/s00165-015-0336-0},
  doi       = {10.1007/s00165-015-0336-0},
  timestamp = {Wed, 17 May 2017 14:25:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/fac/CastroAPM15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Institution-independent Model Theory :institutions:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{institutions,
 author = {Diaconescu, Razvan},
 title = {Institution-independent Model Theory},
 year = {2008},
 isbn = {3764387076, 9783764387075},
 edition = {1st},
 publisher = {Birkh\&\#228;user Basel},
}
#+END_SRC

** OCaml Website                                              :ocaml_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{ocaml_website,
  author = {The {OCaml Team}},
  title = {The OCaml Language, Official Website},
  year = 2018,
  url = {https://ocaml.org/},
  urldate = {2018-10-16}
}
#+END_SRC
** Dependent Types At Work                                    :curry_howard:

# A good walkthrough and practicual use of Curry-Howard.

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{curry_howard,
  author    = {Ana Bove and
           Peter Dybjer},
  title     = {Dependent Types at Work},
  booktitle = {Language Engineering and Rigorous Software Development, International
           LerNet {ALFA} Summer School 2008, Piriapolis, Uruguay, February 24
           - March 1, 2008, Revised Tutorial Lectures},
  pages     = {57--99},
  year      = {2008},
  crossref  = {DBLP:conf/lernet/2008},
  url       = {https://doi.org/10.1007/978-3-642-03153-3\_2},
  doi       = {10.1007/978-3-642-03153-3\_2},
  timestamp = {Sun, 04 Jun 2017 10:11:20 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/lernet/BoveD08},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Wikipedia: Curry-Howard Correspondence              :wiki_curry_howard:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{wiki_curry_howard,
  organisation = {Wikipedia},
  title = {Curry‚ÄìHoward correspondence --- {Wikipedia}{,} The Free Encyclopedia},
  year = 2018,
  url = {https://en.wikipedia.org/wiki/Curry-Howard_correspondence},
  urldate = {2018-10-16}
}
#+END_SRC
** Wikipedia: Multiple inheritance                   :wiki_diamond_problem:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{wiki_diamond_problem,
  organisation = {Wikipedia},
  title = {Multiple inheritance --- {Wikipedia}{,} The Free Encyclopedia},
  year = 2018,
  url = {https://en.wikipedia.org/wiki/Multiple_inheritance#The_diamond_problem},
  urldate = {2018-10-16}
}
#+END_SRC
** Wikipedia: Hungarian notation                       :hungarian_notation:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{hungarian_notation,
  organisation = {Wikipedia},
  title = {Hungarian notation --- {Wikipedia}{,} The Free Encyclopedia},
  year = 2018,
  url = {https://en.wikipedia.org/wiki/Hungarian_notation},
  urldate = {2018-10-16}
}
#+END_SRC
** Type-theory in Color :tt_in_colour:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{tt_in_colour,
 author = {Bernardy, Jean-Philippe and Guilhem, Moulin},
 title = {Type-theory in Color},
 journal = {SIGPLAN Not.},
 issue_date = {September 2013},
 volume = {48},
 number = {9},
 month = sep,
 year = {2013},
 issn = {0362-1340},
 pages = {61--72},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2544174.2500577},
 doi = {10.1145/2544174.2500577},
 acmid = {2500577},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {erasure, parametricity, type-theory},
}
#+END_SRC
** Ornamental Algebras, Algebraic Ornaments                      :ornaments:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{ornaments,
 author = {Conor McBride},
 title = {Ornamental Algebras, Algebraic Ornaments},
 journal = {Unpublished Draft},
 publisher = {University of Strathclyde},
 url       = {https://personal.cis.strath.ac.uk/conor.mcbride/pub/OAAO/Ornament.pdf},
urldate = {2018-10-19},
abstract = {This paper re-examines the presentation of datatypes in dependently typed languages, addressing in
particular the issue of what it means for one datatype to be in various ways more informative than
another. Informal human observations like ‚Äòlists are natural numbers with extra labels‚Äô and ‚Äòvectors
are lists indexed by length‚Äô are expressed in a first class language of ornaments‚Äîpresentations of
fancy new types based on plain old ones.
Each ornament adds information, so it comes with a forgetful function from fancy data back to
plain, expressible as the fold of its ornamental algebra: lists built from numbers acquire the ‚Äòlength‚Äô
algebra. Conversely, each algebra for a datatype induces a way to index it‚Äîan algebraic ornament.
The length algebra for lists induces the construction of the paradigmatic dependent vector types.
Dependent types thus provide not only a new ‚Äòaxis of diversity‚Äô‚Äîindexing‚Äîfor data structures,
but also new abstractions to manage and exploit that diversity. In the new programming (2), coincidence
is replaced by consequence.},
}
#+END_SRC
** Relational Algebraic Ornaments :ornaments_relationally:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{ornaments_relationally,
 author = {Ko, Hsiang-Shang and Gibbons, Jeremy},
 title = {Relational Algebraic Ornaments},
 booktitle = {Proceedings of the 2013 ACM SIGPLAN Workshop on Dependently-typed Programming},
 series = {DTP '13},
 year = {2013},
 isbn = {978-1-4503-2384-0},
 location = {Boston, Massachusetts, USA},
 pages = {37--48},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2502409.2502413},
 doi = {10.1145/2502409.2502413},
 acmid = {2502413},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {algebra of programming, dependently typed programming, greedy algorithms, inductive families, program derivation},
 abstract = {Dependently typed programming is hard, because ideally dependently typed programs should share structure with their correctness proofs, but there are very few guidelines on how one can arrive at such integrated programs. McBride's algebraic ornamentation provides a methodological advancement, by which the programmer can derive a datatype from a specification involving a fold, such that a program that constructs elements of that datatype would be correct by construction. It is thus an effective method that leads the programmer from a specification to a dependently typed program. We enhance the applicability of this method by generalising algebraic ornamentation to a relational setting and bringing in relational algebraic methods, resulting in a hybrid approach that makes essential use of both dependently typed programming and relational program derivation. A dependently typed solution to the minimum coin change problem is presented as a demonstration of this hybrid approach. We also give a theoretically interesting "completeness theorem" of relational algebraic ornaments, which sheds some light on the expressive power of ornaments and inductive families.},
}
#+END_SRC

** Why dependent types matter :why_dependent_types_matter:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{why_dependent_types_matter,
  author    = {James McKinna},
  title     = {Why dependent types matter},
  booktitle = {Proceedings of the 33rd {ACM} {SIGPLAN-SIGACT} Symposium on Principles
           of Programming Languages, {POPL} 2006, Charleston, South Carolina,
           USA, January 11-13, 2006},
  pages     = {1},
  year      = {2006},
  crossref  = {DBLP:conf/popl/2006},
  url       = {http://doi.acm.org/10.1145/1111037.1111038},
  doi       = {10.1145/1111037.1111038},
  timestamp = {Tue, 22 May 2012 15:24:56 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/popl/McKinna06},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** A Tutorial Implementation of a DTL Calculus :dtl_implementation_tutorial:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{dtl_implementation_tutorial,
  author    = {Andres L{\"{o}}h and
           Conor McBride and
           Wouter Swierstra},
  title     = {A Tutorial Implementation of a Dependently Typed Lambda Calculus},
  journal   = {Fundam. Inform.},
  volume    = {102},
  number    = {2},
  pages     = {177--207},
  year      = {2010},
  url       = {https://doi.org/10.3233/FI-2010-304},
  doi       = {10.3233/FI-2010-304},
  timestamp = {Sat, 20 May 2017 00:23:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/fuin/LohMS10},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Lectures on Implementing Idris                 :dtl_implementation_idris:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{dtl_implementation_idris,
  author = {Edwin Brady},
  title = {Lectures on Implementing Idris},
  url = {https://www.idris-lang.org/dependently-typed-functional-programming-with-idris-course-videos-and-slides/},
  urldate = {2018-10-19}
}
#+END_SRC
** Designing DTLs                     :dtl_implementation_lectures_and_code:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{dtl_implementation_lectures_and_code,
  author = {Stephanie Weirich},
  title = {2014 OPLSS Lectures \emph{Designing Dependently-Typed Programming Languages}},
  url = {https://www.cs.uoregon.edu/research/summerschool/summer14/curriculum.html},
  urldate = {2018-10-19}
}
#+END_SRC
#
# Code: https://github.com/sweirich/pi-forall
# A demo implementation of a simple dependently-typed language

** Practical implementation of a DTL :dtl_implementation_practical:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@phdthesis{dtl_implementation_practical,
  author    = {Edwin Brady},
  title     = {Practical implementation of a dependently typed functional programming  language},
  school    = {Durham University, {UK}},
  year      = {2005},
  url       = {http://etheses.dur.ac.uk/2800/},
  timestamp = {Tue, 06 Sep 2016 10:13:42 +0200},
  biburl    = {https://dblp.org/rec/bib/phd/ethos/Brady05},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Implementing and Optimizing a Simple DTL :dtl_implementation_simple:13_pages:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@MastersThesis{dtl_implementation_simple,
  author    = {Michael Blaguszewski},
  title     = {Implementing and Optimizing a Simple, Dependently-Typed Language},
  school    = {Chalmers University of Technology},
  year      = {2010},
  url       = {http://publications.lib.chalmers.se/records/fulltext/124826.pdf},
}
#+END_SRC
** Ynot: dependent types for imperative programs :dtl_imperative:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{dtl_imperative,
  author    = {Aleksandar Nanevski and
           Greg Morrisett and
           Avraham Shinnar and
           Paul Govereau and
           Lars Birkedal},
  title     = {Ynot: dependent types for imperative programs},
  booktitle = {Proceeding of the 13th {ACM} {SIGPLAN} international conference on
           Functional programming, {ICFP} 2008, Victoria, BC, Canada, September
           20-28, 2008},
  pages     = {229--240},
  year      = {2008},
  crossref  = {DBLP:conf/icfp/2008},
  url       = {http://doi.acm.org/10.1145/1411204.1411237},
  doi       = {10.1145/1411204.1411237},
  timestamp = {Fri, 23 Jan 2009 12:54:21 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/icfp/NanevskiMSGB08},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Inductive Families Need Not Store Their Indices :dtl_index_erasure:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{dtl_index_erasure,
  author    = {Edwin Brady and
           Conor McBride and
           James McKinna},
  title     = {Inductive Families Need Not Store Their Indices},
  booktitle = {Types for Proofs and Programs, International Workshop, {TYPES} 2003,
           Torino, Italy, April 30 - May 4, 2003, Revised Selected Papers},
  pages     = {115--129},
  year      = {2003},
  crossref  = {DBLP:conf/types/2003},
  url       = {https://doi.org/10.1007/978-3-540-24849-1\_8},
  doi       = {10.1007/978-3-540-24849-1\_8},
  timestamp = {Thu, 15 Jun 2017 21:39:32 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/types/BradyMM03},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Erasure and Polymorphism in Pure Type Systems :erasure_type_systems:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{erasure_type_systems,
  author    = {Nathan Mishra{-}Linger and
           Tim Sheard},
  title     = {Erasure and Polymorphism in Pure Type Systems},
  booktitle = {Foundations of Software Science and Computational Structures, 11th
           International Conference, {FOSSACS} 2008, Held as Part of the Joint
           European Conferences on Theory and Practice of Software, {ETAPS} 2008,
           Budapest, Hungary, March 29 - April 6, 2008. Proceedings},
  pages     = {350--364},
  year      = {2008},
  crossref  = {DBLP:conf/fossacs/2008},
  url       = {https://doi.org/10.1007/978-3-540-78499-9\_25},
  doi       = {10.1007/978-3-540-78499-9\_25},
  timestamp = {Tue, 26 Jun 2018 14:10:47 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/fossacs/Mishra-LingerS08},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Towards a Proof-Irrelevant Calculus of Inductive Constructions :proof_irrelevant_cic:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@MastersThesis{proof_irrelevant_cic,
  author    = {Philipp Haselwarter},
  title     = {Towards a Proof-Irrelevant Calculus of Inductive Constructions},
  year      = {2015},
  url       = {http://www.haselwarter.org/~philipp/piCoq.pdf},
}
#+END_SRC
** Mathematical Logic as Based on the Theory of Types :russell_type_hierarchy:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{russell_type_hierarchy,
  author = {Bertrand Russell},
  title = {Mathematical Logic as Based on the Theory of Types},
  url = {https://fi.ort.edu.uy/innovaportal/file/20124/1/37-russell1905.pdf},
  urldate = {2018-10-19}
}
#+END_SRC
** An extended calculus of constructions :extended_cic:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@phdthesis{extended_cic,
  author    = {Zhaohui Luo},
  title     = {An extended calculus of constructions},
  school    = {University of Edinburgh, {UK}},
  year      = {1990},
  url       = {http://hdl.handle.net/1842/12487},
  timestamp = {Fri, 07 Oct 2016 21:32:16 +0200},
  biburl    = {https://dblp.org/rec/bib/phd/ethos/Luo90},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** A polymorphic Œª-calculus with Type:Type  :system_F_with_type_in_type:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{system_F_with_type_in_type,
  author = {Luca Cardelli},
  title = {A polymorphic Œª-calculus with Type:Type},
  url = {http://lucacardelli.name/Papers/TypeType.A4.pdf},
  urldate = {2018-10-19}
}
#+END_SRC
** Practical Erasure in Dependently Typed Languages :dtl_practical_erasure:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{dtl_practical_erasure,
 author = {Matus Tejiscak and Edwin Brady},
 title = {Practical Erasure in Dependently Typed Languages},
 journal = {Unpublished Draft},
 publisher = {University of St Andrews},
 url       = {https://eb.host.cs.st-andrews.ac.uk/drafts/dtp-erasure-draft.pdf},
urldate = {2018-10-19},
abstract = {Full-spectrum dependently typed languages and tools, such as
Idris and Agda, have recently been gaining interest due to the
expressive power of their type systems, in particular their ability to
describe precise properties of programs which can be verified by
type checking.
With full-spectrum dependent types, we can treat types as firstclass
language constructs: types can be parameterised on values,
and types can be computed like any other value. However, this
power brings new challenges when compiling to executable code.
Without special treatment, values which exist only for compile-time
checking may leak into compiled code, even in relatively simple
cases. Previous attempts to tackle the problem are unsatisfying in
that they either fail to erase all irrelevant information, require user
annotation or in some other way restrict the expressive power of the
language.
In this paper, we present a new erasure mechanism based on
whole-program analysis, currently implemented in the Idris programming
language. We give some simple examples of dependently
typed functional programs with compile-time guarantees of their
properties, but for which existing erasure techniques fall short. We
then describe our new analysis method and show that with it, erasure
can lead to asymptotically faster code thanks to the ability to erase
not only proofs but also indices.},
}
#+END_SRC
** Proof-relevant unification: Dependent pattern matching with only the axioms of your type theory :proof_relevant_unification:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{proof_relevant_unification,
  author    = {Jesper Cockx and
           Dominique Devriese},
  title     = {Proof-relevant unification: Dependent pattern matching with only the
           axioms of your type theory},
  journal   = {J. Funct. Program.},
  volume    = {28},
  pages     = {e12},
  year      = {2018},
  url       = {https://doi.org/10.1017/S095679681800014X},
  doi       = {10.1017/S095679681800014X},
  timestamp = {Tue, 29 May 2018 13:36:43 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/jfp/CockxD18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Dependently Typed Functional Programs and their Proofs :dependent_matching_is_just_K:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@phdthesis{dependent_matching_is_just_K,
  author    = {Conor McBride},
  title     = {Dependently typed functional programs and their proofs},
  school    = {University of Edinburgh, {UK}},
  year      = {2000},
  url       = {http://hdl.handle.net/1842/374},
  timestamp = {Mon, 26 Sep 2016 17:14:49 +0200},
  biburl    = {https://dblp.org/rec/bib/phd/ethos/McBride00},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Investigations Into Intensional Type Theory :uip_streicher:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@phdthesis{uip_streicher,
  author    = {Thomas Streicher},
  title     = {Investigations Into Intensional Type Theory },
  year      = {1993},
  url       = {https://www2.mathematik.tu-darmstadt.de/~streicher/HabilStreicher.pdf},
}
#+END_SRC

** Pattern matching without K :matching_without_K:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{matching_without_K,
  author    = {Jesper Cockx and
           Dominique Devriese and
           Frank Piessens},
  title     = {Pattern matching without {K}},
  booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} international conference on
           Functional programming, Gothenburg, Sweden, September 1-3, 2014},
  pages     = {257--268},
  year      = {2014},
  crossref  = {DBLP:conf/icfp/2014},
  url       = {http://doi.acm.org/10.1145/2628136.2628139},
  doi       = {10.1145/2628136.2628139},
  timestamp = {Sun, 04 Jun 2017 10:05:10 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icfp/CockxDP14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Eliminating Dependent Pattern Matching :eliminating_dependent_matching:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{eliminating_dependent_matching,
  author    = {Healfdene Goguen and
           Conor McBride and
           James McKinna},
  title     = {Eliminating Dependent Pattern Matching},
  booktitle = {Algebra, Meaning, and Computation, Essays Dedicated to Joseph A. Goguen
           on the Occasion of His 65th Birthday},
  pages     = {521--540},
  year      = {2006},
  crossref  = {DBLP:conf/birthday/2006goguen},
  url       = {https://doi.org/10.1007/11780274\_27},
  doi       = {10.1007/11780274\_27},
  timestamp = {Fri, 02 Jun 2017 13:01:06 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/birthday/GoguenMM06},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Elimination with a motive                       :elimination_with_motive:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{elimination_with_motive,
  author    = {Conor McBride},
  title     = {Elimination with a Motive},
  booktitle = {Types for Proofs and Programs, International Workshop, {TYPES} 2000,
           Durham, UK, December 8-12, 2000, Selected Papers},
  pages     = {197--216},
  year      = {2000},
  crossref  = {DBLP:conf/types/2000},
  url       = {https://doi.org/10.1007/3-540-45842-5\_13},
  doi       = {10.1007/3-540-45842-5\_13},
  timestamp = {Fri, 26 May 2017 14:09:14 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/types/McBride00},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** The groupoid model refutes uniqueness of identity proofs :uip_problem:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{uip_problem,
  author    = {Martin Hofmann and
           Thomas Streicher},
  title     = {The Groupoid Model Refutes Uniqueness of Identity Proofs},
  booktitle = {Proceedings of the Ninth Annual Symposium on Logic in Computer Science
           {(LICS} '94), Paris, France, July 4-7, 1994},
  pages     = {208--212},
  year      = {1994},
  crossref  = {DBLP:conf/lics/1994},
  url       = {https://doi.org/10.1109/LICS.1994.316071},
  doi       = {10.1109/LICS.1994.316071},
  timestamp = {Thu, 25 May 2017 00:42:41 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/lics/HofmannS94},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** On the Strength of Proof-irrelevant Type Theories :uip_strength:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{uip_strength,
  author    = {Benjamin Werner},
  title     = {On the Strength of Proof-irrelevant Type Theories},
  journal   = {Logical Methods in Computer Science},
  volume    = {4},
  number    = {3},
  year      = {2008},
  url       = {https://doi.org/10.2168/LMCS-4(3:13)2008},
  doi       = {10.2168/LMCS-4(3:13)2008},
  timestamp = {Sat, 20 May 2017 00:22:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/lmcs/Werner08},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Inconsistency of Set:Set                :agda_type_in_type_contradiction:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{agda_type_in_type_contradiction,
  author = {Thorsten Altenkirch},
  title = {Inconsistency of Set:Set},
  url = {http://www.cs.nott.ac.uk/~psztxa/g53cfr/l20.html/l20.html},
  urldate = {2018-10-19}
}
#+END_SRC

** Formal Proof--The Four-Color Theorem :coq_four_colour:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{coq_four_colour,
  author = {Georges Gonthier},
  title = {Formal Proof--The Four-Color Theorem},
  url = {http://www.ams.org/notices/200811/},
  urldate = {2018-10-19}
}
#+END_SRC

** A Machine-Checked Proof of the Odd Order Theorem :coq_feit:


#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{coq_feit,
  author    = {Georges Gonthier and
           Andrea Asperti and
           Jeremy Avigad and
           Yves Bertot and
           Cyril Cohen and
           Fran{\c{c}}ois Garillot and
           St{\'{e}}phane Le Roux and
           Assia Mahboubi and
           Russell O'Connor and
           Sidi Ould Biha and
           Ioana Pasca and
           Laurence Rideau and
           Alexey Solovyev and
           Enrico Tassi and
           Laurent Th{\'{e}}ry},
  title     = {A Machine-Checked Proof of the Odd Order Theorem},
  booktitle = {Interactive Theorem Proving - 4th International Conference, {ITP}
           2013, Rennes, France, July 22-26, 2013. Proceedings},
  pages     = {163--179},
  year      = {2013},
  crossref  = {DBLP:conf/itp/2013},
  url       = {https://doi.org/10.1007/978-3-642-39634-2\_14},
  doi       = {10.1007/978-3-642-39634-2\_14},
  timestamp = {Thu, 15 Jun 2017 21:38:54 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/itp/GonthierAABCGRMOBPRSTT13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** The Compcert C Compiler :coq_compcert:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{coq_compcert,
  author = {The {Compcert Team}},
  title = {The Compcert C Compiler},
  url = {http://compcert.inria.fr/compcert-C.html},
  year=2018,
  urldate = {2018-10-19}
}
#+END_SRC

** Software Foundations :coq_sf:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{coq_sf,
  author = {The {Software Foundations Team}},
  title = {Software Foundations},
  url = {https://softwarefoundations.cis.upenn.edu/},
  year=2018,
  urldate = {2018-10-19}
}
#+END_SRC

** Type-driven Development With Idris :idris_tdd:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{idris_tdd,
  author = {Brady, Edwin},
  isbn = {9781617293023},
  keywords = {03b15-higher-order-logic-type-theory, 68n15-programming-languages, 68n18-functional-programming-and-lambda-calculus},
  publisher = {Manning},
  title = {Type-driven Development With {I}dris},
  url = {http://www.worldcat.org/isbn/9781617293023},
  year = 2016
}
#+END_SRC
** Idris: Frequently Asked Questions :idris_faq:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{idris_faq,
  author = {The {Idris Team}},
  title = {Idris: Frequently Asked Questions},
  url = {http://docs.idris-lang.org/en/latest/faq/faq.html},
  year=2018,
  urldate = {2018-10-19}
}
#+END_SRC

** Idris Website :idris_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{idris_website,
  author = {The {Idris Team}},
  title = {Idris: A Language With Dependent Types},
  url = {https://www.idris-lang.org/},
  year=2018,
  urldate = {2018-10-19}
}
#+END_SRC
** The ATS Programming Language: Unleashing the Potentials of Types and Templates! :ats_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{ats_website,
  author = {The {ATS Team}},
  title = {The ATS Programming Language: Unleashing the Potentials of Types and Templates!},
  url = {http://www.ats-lang.org/#What_is_ATS_good_for},
  year=2018,
  urldate = {2018-10-19}
}
#+END_SRC

** Combining Programming with Theorem Proving :ats_combining:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{ats_combining,
  author    = {Chiyan Chen and
           Hongwei Xi},
  title     = {Combining programming with theorem proving},
  booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on
           Functional Programming, {ICFP} 2005, Tallinn, Estonia, September 26-28,
           2005},
  pages     = {66--77},
  year      = {2005},
  crossref  = {DBLP:conf/icfp/2005},
  url       = {http://doi.acm.org/10.1145/1086365.1086375},
  doi       = {10.1145/1086365.1086375},
  timestamp = {Mon, 13 Feb 2006 15:41:18 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/icfp/ChenX05},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** F* Official Website :fstar_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{fstar_website,
  author = {The {F^* Team}},
  title = {F^* Official Website},
  url = {https://www.fstar-lang.org/},
  year=2018,
  urldate = {2018-10-19}
}
#+END_SRC
** Mizar Home Page                                         :mizar_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{mizar_website,
  author = {The {Mizar Team}},
  title = {Mizar Home Page},
  url = {http://www.mizar.org/},
  year=2018,
  urldate = {2018-10-19}
}
#+END_SRC

** A Brief Overview of Mizar :mizar_overview:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{mizar_overview,
  author    = {Adam Naumowicz and
           Artur Kornilowicz},
  title     = {A Brief Overview of Mizar},
  booktitle = {Theorem Proving in Higher Order Logics, 22nd International Conference,
           TPHOLs 2009, Munich, Germany, August 17-20, 2009. Proceedings},
  pages     = {67--72},
  year      = {2009},
  crossref  = {DBLP:conf/tphol/2009},
  url       = {https://doi.org/10.1007/978-3-642-03359-9\_5},
  doi       = {10.1007/978-3-642-03359-9\_5},
  timestamp = {Tue, 23 May 2017 01:12:08 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/tphol/NaumowiczK09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** The Role of the Mizar Mathematical Library for Interactive Proof Development in Mizar :mizar_library:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{mizar_library,
  author    = {Grzegorz Bancerek and
           Czeslaw Bylinski and
           Adam Grabowski and
           Artur Kornilowicz and
           Roman Matuszewski and
           Adam Naumowicz and
           Karol Pak},
  title     = {The Role of the Mizar Mathematical Library for Interactive Proof Development
           in Mizar},
  journal   = {J. Autom. Reasoning},
  volume    = {61},
  number    = {1-4},
  pages     = {9--32},
  year      = {2018},
  url       = {https://doi.org/10.1007/s10817-017-9440-6},
  doi       = {10.1007/s10817-017-9440-6},
  timestamp = {Tue, 26 Jun 2018 14:09:47 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/jar/BancerekBGKMNP18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** The undecidability of typability in the ŒªŒ†-calculus :undecidability_of_typing:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{undecidability_of_typing,
  author    = {Gilles Dowek},
  title     = {The Undecidability of Typability in the Lambda-Pi-Calculus},
  booktitle = {Typed Lambda Calculi and Applications, International Conference on
           Typed Lambda Calculi and Applications, {TLCA} '93, Utrecht, The Netherlands,
           March 16-18, 1993, Proceedings},
  pages     = {139--145},
  year      = {1993},
  crossref  = {DBLP:conf/tlca/1993},
  url       = {https://doi.org/10.1007/BFb0037103},
  doi       = {10.1007/BFb0037103},
  timestamp = {Sat, 20 May 2017 15:32:50 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/tlca/Dowek93},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Wikipedia: Proof assistant :wiki_proof_assistants:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{wiki_proof_assistants,
  title = {Proof assistant --- {Wikipedia}{,} The Free Encyclopedia},
  organisation = {Wikipedia},
  year=2018,
  url = {https://en.wikipedia.org/wiki/Proof_assistant},
  urldate = {2018-10-19}
}
#+END_SRC

** Wikipedia: Dependent type :wiki_proof_assistants_dependent:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{wiki_proof_assistants_dependent,
  title = {Dependent type --- {Wikipedia}{,} The Free Encyclopedia},
  organisation = {Wikipedia},
  year=2018,
  url = {https://en.wikipedia.org/wiki/Dependent_type},
  urldate = {2018-10-19}
}
#+END_SRC

** A practical module system for LF  :LF_practical_module_system:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{LF_practical_module_system,
  author    = {Florian Rabe and
           Carsten Sch{\"{u}}rmann},
  title     = {A practical module system for {LF}},
  booktitle = {Proceedings of the Fourth International Workshop on Logical Frameworks
           and Meta-Languages: Theory and Practice, {LFMTP} '09, McGill University,
           Montreal, Canada, August 2, 2009},
  pages     = {40--48},
  year      = {2009},
  crossref  = {DBLP:conf/lfmtp/2009},
  url       = {http://doi.acm.org/10.1145/1577824.1577831},
  doi       = {10.1145/1577824.1577831},
  timestamp = {Mon, 12 Mar 2012 07:35:17 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/lfmtp/RabeS09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Towards a practical programming language based on dependent type theory :agda_main:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@phdthesis{agda_main,
  author    = {Ulf Norell},
  title     = {Towards a practical programming language based on dependent type theory},
  school    = {Chalmers University of Technology},
  year      = {2007},
}
#+END_SRC

** Implementing Modules in the Coq System :coq_implementing_modules:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{coq_implementing_modules,
  author    = {Jacek Chrzaszcz},
  title     = {Implementing Modules in the Coq System},
  booktitle = {Theorem Proving in Higher Order Logics, 16th International Conference,
           TPHOLs 2003, Rom, Italy, September 8-12, 2003, Proceedings},
  pages     = {270--286},
  year      = {2003},
  crossref  = {DBLP:conf/tphol/2003},
  url       = {https://doi.org/10.1007/10930755\_18},
  doi       = {10.1007/10930755\_18},
  timestamp = {Mon, 29 May 2017 16:53:44 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/tphol/Chrzaszcz03},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Locales - {A} Sectioning Concept for Isabelle :isabelle_locales:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{isabelle_locales,
  author    = {Florian Kamm{\"{u}}ller and
           Markus Wenzel and
           Lawrence C. Paulson},
  title     = {Locales - {A} Sectioning Concept for Isabelle},
  booktitle = {Theorem Proving in Higher Order Logics, 12th International Conference,
           TPHOLs'99, Nice, France, September, 1999, Proceedings},
  pages     = {149--166},
  year      = {1999},
  crossref  = {DBLP:conf/tphol/1999},
  url       = {https://doi.org/10.1007/3-540-48256-3\_11},
  doi       = {10.1007/3-540-48256-3\_11},
  timestamp = {Sat, 30 Dec 2017 11:46:44 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/tphol/KammullerWP99},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Constructive Type Classes in Isabelle :isabelle_constructive_typeclasses:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{isabelle_constructive_typeclasses,
  author    = {Florian Haftmann and
           Makarius Wenzel},
  title     = {Constructive Type Classes in Isabelle},
  booktitle = {Types for Proofs and Programs, International Workshop, {TYPES} 2006,
           Nottingham, UK, April 18-21, 2006, Revised Selected Papers},
  pages     = {160--174},
  year      = {2006},
  crossref  = {DBLP:conf/types/2006},
  url       = {https://doi.org/10.1007/978-3-540-74464-1\_11},
  doi       = {10.1007/978-3-540-74464-1\_11},
  timestamp = {Fri, 02 Jun 2017 13:01:07 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/types/HaftmannW06},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Category Theory for Computing Science :cats_for_cs:


#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{cats_for_cs,
  author    = {Michael Barr and
           Charles Wells},
  title     = {Category theory for computing science {(2.} ed.)},
  series    = {Prentice Hall international series in computer science},
  publisher = {Prentice Hall},
  year      = {1995},
  isbn      = {978-0-13-323809-9},
  timestamp = {Wed, 27 Apr 2011 17:30:30 +0200},
  biburl    = {https://dblp.org/rec/bib/books/daglib/0080381},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Categorical Models of Dependent Type Theory :dtl_cat_models:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@misc{dtl_cat_models,
  author    = {Alexandre Buisse},
  title     = {Categorical Models of Dependent Type Theory},
  school    = {Chalmers University of Technology},
  year      = {2006},
  url       = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.8051&rep=rep1&type=pdf},
}
#+END_SRC
** Modular correspondence between dependent type theories and categories including pretopoi and topoi :dtl_cat_correspondences:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{dtl_cat_correspondences,
  author    = {Maria Emilia Maietti},
  title     = {Modular correspondence between dependent type theories and categories
           including pretopoi and topoi},
  journal   = {Mathematical Structures in Computer Science},
  volume    = {15},
  number    = {6},
  pages     = {1089--1149},
  year      = {2005},
  url       = {https://doi.org/10.1017/S0960129505004962},
  doi       = {10.1017/S0960129505004962},
  timestamp = {Sun, 28 May 2017 13:25:37 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/mscs/Maietti05},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** On the Interpretation of Intuitionistic Logic :il_interpretation:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{il_interpretation,
  author      = {Andrey Kolmogorov},
  translator  = {James McKinna},
  title       = {On the Interpretation of Intuitionistic Logic, \emph{Zur Deutung der intuitionistischen Logik}},
  language    = {langgerman},
  year        = {1932},
  url         = {http://homepages.inf.ed.ac.uk/jmckinna/kolmogorov-1932.pdf},
  urldate = {2018-10-31}
}
#+END_SRC
** On Various Negative Translations :translating_cl_to_il:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{translating_cl_to_il,
  author    = {Gilda Ferreira and
           Paulo Oliva},
  title     = {On Various Negative Translations},
  booktitle = {Proceedings Third International Workshop on Classical Logic and Computation,
           CL{\&}C 2010, Brno, Czech Republic, 21-22 August 2010.},
  pages     = {21--33},
  year      = {2010},
  crossref  = {DBLP:journals/corr/abs-1101-5200},
  url       = {https://doi.org/10.4204/EPTCS.47.4},
  doi       = {10.4204/EPTCS.47.4},
  timestamp = {Wed, 12 Sep 2018 01:05:15 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1101-5442},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** The Racket Manifesto                                   :racket_manifesto:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{racket_manifesto,
  author    = {Matthias Felleisen and
           Robert Bruce Findler and
           Matthew Flatt and
           Shriram Krishnamurthi and
           Eli Barzilay and
           Jay A. McCarthy and
           Sam Tobin{-}Hochstadt},
  title     = {The Racket Manifesto},
  booktitle = {1st Summit on Advances in Programming Languages, {SNAPL} 2015, May
           3-6, 2015, Asilomar, California, {USA}},
  pages     = {113--128},
  year      = {2015},
  crossref  = {DBLP:conf/snapl/2015},
  url       = {https://doi.org/10.4230/LIPIcs.SNAPL.2015.113},
  doi       = {10.4230/LIPIcs.SNAPL.2015.113},
  timestamp = {Thu, 23 Aug 2018 15:56:17 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/snapl/FelleisenFFKBMT15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Creating languages in Racket :racket_creating_languages:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{racket_creating_languages,
  author    = {Matthew Flatt},
  title     = {Creating languages in Racket},
  journal   = {Commun. {ACM}},
  volume    = {55},
  number    = {1},
  pages     = {48--56},
  year      = {2012},
  url       = {http://doi.acm.org/10.1145/2063176.2063195},
  doi       = {10.1145/2063176.2063195},
  timestamp = {Mon, 09 Jan 2012 13:39:03 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/cacm/Flatt12},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Racket Website                                            :racket_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{racket_website,
  author = {The {Racket Team}},
  title = {Racket: Solve Problems, Make Languages},
  url = {https://racket-lang.org/},
  year=2018,
  urldate = {2018-10-31}
}
#+END_SRC
** Submodules in racket: you want it when, again? :racket_submodules:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{racket_submodules,
  author    = {Matthew Flatt},
  title     = {Submodules in Racket: you want it when, again?},
  booktitle = {Generative Programming: Concepts and Experiences, GPCE'13, Indianapolis,
           IN, {USA} - October 27 - 28, 2013},
  pages     = {13--22},
  year      = {2013},
  crossref  = {DBLP:conf/gpce/2013},
  url       = {http://doi.acm.org/10.1145/2517208.2517211},
  doi       = {10.1145/2517208.2517211},
  timestamp = {Fri, 25 Oct 2013 08:34:11 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/gpce/Flatt13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** The Racket Guide :racket_guide:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{racket_guide,
  author = {Matthew Flatt and Robert Bruce Findler},
  title = {The Racket Guide},
  year=2018,
  url = {https://docs.racket-lang.org/guide/},
  urldate = {2018-10-31}
}
#+END_SRC

** Scala Website                                       :scala_website:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{scala_website,
  author = {The {Scala Team}},
  title = {The Scala Programming Language},
  year=2018,
  url = {https://www.scala-lang.org/},
  urldate = {2018-10-31}
}
#+END_SRC
** A Beginner's Guide to Scala, Object Orientation and Functional Programming :scala_book:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{scala_book,
  author    = {John Hunt},
  title     = {A Beginner's Guide to Scala, Object Orientation and Functional Programming,
           Second Edition},
  publisher = {Springer},
  year      = {2018},
  url       = {https://doi.org/10.1007/978-3-319-75771-1},
  doi       = {10.1007/978-3-319-75771-1},
  isbn      = {978-3-319-75770-4},
  timestamp = {Thu, 08 Mar 2018 12:15:18 +0100},
  biburl    = {https://dblp.org/rec/bib/books/sp/Hunt18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Literate Programming :lp_knuth:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{lp_knuth,
  author    = {Donald E. Knuth},
  title     = {Literate Programming},
  journal   = {Comput. J.},
  volume    = {27},
  number    = {2},
  pages     = {97--111},
  year      = {1984},
  url       = {https://doi.org/10.1093/comjnl/27.2.97},
  doi       = {10.1093/comjnl/27.2.97},
  timestamp = {Sat, 20 May 2017 00:22:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/cj/Knuth84},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Modular libraries and literate programming in software for ‚Ä¶ electronic calculations :lp_modular:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{lp_modular,
  author    = {Carlos F. Bunge and
           Gerardo Cisneros},
  title     = {Modular libraries and literate programming in software for ab initio
           atomic and molecular electronic structure calculations},
  journal   = {Computers {\&} Chemistry},
  volume    = {12},
  number    = {2},
  pages     = {85--89},
  year      = {1988},
  url       = {https://doi.org/10.1016/0097-8485(88)85009-5},
  doi       = {10.1016/0097-8485(88)85009-5},
  timestamp = {Fri, 26 May 2017 22:53:59 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/candc/BungeC88},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Experiences of 'Literate Programming' :lp_experiences:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{lp_experiences,
  author    = {Harold W. Thimbleby},
  title     = {Experiences of 'Literate Programming' Using Cweb {(A} Variant of Knuth's
           {WEB)}},
  journal   = {Comput. J.},
  volume    = {29},
  number    = {3},
  pages     = {201--211},
  year      = {1986},
  url       = {https://doi.org/10.1093/comjnl/29.3.201},
  doi       = {10.1093/comjnl/29.3.201},
  timestamp = {Sat, 20 May 2017 00:22:25 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/cj/Thimbleby86},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** A Structured Method for Literate Programming              :lp_structured:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{lp_structured,
  author    = {Sho{-}Huan Tung},
  title     = {A Structured Method for Literate Programming},
  journal   = {Structured Programming},
  volume    = {10},
  number    = {2},
  pages     = {113--120},
  year      = {1989},
  timestamp = {Thu, 03 Jan 2002 12:26:55 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/stp/Tung89},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Literate Program Derivation: {A} Case Study :lp_derivation:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{lp_derivation,
  author    = {Peter Pepper},
  title     = {Literate Program Derivation: {A} Case Study},
  booktitle = {Method of Programming, Selected Papers on the CIP-Project},
  pages     = {101--124},
  year      = {1991},
  crossref  = {DBLP:conf/cip/1991},
  url       = {https://doi.org/10.1007/BFb0018271},
  doi       = {10.1007/BFb0018271},
  timestamp = {Sat, 20 May 2017 15:32:55 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cip/Pepper91},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Post-literate Programming: Linking Discussion and Code in Software Development {Team}s :lp_after_the_fact:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{lp_after_the_fact,
  author    = {Soya Park and
           Amy X. Zhang and
           David R. Karger},
  title     = {Post-literate Programming: Linking Discussion and Code in Software
           Development Teams},
  booktitle = {The 31st Annual {ACM} Symposium on User Interface Software and Technology
           Adjunct Proceedings, {UIST} 2018, Berlin, Germany, October 14-17,
           2018},
  pages     = {51--53},
  year      = {2018},
  crossref  = {DBLP:conf/uist/2018a},
  url       = {http://doi.acm.org/10.1145/3266037.3266098},
  doi       = {10.1145/3266037.3266098},
  timestamp = {Sun, 14 Oct 2018 18:55:03 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/uist/ParkZK18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** A Language with first-class support for literate programming :lp_first_class:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{lp_first_class,
  author    = {James Dean Palmer and
           Eddie Hillenbrand},
  title     = {Reimagining literate programming},
  booktitle = {Companion to the 24th Annual {ACM} {SIGPLAN} Conference on Object-Oriented
           Programming, Systems, Languages, and Applications, {OOPSLA} 2009,
           October 25-29, 2009, Orlando, Florida, {USA}},
  pages     = {1007--1014},
  year      = {2009},
  crossref  = {DBLP:conf/oopsla/2009c},
  url       = {http://doi.acm.org/10.1145/1639950.1640072},
  doi       = {10.1145/1639950.1640072},
  timestamp = {Fri, 30 Oct 2009 14:45:38 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/oopsla/PalmerH09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Literate Programming to Enhance Agile Methods :lp_agile:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{lp_agile,
  author    = {Vreda Pieterse and
           Derrick G. Kourie and
           Andrew Boake},
  title     = {Literate Programming to Enhance Agile Methods},
  booktitle = {Extreme Programming and Agile Processes in Software Engineering, 5th
           International Conference, {XP} 2004, Garmisch-Partenkirchen, Germany,
           June 6-10, 2004, Proceedings},
  pages     = {250--253},
  year      = {2004},
  crossref  = {DBLP:conf/xpu/2004},
  url       = {https://doi.org/10.1007/978-3-540-24853-8\_34},
  doi       = {10.1007/978-3-540-24853-8\_34},
  timestamp = {Tue, 23 May 2017 01:10:41 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/xpu/PieterseKB04},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Software Development as Knowledge Creation :lp_knowledge_creation:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{lp_knowledge_creation,
  author = {Sidney Bailin},
  title = {Software Development as Knowledge Creation},
  url = {https://pdfs.semanticscholar.org/67cb/43536824069270a2d02db5d8d61b616d1568.pdf},
  year={1997},
  urldate = {2018-10-31}
}
#+END_SRC

** Structure and Interpretation of Computer Programs, Second Edition :sicp:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{sicp,
  author    = {Harold Abelson and
           Gerald J. Sussman},
  title     = {Structure and Interpretation of Computer Programs, Second Edition},
  publisher = {{MIT} Press},
  year      = {1996},
  isbn      = {0-262-01153-0},
  timestamp = {Mon, 28 Jan 2002 16:12:01 +0100},
  biburl    = {https://dblp.org/rec/bib/books/mit/AbelsonS96},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Head first design patterns - your brain on design patterns :design_patterns_head_first:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{design_patterns_head_first,
  author    = {Eric Freeman and
           Elisabeth Robson},
  title     = {Head first design patterns - your brain on design patterns},
  publisher = {O'Reilly},
  year      = {2014},
  url       = {http://www.oreilly.de/catalog/hfdesignpat/index.html},
  isbn      = {978-0-596-00712-6},
  timestamp = {Thu, 14 Apr 2011 14:43:21 +0200},
  biburl    = {https://dblp.org/rec/bib/books/daglib/0011977},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Clean Code - a Handbook of Agile Software Craftsmanship :clean_code:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{clean_code,
  author    = {Robert C. Martin},
  title     = {Clean Code - a Handbook of Agile Software Craftsmanship},
  publisher = {Prentice Hall},
  year      = {2009},
  url       = {http://vig.pearsoned.com/store/product/1,1207,store-12521\_isbn-0132350882,00.html},
  isbn      = {978-0-13-235088-4},
}
#+END_SRC
** Program Construction: Calculating Implementations from Specifications  :backhouse_program_construction:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{backhouse_program_construction,
  author    = {Roland Carl Backhouse},
  title     = {Program Construction: Calculating Implementations from Specifications},
  publisher = {John Wiley {\&} Sons},
  year      = {2004},
  isbn      = {978-0-47-084882-1},
}
#+END_SRC

** Programming from First Principles :bornat_programming:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{bornat_programming,
 author = {Bornat, Richard},
 title = {Programming from First Principles},
 year = {1987},
 isbn = {0-13-729104-3},
 publisher = {Prentice Hall International (UK) Ltd.},
 address = {Hertfordshire, UK, UK},
}
#+END_SRC
** A Gentle Introduction to Category Theory --- the calculational approach :cats_fokkinga:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inbook{cats_fokkinga,
  author = {Fokkinga, Maarten},
  title = {{A Gentle Introduction to Category Theory --- the calculational approach}},
  crossref = {db-utwente:book:0000003535},
  pages = {1--72}
}
@book{db-utwente:book:0000003535,
  author = {Fokkinga, Maarten and
        Jeuring, Johan},
  title = {{Lecture Notes of the STOP 1992 Summerschool on Constructive Algorithmics}},
  booktitle = {{Lecture Notes of the STOP 1992 Summerschool on Constructive Algorithmics}},
  month = sep,
  year = {1992},
  volume = {Part I},
  publisher = {University of Utrecht},
  address = {Utrecht, Netherlands}
}
#+END_SRC
** F-ing modules :f_ing_modules:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{f_ing_modules,
  author    = {Andreas Rossberg and
           Claudio V. Russo and
           Derek Dreyer},
  title     = {F-ing modules},
  journal   = {J. Funct. Program.},
  volume    = {24},
  number    = {5},
  pages     = {529--607},
  year      = {2014},
  url       = {https://people.mpi-sws.org/~rossberg/f-ing/},
  doi       = {10.1017/S0956796814000264},
  timestamp = {Sat, 27 May 2017 14:24:34 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/jfp/RossbergRD14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Programming in the 1990s - An Introduction to the Calculation of Programs :sop_cohen:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{sop_cohen,
  author    = {Edward Cohen},
  title     = {Programming in the 1990s - An Introduction to the Calculation of Programs},
  series    = {Texts and Monographs in Computer Science},
  publisher = {Springer},
  year      = {1990},
  url       = {https://doi.org/10.1007/978-1-4613-9706-9},
  doi       = {10.1007/978-1-4613-9706-9},
  isbn      = {978-0-387-97382-1},
  timestamp = {Tue, 16 May 2017 14:24:21 +0200},
  biburl    = {https://dblp.org/rec/bib/series/mcs/Cohen90},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** A Discipline of Programming :ewd_discipline:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{ewd_discipline,
  author    = {Edsger W. Dijkstra},
  title     = {A Discipline of Programming},
  publisher = {Prentice-Hall},
  year      = {1976},
  url       = {http://www.worldcat.org/oclc/01958445},
  isbn      = {013215871X},
  timestamp = {Wed, 26 Apr 2017 17:48:52 +0200},
  biburl    = {https://dblp.org/rec/bib/books/ph/Dijkstra76},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** The Science of Programming  :sop:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{sop,
  author    = {David Gries},
  title     = {The Science of Programming},
  series    = {Texts and Monographs in Computer Science},
  publisher = {Springer},
  year      = {1981},
  url       = {https://doi.org/10.1007/978-1-4612-5983-1},
  doi       = {10.1007/978-1-4612-5983-1},
  isbn      = {978-0-387-96480-5},
  timestamp = {Tue, 16 May 2017 14:01:46 +0200},
  biburl    = {https://dblp.org/rec/bib/books/sp/Gries81},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Design Principles and Design Patterns :design-patterns-solid:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{design-patterns-solid,
  author = {Robert C. Martin},
  title = {Design Principles and Design Patterns},
  url = {https://fi.ort.edu.uy/innovaportal/file/2032/1/design_principles.pdf},
  urldate = {2018-10-19},
  date    = {2000}
}
#+END_SRC
** Categorical logic from a categorical point of view                                                     :cats_logic_shulman:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{cats_logic_shulman,
  author = {Michael Shulman},
  title = {Categorical logic from a categorical point of view},
  url = {https://mikeshulman.github.io/catlog/catlog.pdf},
  urldate = {2018-10-19},
  date = {2016}
}
#+END_SRC

** Why Dependent Types Matter :dtl_why:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{dtl_why,
  author = {Thorsten Alkenkirch AND Conor McBride AND James McKinna},
  title = {Why Dependent Types Matter},
  url = {http://www.cs.nott.ac.uk/~psztxa/publ/ydtm.pdf},
  urldate = {2018-10-19},
  date = {2005}
}
#+END_SRC

** PVS Prover Guide                                             :pvs_prover:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{pvs_prover,
  author = {Natarajan Shankar AND Sam Owre AND John Rushby AND Dave Stringer-Calvert},
  title = {PVS Prover Guide},
  url = {http://pvs.csl.sri.com/doc/pvs-prover-guide.pdf},
  urldate = {2019-04-19},
  date = {2001}
}
#+END_SRC

** The Twelf Project :twelf_site:

The last ``new'' item seems to be from 2015, and so this project is likely abandonded.

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{twelf_site,
  author = {Frank Pfenning and The Twelf Team},
  title = {The Twelf Project},
  url = {http://twelf.org/wiki/Main_Page},
  urldate = {2018-10-19},
  date = {2015}
}
#+END_SRC

** PRL Project: Proof/Program Refinment Logic :prl_site:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{prl_site,
  author = {The {PRL Team}},
  title = {PRL Project: Proof/Program Refinment Logic},
  url = {http://www.nuprl.org},
  urldate = {2018-10-19},
  date = {2014}
}
#+END_SRC
** The Matita Interactive Theorem Prover :matita_site:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{matita_site,
  author = {The {Matita Team}},
  title = {The Matita Interactive Theorem Prover},
  url = {http://matita.cs.unibo.it},
  urldate = {2018-10-19},
  date = {2016}
}
#+END_SRC
** Named Instances for Haskell Type Classes :named_instances:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{named_instances,
 journal   = {Haskell Workshop},
 author = {Wolfram Kahl and Jan Scheffczyk},
 title = {Named Instances for Haskell Type Classes},
 abstract = {Although the functional programming language Haskell has a powerful type class system, users frequently run into situations where they would like to be able to define or adapt instances of type classes only after the remainder of a component has been produced. However, Haskell's type class system essentially only allows late binding of type class constraints on free type variables, and not on uses of type class members at variable-free types.

In the current paper we propose a language extension that enhances the late binding capabilities of Haskell type classes, and provides more flexible means for type class instantiation. The latter is achieved via named instances that do not participate in automatic context reduction, but can only be used for late binding. By combining this capability with the automatic aspects of the Haskell type class system, we arrive at an essentially conservative extension that greatly improves flexibility of programming using type classes and opens up new structuring principles for Haskell library design.

We exemplify our extension through the sketch of some applications and show how our approach could be used to explain or subsume other language features as for example implicit parameters. We present a typed lambda-calculus for our extension and provide a working prototype type checker on the basis of Mark Jones' ``Typing Haskell in Haskell''.

},
 year={2001},
}
#+END_SRC

** Literate Programming :knuth_lp:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{knuth_lp,
  author       = {Donald E. Knuth},
  title        = {Literate Programming},
  year         = 1984,
  volume       = 27,
  number       = 2,
  pages        = {97-111},
  doi          = {10.1093/comjnl/27.2.97},
  url          = {https://doi.org/10.1093/comjnl/27.2.97},
  journal      = {Comput. J.},
  timestamp    = {Wed, 14 Nov 2018 10:17:27 +0100},
  biburl       = {https://dblp.org/rec/bib/journals/cj/Knuth84},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Termination Proofs for Recursive Functions in FoCaLiZe :focalize:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{focalize,
  author       = {Catherine Dubois and Fran{\c{c}}ois Pessaux},
  title        = {Termination Proofs for Recursive Functions in FoCaLiZe},
  year         = 2015,
  booktitle    = {Trends in Functional Programming - 16th International
          Symposium, {TFP} 2015, Sophia Antipolis, France, June 3-5,
          2015. Revised Selected Papers},
  pages        = {136-156},
  doi          = {10.1007/978-3-319-39110-6\_8},
  url          = {https://doi.org/10.1007/978-3-319-39110-6\_8},
  crossref     = {DBLP:conf/sfp/2015},
  timestamp    = {Fri, 26 May 2017 00:49:32 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/sfp/DuboisP15},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Domain Interpretations of Martin-L{\"{o}}f's Partial Type Theory :mlt_partial:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@article{mlt_partial,
  author    = {Erik Palmgren and
           Viggo Stoltenberg{-}Hansen},
  title     = {Domain Interpretations of Martin-L{\"{o}}f's Partial Type Theory},
  journal   = {Ann. Pure Appl. Logic},
  volume    = {48},
  number    = {2},
  pages     = {135--196},
  year      = {1990},
  url       = {https://doi.org/10.1016/0168-0072(90)90044-3},
  doi       = {10.1016/0168-0072(90)90044-3},
  timestamp = {Wed, 17 May 2017 14:25:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/apal/PalmgrenS90},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Higher-order interpretations and program complexity :higher_order_interpretations:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{higher_order_interpretations,
  author       = {Patrick Baillot and Ugo Dal Lago},
  title        = {Higher-order interpretations and program complexity},
  year         = 2016,
  volume       = 248,
  pages        = {56-81},
  doi          = {10.1016/j.ic.2015.12.008},
  url          = {https://doi.org/10.1016/j.ic.2015.12.008},
  journal      = {Inf. Comput.},
  timestamp    = {Thu, 18 May 2017 09:54:18 +0200},
  biburl       = {https://dblp.org/rec/bib/journals/iandc/BaillotL16},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC

** Generalising Interpretations between Theories in the context of (pi-) Institutions :institution_interpretations:


#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@inproceedings{institution_interpretations,
  author    = {Jos{\'{e}} Luiz Fiadeiro and
           T. S. E. Maibaum},
  title     = {Generalising Interpretations between Theories in the context of (pi-)
           Institutions},
  booktitle = {Theory and Formal Methods 1993, Proceedings of the First Imperial
           College Department of Computing Workshop on Theory and Formal Methods,
           Isle of Thorns Conference Centre, Chelwood Gate, Sussex, UK, 29-31
           March 1993},
  pages     = {126--147},
  year      = {1993},
  crossref  = {DBLP:conf/imperial/1993},
  timestamp = {Tue, 25 Feb 2003 14:11:07 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/imperial/FiadeiroM93},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** Kripke semantics for dependent type theory and realizability interpretations :dtl_interpretations:


#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{dtl_interpretations,
author="Lipton, James",
editor="Myers, J. Paul
and O'Donnell, Michael J.",
title="Kripke semantics for dependent type theory and realizability interpretations",
booktitle="Constructivity in Computer Science",
year="1992",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="22--32",
abstract="Constructive reasoning has played an increasingly important role in the development of provably correct software. Both typed and type-free frameworks stemming from ideas of Heyting, Kleene, and Curry have been developed for extracting computations from constructive specifications. These include Realizability, and Theories based on the Curry-Howard isomorphism. Realizability --- in its various typed and type-free formulations --- brings out the algorithmic content of theories and proofs and supplies models of the ``recursive universe''. Formal systems based on the propositions-as-types paradigm, such as Martin-L{\"o}f's dependent type theories, incorporate term extraction into the logic itself.",
isbn="978-3-540-47265-0"
}
#+END_SRC
** Theories as Types :theories-as-types:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{theories-as-types,
  author       = {Dennis M{\"{u}}ller and Florian Rabe and Michael Kohlhase},
  title        = {Theories as Types},
  year         = 2018,
  booktitle    = {Automated Reasoning - 9th International Joint Conference,
          {IJCAR} 2018, Held as Part of the Federated Logic Conference,
          FloC 2018, Oxford, UK, July 14-17, 2018, Proceedings},
  pages        = {575-590},
  doi          = {10.1007/978-3-319-94205-6\_38},
  url          = {https://doi.org/10.1007/978-3-319-94205-6\_38},
  timestamp    = {Mon, 09 Jul 2018 13:01:56 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/cade/MullerRK18},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
#+END_SRC
** A Scalable Module System :mmt_main_paper:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Online{mmt_main_paper,
  author       = {Florian Rabe AND Michael Kohlhase},
  title        = {{A Scalable Module System}},
  year         = 2011,
  archiveprefix= {arXiv},
  eprint       = {1105.0548v1},
  primaryclass = {cs.LO}
}
#+END_SRC
** The MMT API: A Generic MKM System                               :mmt_api:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Online{mmt_api,
  author       = {Florian Rabe},
  title        = {{The MMT API: A Generic MKM System}},
  year         = 2013,
  archiveprefix= {arXiv},
  eprint       = {1306.3199v1},
  primaryclass = {cs.LO}
}
#+END_SRC
** Types and Programming Languages :tapl:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@book{tapl,
 author = {Pierce, Benjamin C.},
 title = {Types and Programming Languages},
 year = {2002},
 isbn = {0262162091, 9780262162098},
 edition = {1st},
 publisher = {The MIT Press},
}
#+END_SRC


** An Analysis of Girard's Paradox :girard_paradox:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{girard_paradox,
  author       = {Thierry Coquand},
  title        = {An Analysis of Girard's Paradox},
  year         = 1986,
  booktitle    = {Proceedings of the Symposium on Logic in Computer
          Science {(LICS} '86), Cambridge, Massachusetts, USA,
          June 16-18, 1986},
  pages        = {227-236},
  timestamp    = {Thu, 22 Jan 2015 10:44:13 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/lics/Coquand86},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** A new type for tactics :tacticstype:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@online{tacticstype,
  author = {Andrea Asperti and Wilmer Ricciotti and Claudio Sacerdoti Coen and Enrico Tassi},
  title = {A new type for tactics},
  url = {http://matita.cs.unibo.it/PAPERS/plmms09.pdf},
  urldate = {2018-10-19},
}
#+END_SRC
** Program Verification in {SPARK} and {ACSL}: A Comparative Case Study :acsl:


#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{acsl,
  author       = {Eduardo Brito and Jorge Sousa Pinto},
  title        = {Program Verification in {SPARK} and {ACSL:} {A}
          Comparative Case Study},
  year         = 2010,
  booktitle    = {Reliable Software Technologiey - Ada-Europe 2010,
          15th Ada-Europe International Conference on Reliable
          Software Technologies, Valencia, Spain, June 14-18,
          2010. Proceedings},
  pages        = {97-110},
  doi          = {10.1007/978-3-642-13550-7\_7},
  url          = {https://doi.org/10.1007/978-3-642-13550-7\_7},
  timestamp    = {Mon, 29 May 2017 13:41:16 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/adaEurope/BritoP10},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Lemma Functions for Frama-C: {C} Programs as Proofs} :frama_c:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{frama_c,
  author       = {Grigoriy Volkov and Mikhail U. Mandrykin and Denis
          Efremov},
  title        = {Lemma Functions for Frama-C: {C} Programs as Proofs},
  year         = 2018,
  volume       = {abs/1811.05879},
  eprint       = {1811.05879},
  url          = {http://arxiv.org/abs/1811.05879},
  journal      = {CoRR},
  archiveprefix= {arXiv},
  timestamp    = {Sat, 24 Nov 2018 17:52:00 +0100},
  biburl       =
          {https://dblp.org/rec/bib/journals/corr/abs-1811-05879},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Faster Proof Checking in the Edinburgh Logical Framework :lf_fast_proof_checking:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{lf_fast_proof_checking,
  author       = {Aaron Stump and David L. Dill},
  title        = {Faster Proof Checking in the Edinburgh Logical
          Framework},
  year         = 2002,
  booktitle    = {Automated Deduction - CADE-18, 18th International
          Conference on Automated Deduction, Copenhagen,
          Denmark, July 27-30, 2002, Proceedings},
  pages        = {392-407},
  doi          = {10.1007/3-540-45620-1\_32},
  url          = {https://doi.org/10.1007/3-540-45620-1\_32},
  timestamp    = {Fri, 26 May 2017 14:09:14 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/cade/StumpD02},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Mechanizing the Metatheory of LF :lf_meta_mechanisation:
#+BEGIN_SRC latex  :tangle MyReferences.bib  :exports none
@Online{lf_meta_mechanisation,
  author       = {Christian Urban AND James Cheney AND Stefan
          Berghofer},
  title        = {{Mechanizing the Metatheory of LF}},
  year         = 2008,
  archiveprefix= {arXiv},
  eprint       = {0804.1667v3},
  primaryclass = {cs.LO}
}
#+END_SRC
** Representing Isabelle in LF :lf_has_isabelle:
#+BEGIN_SRC latex  :tangle MyReferences.bib  :exports none
@Article{lf_has_isabelle,
  author       = {Rabe, Florian},
  title        = {Representing Isabelle in LF},
  year         = 2010,
  volume       = 34,
  month        = {Sep},
  pages        = {85‚Äì99},
  issn         = {2075-2180},
  doi          = {10.4204/eptcs.34.8},
  url          = {http://dx.doi.org/10.4204/EPTCS.34.8},
  journal      = {Electronic Proceedings in Theoretical Computer
          Science},
  publisher    = {Open Publishing Association}
}
#+END_SRC

** A practical module system for {LF} :lf_practical_modules:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{lf_practical_modules,
  author       = {Florian Rabe and Carsten Sch{\"{u}}rmann},
  title        = {A practical module system for {LF}},
  year         = 2009,
  booktitle    = {Proceedings of the Fourth International Workshop on
          Logical Frameworks and Meta-Languages: Theory and
          Practice, {LFMTP} '09, McGill University, Montreal,
          Canada, August 2, 2009},
  pages        = {40-48},
  doi          = {10.1145/1577824.1577831},
  url          = {https://doi.org/10.1145/1577824.1577831},
  timestamp    = {Tue, 06 Nov 2018 16:57:31 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/lfmtp/RabeS09},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Crafting a Proof Assistant :matita_main:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{matita_main,
  author       = {Andrea Asperti and Claudio Sacerdoti Coen and Enrico
          Tassi and Stefano Zacchiroli},
  title        = {Crafting a Proof Assistant},
  year         = 2006,
  booktitle    = {Types for Proofs and Programs, International
          Workshop, {TYPES} 2006, Nottingham, UK, April 18-21,
          2006, Revised Selected Papers},
  pages        = {18-32},
  doi          = {10.1007/978-3-540-74464-1\_2},
  url          = {https://doi.org/10.1007/978-3-540-74464-1\_2},
  timestamp    = {Wed, 14 Nov 2018 10:59:42 +0100},
  biburl       = {https://dblp.org/rec/bib/conf/types/AspertiCTZ06},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Efficient Ambiguous Parsing of Mathematical Formulae :ambiguous_parsing:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{ambiguous_parsing,
  author       = {Coen, Claudio Sacerdoti and Zacchiroli, Stefano},
  title        = {Efficient Ambiguous Parsing of Mathematical
          Formulae},
  year         = 2004,
  pages        = {347‚Äì362},
  issn         = {1611-3349},
  doi          = {10.1007/978-3-540-27818-4_25},
  url          = {http://dx.doi.org/10.1007/978-3-540-27818-4_25},
  isbn         = 9783540278184,
  journal      = {Mathematical Knowledge Management},
  publisher    = {Springer Berlin Heidelberg}
}
#+END_SRC
** A compact kernel for the calculus of inductive constructions :matita_is_coq_light:

#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{matita_is_coq_light,
  author       = {Asperti, A. and Ricciotti, W. and Sacerdoti Coen,
          C. and Tassi, E.},
  title        = {A compact kernel for the calculus of inductive
          constructions},
  year         = 2009,
  volume       = 34,
  number       = 1,
  month        = {Feb},
  pages        = {71‚Äì144},
  issn         = {0973-7677},
  doi          = {10.1007/s12046-009-0003-3},
  url          = {http://dx.doi.org/10.1007/s12046-009-0003-3},
  journal      = {Sadhana},
  publisher    = {Springer Nature}
}

#+END_SRC

** {CASL:} the Common Algebraic Specification Language}      :casl_overview:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Article{casl_overview,
  author       = {Egidio Astesiano and Michel Bidoit and
          H{\'{e}}l{\`{e}}ne Kirchner and Bernd
          Krieg{-}Br{\"{u}}ckner and Peter D. Mosses and
          Donald Sannella and Andrzej Tarlecki},
  title        = {{CASL:} the Common Algebraic Specification Language},
  year         = 2002,
  volume       = 286,
  number       = 2,
  pages        = {153-196},
  doi          = {10.1016/S0304-3975(01)00368-1},
  url          = {https://doi.org/10.1016/S0304-3975(01)00368-1},
  journal      = {Theor. Comput. Sci.},
  timestamp    = {Wed, 14 Nov 2018 10:33:31 +0100},
  biburl       =
          {https://dblp.org/rec/bib/journals/tcs/AstesianoBKKMST02},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** Casl User Manual - Introduction to Using the Common :casl_user_manual:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Book{casl_user_manual,
  author       = {Michel Bidoit and Peter D. Mosses},
  title        = {Casl User Manual - Introduction to Using the Common
          Algebraic Specification Language},
  year         = 2004,
  volume       = 2900,
  series       = {Lecture Notes in Computer Science},
  publisher    = {Springer},
  isbn         = {3-540-20766-X},
  doi          = {10.1007/b11968},
  url          = {https://doi.org/10.1007/b11968},
  timestamp    = {Wed, 14 Nov 2018 10:12:23 +0100},
  biburl       = {https://dblp.org/rec/bib/books/sp/BidoitM04},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

** {CASL} Reference Manual, The Complete Documentation :casl_reference_manual:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@Book{casl_reference_manual,
  author       = {Peter D. Mosses},
  title        = {{CASL} Reference Manual, The Complete Documentation
          of the Common Algebraic Specification Language},
  year         = 2004,
  volume       = 2960,
  series       = {Lecture Notes in Computer Science},
  publisher    = {Springer},
  isbn         = {3-540-21301-5},
  doi          = {10.1007/b96103},
  url          = {https://doi.org/10.1007/b96103},
  timestamp    = {Wed, 14 Nov 2018 10:12:23 +0100},
  biburl       = {https://dblp.org/rec/bib/books/sp/Mosses04},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC
** Compcert reference :compcert_paper:
#+BEGIN_SRC latex :tangle MyReferences.bib  :exports none
@InProceedings{compcert_paper,
  author       = {Robbert Krebbers and Xavier Leroy and Freek Wiedijk},
  title        = {Formal {C} Semantics: CompCert and the {C} Standard},
  year         = 2014,
  booktitle    = {Interactive Theorem Proving - 5th International
          Conference, {ITP} 2014, Held as Part of the Vienna
          Summer of Logic, {VSL} 2014, Vienna, Austria, July
          14-17, 2014. Proceedings},
  pages        = {543-548},
  doi          = {10.1007/978-3-319-08970-6\_36},
  url          = {https://doi.org/10.1007/978-3-319-08970-6\_36},
  timestamp    = {Sun, 21 May 2017 00:18:59 +0200},
  biburl       = {https://dblp.org/rec/bib/conf/itp/KrebbersLW14},
  bibsource    = {dblp computer science bibliography,
          https://dblp.org}
}
#+END_SRC

* COMMENT Making README.md                                                 :noexport:

# PhD research ;; What's the difference between a typeclass/trait and a # record/class/struct? Nothing really, or so I argue.

# ( A brief demonstration of the prototype may be viewed at https://www.youtube.com/watch?v=NYOOF9xKBz8 )

:Importance-of-narrative:

The importance of the narrative is that it forces the remaining sections to tie into the
ideas and questions posed here. Furthermore, it servers as a guide map for the remainder
of the thesis proposal. Additionally, it serves as a writing prompt insisting each sentence
of our proposal relates or contributes to our core mood:
The disillusionment with computational organisation can be rectified by using dependent types
to bring about a homogeneous treatment of structuring mechanisms.
:End:

#+NAME: make-readme
#+BEGIN_SRC emacs-lisp :results none
(with-temp-buffer
    (insert
    "#+EXPORT_FILE_NAME: README.md
     #+OPTIONS: toc:nil

     #+HTML: <h1> The Next 700 Module Systems </h1>
     #+HTML: <h3> Extending Dependently-Typed Languages to Implement Module System Features In The Core Language </h3>

     This repository contains the research proposal for my doctoral studies at McMaster University
     under the supervision of Jacques Carette and Wolfram Kahl.

     /What are and what should be the module systems of DTLs?/
     /DTLs remove distinctions between packaging systems and so/
     /using pedestrian modules systems is not necessarily the best route./

    + A requirements driven approach to coherent modularisarion constructs in Dependently-typed languages.
    + Main Question: /What are the module systems for Dependently-Typed Languages?/
    + Goal: Extend Agda to be powerful enough to implement the module system features, in the core language, that people want to do.

      In user facing libraries, [[https://inf.ug.edu.pl/~schwarzw/papers/mkm2010.pdf][redundancies are desirable]]
      since they may utilise a a variety of aliases for what user want, this is useful
      flexibility.
      - However, in the source file, each item should only exist once.
      - The front-end redundancy should be produced by machine generation,
    rather than by hand.

   # /How to package two operations?/
   # E.g., dot product in ‚Ñù¬≥ takes 6 numbers /or/ two arguments,
   # being vectors. Hence, we can bundle arguments in logically
   # meaningul ways.

      [[https://alhassy.github.io/next-700-module-systems-proposal/][Website]] ‚óà [[https://alhassy.github.io/next-700-module-systems-proposal/thesis-proposal.pdf][PDF]] ‚óà [[https://alhassy.github.io/next-700-module-systems-proposal/thesis-proposal.html][HTML]] ‚óà [[https://alhassy.github.io/next-700-module-systems-proposal/defence-slides.html][Slides]] ‚óà [[https://alhassy.github.io/next-700-module-systems-proposal/translate_functions.agda.html][~translate~ code]] ‚óà [[https://alhassy.github.io/next-700-module-systems-proposal/monoid_renditions.agda.html][~monoid~ code]] ‚óÜ [[https://www.youtube.com/watch?v=NYOOF9xKBz8&feature=youtu.be][Demo]]

   A super simple description of this work, for the layman, can be found [[https://alhassy.github.io/three_minutes/][here]].

    ")
    (org-mode)
    (org-md-export-to-markdown)
    ;; Coloured html does not work in Github, afaik.
    ;; (org-html-export-to-html)
    ;; (shell-command "mv README.html README.md")
)

;; Does not work well with Agda's load.
;;
;; Make HTMLs of agda code
;; (with-temp-buffer
;;   (find-file "translate_functions.agda")
;;   (agda2-load)
;;   ;; (htmlize-buffer)
;; )

;; making html page
(with-temp-buffer
    (insert
    "#+EXPORT_FILE_NAME: thesis-proposal.html
     #+OPTIONS: toc:nil tags:nil
     #+INFOJS_OPT: view:info toc:t buttons:t
     #+TITLE: The Next 700 Module Systems
     #+SUBTITLE: Extending Dependently-Typed Languages to Implement Module System Features In The Core Language

     # INCLUDE: \"thesis-proposal.org::#abstract\" :only-contents t

     # TOC: headlines 2
     #+MACRO: code
     #+MACRO: remark
     #+MACRO: null
     #+INCLUDE: \"thesis-proposal.org::#introduction\"
     #+INCLUDE: \"thesis-proposal.org::#current_approaches\"
     #+INCLUDE: \"thesis-proposal.org::#solution_requirements\"
     #+INCLUDE: \"thesis-proposal.org::#approach_and_timeline\"
     #+INCLUDE: \"thesis-proposal.org::#conclusion\"

    ")
    (org-mode)
    (org-html-export-to-html)
    ;; (suspend-frame)
)
#+END_SRC
* COMMENT footer                                                     :ignore:

# Local Variables:
# eval: (progn (org-babel-goto-named-src-block "make-acmart-class") (org-babel-execute-src-block) (outline-hide-sublevels 1))
# eval: (progn (org-babel-goto-named-src-block "make-readme") (org-babel-execute-src-block) (outline-hide-sublevels 1))
# compile-command: (progn (org-babel-tangle) (org-latex-export-to-pdf) (async-shell-command "open Paper0.pdf"))
# End:
